<!DOCTYPE HTML>
<html lang="en">
<head>
    
<title>Bers - Shadertoy BETA</title>
<meta charset="utf-8" />
<meta name="Keywords" content="shadertoy, shader toy, quilez, inigo, jeremias, pol, fractals, demoscene, computer graphics, mathematics, rendering, demo, 3D, realtime, shader, raytracing, raymarching, webgl, glsl" />
<meta name="Description" content="Build shaders, share them, and learn from the best community." />
<meta name="Author" content="Beautypi" />
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />

<link rel="image_src" href="https://www.shadertoy.com/img/logo.png" />
<link rel="apple-touch-icon" href="/img/launch_icon_57.png"/>
<link rel="apple-touch-icon" sizes="72x72" href="/img/launch_icon_72.png"/>
<link rel="apple-touch-icon" sizes="114x114" href="/img/launch_icon_114.png"/>
<link rel="shortcut icon" href="/img/favicon.ico"/>

<style>::-webkit-scrollbar {
    height: 8px;
    width: 8px;
    background: #404040;
}

::-webkit-scrollbar-thumb
{
    background: #909090;
    border-radius: 0ex;
}

::-webkit-scrollbar-corner
{
    background: #000;
}

::-webkit-input-placeholder
{
	font-style:italic;
}
input:-moz-placeholder, textarea:-moz-placeholder
{
	font-style:italic;
}
input.placeholder-text, textarea.placeholder-text
{
	font-style:italic;
}

pre 
{
    white-space: pre-wrap;
    white-space: -moz-pre-wrap;
    white-space: -pre-wrap;
    white-space: -o-pre-wrap;
    word-wrap: break-word;
}

@font-face
{
    font-family: Lobster;
    src: url("/img/lobster.otf") format("opentype");
}

div#centerScreen
{
    left: 50%;
    top: 50%;
    position: absolute;
}

a.headerLinks:hover
{
    background-color:#505050;
    color : #ff8020;
}

body
{
    color: #000000;
    font-size:12px;
    font-style:normal;
    font-family:Tahoma,Arial;
    background-repeat: no-repeat;
    //background-attachment: fixed;
    padding:0px;
    margin:0px;
    text-align: left;
    background-color: #d0d0d0;
    background-repeat: repeat;
    user-select: text;
}

a,
a:hover,
a:visited
{
  color : inherit;
}

div#content {
    width: 95%;
    overflow: hidden;
    margin: auto;
    padding: 0px;
    min-height: calc(100vh - 80px);
    //box-sizing: border-box;
}


.notificationCount
{
 background-color:#ff0000;
 padding-left:3px;
 padding-right:1px;
 padding-top:1px;
 padding-bottom:1px;
}

div#header
{
    background-color: #404040;
    top: 0px;
    left: 0px;
    width: 100%;
    padding: 0;
    margin: 0;
    color: #ffffff;
    display: flex;
    flex-direction:row;
}

#headerBlock1
{
    width: 50%;
    display:flex;
    align-items:center;
}

a#headerTitle
{
    font-size: 2.25em;
    font-family: Lobster,Tahoma,Arial;
    text-decoration: none;
    padding-left:32px;
    padding-right:32px;
}

#headerSearch
{
    display: inline-block;
    color: #000000;
    width: 300px;
}

input[type=search]#mySearch
{
    width: 100%;
    border-radius: 6px;
    border: 1px solid black;
    padding:12px;
}

#headerBlock2
{
    width: 50%;
    margin-left: auto;
    display: flex;
    justify-content: flex-end;
}


a#headerTitle:hover
{
    color : #ff8020;
}

a.headerLinks
{
    font-weight: bold;
    padding-top: 14px;
    padding-bottom: 14px;
    padding-left: 14px;
    padding-right: 14px;
    margin:0px;
    text-decoration: none;
    transition: background-color 0.15s linear, color 0.15s linear;
}

#footer
{
    background-color: rgba(64,64,64,0.25);
    color: #000000;
    padding: 0px;
    margin: 0px;
    width: 100%;
    display: flex;
    justify-content: space-between;
    flex-wrap: wrap;
}

#footer div
{
    padding-top:10px;
    padding-bottom:0px;
    padding-left:16px;
    padding-right:16px;
}

#footer div ul
{
    margin-left:0px;
    padding-left:16px;
}

#footer div ul li
{
    padding-top:6px;
}

a.regular
{
    font-weight:bold;
    text-decoration:none
}

a.regular:hover
{
  color : #ff8020;
}

a.user
{
    font-weight:bold;
    text-decoration:none;
}

a.user:hover
{
  color : #ff8020;
  text-decoration: underline;
}

.uiButton
{
    border: none;
    outline: none;
    margin: 0px;
    padding: 0px;
    width: 22px;
    height: 22px;
    position: absolute;
    cursor: pointer;
    border-radius: 4px;
}

.uiButton:hover
{
    box-shadow: inset 0px 0px 1px 1px #808080, 0px 0px 1px 1px #808080;
}

.uiDivBUtton
{
    cursor:pointer;
}

.uiDivBUtton:hover
{
    color: #ffffff;
}


.dialog
{
    display: block;
    background-color: #e0e0e0;
    color: #000000;
    border:1px solid #000;
    padding:0px;
    margin:0px;
    text-align:left;
    border-radius: 4px;
    box-shadow:4px 4px 6px 0px rgba(0,0,0,0.5);
    overflow: hidden;
    z-index:1000;
    visibility: hidden;
    opacity:0;
    -moz-transition: opacity 0.25s linear,visibility 0.25s linear;
    -webkit-transition: opacity 0.25s linear,visibility 0.25s linear;
    transition: opacity 0.25s linear,visibility 0.25s linear;
}

.dialogHeader
{
    left:0px;
    top: 0px;
    width:100%;
    height:32px;
    position: absolute;
    background-color: #808080;
    cursor:move;
}

.dialogTitle
{
    left: 12px;
    top: 4px;
    position: absolute;
    padding: 0px;
    margin: 0px;
    color:#000000;
    font-size:1.5em;
    text-align: left;
    user-select: none;
    -moz-user-select: -moz-none;
    -webkit-user-select: none;
}

.dialogOverlay
{
    z-index:1000;

    visibility: hidden;
    opacity:0;
    -moz-transition: opacity 0.25s linear,visibility 0.25s linear;
    -webkit-transition: opacity 0.25s linear,visibility 0.25s linear;
    transition: opacity 0.25s linear,visibility 0.25s linear;

    left:0px;
    top:0px;
    padding:0px;
    margin:0px;
    width:100%;
    height:100%;
    position:absolute;

    background-color:rgba(0,0,0,.4);
}

.viewsIcon, .likesIcon
{
    border: none;
    outline: none;
    display:inline-block;
    background-repeat:no-repeat;
    top:0px;
    left:0px;
    padding:0px;
    padding-right: 2px;
    margin:0px;
    position:relative;
}

.userPictureSmall
{
    background-color:#808080;
    border: 1px solid #000000;
    width:32px;
    height:32px;
}

.dialogCloseButton
{
    right:8px;
    top: 4px;
    width:22px;
    height:22px;
    position: absolute;
    background-image: url("/img/close.png");
    cursor: pointer;
    border-radius: 4px;
}

.dialogCloseButton:hover
{
    box-shadow: inset 0px 0px 4px 2px #ffffff, 0px 0px 4px 2px #ffffff;
}

.dialogContentButtons
{
     padding:0;
     border:0;
     text-align: justify;
     left: 24px;
     bottom:40px;
     position:absolute;
}

.dialogButton
{
    text-align: center;
    vertical-align: middle;
    display: inline-block;
    border-radius: 4px;
    font-weight: bold;
    cursor: pointer;
    padding-bottom:5px;
    padding-top:4px;
    padding-left: 8px;
    padding-right: 8px;
    margin-left:4px;
    margin-right:4px;
    text-decoration: none;
    color:#000000;
    width: 80px;
    -moz-transition:    background-color 0.15s linear, color 0.15s linear;
    -webkit-transition: background-color 0.15s linear, color 0.15s linear;
    transition:         background-color 0.15s linear, color 0.15s linear;
}

.dialogButton:hover
{
  background-color:#808080;
  color : #ff8020;
}

.dialogCloseButton:hover
{
    box-shadow: inset 0px 0px 4px 2px #ffffff, 0px 0px 4px 2px #ffffff;
}

.dialogContent
{
    color: inherit;
    overflow: auto;
    width:100%;
    height:100%;
    left: 0px;
    top: 32px;
    position:absolute
}

.dialogContentBody
{
    color: inherit;
    width:100%;
    height:auto;
    padding-top:24px;
    padding-bottom:24px;
    padding-left:24px;
    padding-right:24px;
    text-align: left;
}

.formButton
{
    font-weight:bold;
	color:#ffffff;
	border:none;
    text-align:center;
	background-color:#808080;
    border-radius: 4px;
	padding-left:8px;
	padding-right:8px;
	padding-top:4px;
	padding-bottom:4px;
    cursor:pointer;
    min-width:80px;
    box-sizing: border-box;
}
.formInput {
    border-radius: 6px;
    border: 1px solid black;
    padding: 4px;
    border: none;
}
.formButton:hover {
    background-color: #e0e0e0;
}
.formButton:disabled
{
	color:#b0b0b0;
	background-color:#808080;
}

.formButtonSmall
{
    color:#ffffff;
    border:none;
    text-align:center;
    background-color:#808080;
    border-radius: 4px;
    padding-left:2px;
    padding-right:2px;
    padding-top:2px;
    padding-bottom:2px;
    cursor:pointer;
    min-width:40px;
}

.formButtonSmall:hover
{
    background-color: #e0e0e0;
}

.formButtonSmall:disabled
{
    color:#b0b0b0;
    background-color:#808080;
}

.formButtonSmall.disabled2,
.formButton.disabled2 { color:#b0b0b0; background-color:#808080; pointer-events: none; }

.inputForm
{
    padding-left:2%;
    padding-right:2%;
    resize: none;
    text-align: left;
    background-color:#e0e0e0;
    outline: none;
    border-radius: 4px;
    border: 1px solid #808080;
    color:inherit;
    box-sizing: border-box;
}

.inputForm:focus
{
    border: 1px solid #AFCDD8;
    background-color: #EBF2F4;
}

.transparentPannel
{
    background-color:rgba(64,64,64,0.1);
    padding:16px;
}

.comment, .commentSelf, .commentNew
{
    border-radius: 4px;
    width: 100%;
    margin-left: 0px;
    margin-right: 0px;
    margin-top: 0px;
    margin-bottom: 6px;

    padding: 14px;
    box-sizing: border-box;
    display: grid;
    grid-template-columns: 32px auto 8px;
    grid-template-rows: 1fr;
    grid-gap:8px;
}

.comment:nth-child(even)
{
    background-color: rgba(64,64,64,0.1);
}

.comment:nth-child(odd)
{
    background-color: rgba(128,128,128,0.1);
}

.commentSelf
{
    background-color: rgba(240,160,64,0.1);
}

.commentNew
{
    padding-right: 0px;
    grid-template-columns: 40px auto;
}

.commentContent
{
    vertical-align: top;
    text-align: left;
    word-break: break-all;
    word-break: break-word;
    white-space: pre-wrap;
    white-space: -moz-pre-wrap;
}


/* ----------------------- media resolutions ------------------------ */

@media screen and (max-width:799px)
{
    div#header {flex-direction:column; }
    #headerBlock1 { width:100%; }
    #headerBlock2 { width:100%; justify-content: space-around;}
    div#headerSearch {width:200px;}
    input#mySearch { width:200px; left:21px; height:22px; border-radius:6px; padding-left:8px; padding-right:8px; }
    .previewText { width:130px; }
    .transparentPannel { padding:10px; }
}

@media screen and (min-width:800px) and (max-width:1279px)
{
    body { font-size: 9px; }
    div#headerSearch {width: 250px;}
    input#mySearch { width:250px; left:21px; height:22px; border-radius:6px; padding-left:8px; padding-right:8px; }
    .previewText { width:130px; }
    .transparentPannel { padding:11px; }
}

@media screen and (min-width:1280px) and (max-width:1439px)
{
    body { font-size: 10px; }
    div#headerSearch {width: 300px;}
    input#mySearch { width:300px; left:21px; height:22px; border-radius:6px; padding-left:8px; padding-right:8px; }
    .dialogHeader { height:28px; }
    .previewText { width:180px; }
    .transparentPannel { padding:12px; }
}

@media screen and (min-width:1440px) and (max-width:1919px)
{
    div#headerSearch {width: 300px;}
    input#mySearch { width:300px; left:21px; height:22px; border-radius:6px; padding-left:8px; padding-right:8px; }
    .dialogHeader { height:28px; }
    .previewText { width:180px; }
    .transparentPannel { padding:12px; }
}

@media screen and (min-width:1920px) and (max-width:2559px)
{
    div#headerSearch {width: 300px;}
    input#mySearch { width:300px; left:21px; height:22px; border-radius:6px; padding-left:8px; padding-right:8px; }
    .dialogHeader { height:32px; }
    .previewText { width:220px; }
    .transparentPannel { padding:16px; }
}

@media screen and (min-width:2560px) 
{
    div#headerSearch {width: 300px;}
    input#mySearch { width:300px; left:21px; height:22px; border-radius:6px; padding-left:8px; padding-right:8px; }
    .dialogHeader { height:32px; }
    .previewText { width:220px; }
    .transparentPannel { padding:16px; }
}
body
{
    background-image: url("/img/themes/classic/background.jpg");
}
</style>


    <script>"use strict"

//==============================================================================
//
// piLibs 2015-2017 - http://www.iquilezles.org/www/material/piLibs/piLibs.htm
//
// piCamera
//
//==============================================================================

function piCamera()
{
    var mMatrix = setIdentity();
    var mMatrixInv = setIdentity();

    var mPosition = [0.0,0.0,0.0];
    var mXRotation = 0.0;
    var mYRotation = 0.0;

    var mPositionTarget = [0.0,0.0,0.0];
    var mXRotationTarget = 0.0;
    var mYRotationTarget = 0.0;

    var me = {};
/*
    me.Set = function( pos, dir, roll) 
             {
                 mMatrix    = setLookat( pos, add(pos,dir), [Math.sin(roll),Math.cos(roll),Math.sin(roll)] );
                 mMatrixInv = invertFast( mMatrix );
             };
*/
    me.SetPos = function(pos)
                {
                    mPosition = pos;
                    //mMatrix[ 3] = -(mMatrix[0] * pos[0] + mMatrix[1] * pos[1] + mMatrix[ 2] * pos[2]);
                    //mMatrix[ 7] = -(mMatrix[4] * pos[0] + mMatrix[5] * pos[1] + mMatrix[ 6] * pos[2]);
                    //mMatrix[11] = -(mMatrix[8] * pos[0] + mMatrix[9] * pos[1] + mMatrix[10] * pos[2]);
                };
/*
    me.GlobalMove = function(pos)
                    {
                        mMatrix[ 3] -= (mMatrix[0] * pos[0] + mMatrix[1] * pos[1] + mMatrix[ 2] * pos[2]);
                        mMatrix[ 7] -= (mMatrix[4] * pos[0] + mMatrix[5] * pos[1] + mMatrix[ 6] * pos[2]);
                        mMatrix[11] -= (mMatrix[8] * pos[0] + mMatrix[9] * pos[1] + mMatrix[10] * pos[2]);
                        mMatrixInv = invertFast(mMatrix);
                    };
*/
    me.LocalMove = function( dis )
                    {
                        dis = matMulvec( setRotationY(-mYRotation), dis);
                        mPositionTarget = sub(mPositionTarget,dis)
                    };

    me.RotateXY = function( x, y)
                  {
                    mXRotationTarget -= x;
                    mYRotationTarget -= y;
                    mXRotationTarget = Math.min( Math.max( mXRotationTarget, -Math.PI/2), Math.PI/2 );
                  };


    me.CameraExectue = function( dt )
    {
        // smooth position
        mXRotation += (mXRotationTarget-mXRotation) * 12.0*dt;
        mYRotation += (mYRotationTarget-mYRotation) * 12.0*dt;
        mPosition = add(mPosition, mul( sub(mPositionTarget, mPosition), 12.0*dt));

        // Make Camera matrix
        mMatrix = matMul( matMul(setRotationX(mXRotation), 
                                 setRotationY(mYRotation)),  
                                 setTranslation(mPosition));
        mMatrixInv = invertFast(mMatrix);

    }

    me.GetMatrix = function() { return mMatrix; };
    me.GetMatrixInverse = function() { return mMatrixInv; };
    me.SetMatrix = function( mat ) 
                    {
                        mMatrix = mat;
                        mMatrixInv = invertFast(mMatrix);

                        mPosition = getXYZ(matMulpoint(mat, [0.0,0.0,0.0]));
                        mPositionTarget = mPosition;
                    };

    me.GetPos = function() { return getXYZ(matMulpoint(mMatrixInv, [0.0,0.0,0.0])); }
    me.GetDir = function() { return getXYZ(normalize(matMulvec(mMatrixInv, [0.0,0.0,-1.0]))); }

    return me;
}
//==============================================================================
//
// piLibs 2015-2017 - http://www.iquilezles.org/www/material/piLibs/piLibs.htm
//
// piFile
//
//==============================================================================

function piFile( binaryDataArrayBuffer )
{
    // private
    //var mDataView = new DataView( binaryDataArrayBuffer, 0 );
    var mDataView = binaryDataArrayBuffer;
    var mOffset = 0;

    // public members
    var me = {};
    me.mDummy = 0;
/*
    // public functions
    me.Seek = function( off ) { mOffset = off - 3; };
    me.ReadUInt16 = function()  { var res = mDataView.getUint16( mOffset ); mOffset+=2; return res; };
    me.ReadUInt32 = function()  { var res = mDataView.getUint32( mOffset ); mOffset+=4; return res; };
    me.ReadUInt64 = function()  { return me.ReadUInt32() + (me.ReadUInt32()<<32); };
    me.ReadFloat32 = function() { var res = mDataView.getFloat32( mOffset ); mOffset+=4; return res; };
*/

    me.Seek = function( off ) { mOffset = off; };
    me.ReadUInt8  = function()  { var res = (new Uint8Array(mDataView,mOffset))[0]; mOffset+=1; return res; };
    me.ReadUInt16 = function()  { var res = (new Uint16Array(mDataView,mOffset))[0]; mOffset+=2; return res; };
    me.ReadUInt32 = function()  { var res = (new Uint32Array(mDataView,mOffset))[0]; mOffset+=4; return res; };
    me.ReadUInt64 = function()  { return me.ReadUInt32() + (me.ReadUInt32()<<32); };
    me.ReadFloat32 = function() { var res = (new Float32Array(mDataView,mOffset))[0]; mOffset+=4; return res; };
    me.ReadFloat32Array = function(n) 
                          { 
                              var src = new Float32Array(mDataView, mOffset);
                              var res = [];  for( var i=0; i<n; i++ ) { res[i] = src[i]; }
                              mOffset += 4*n;
                              return res;
                          };
    me.ReadFloat32ArrayNative = function(n) { var src = new Float32Array(mDataView, mOffset); mOffset += 4*n; return src; };
    return me;
}
//==============================================================================
//
// piLibs 2015-2017 - http://www.iquilezles.org/www/material/piLibs/piLibs.htm
//
// piMesh
//
//==============================================================================

function piMesh()
{
    this.mChunks = [];
    this.mPrimitiveType = 0;
    this.mVertexFormat = null;
}

/*
piMesh.prototype.normalize = function( ppos, npos )
{
    var numv = this.mVertexData.length;
    var numt = this.mIndices.length;

    for( var i=0; i<numv; i++ )
    {
        //float *v = (float*)piMesh_GetVertexData( me, i, npos );
        //v[0] = 0.0f;
        //v[1] = 0.0f;
        //v[2] = 0.0f;
        this.mVerts[8 * i + 3] = 0.0;
        this.mVerts[8 * i + 4] = 0.0;
        this.mVerts[8 * i + 5] = 0.0;
    }

    for( var i=0; i<numt; i++ )
    {
        piMeshFace *face = me->mFaceData.mIndexArray[0].mBuffer + i;

        const int ft = face->mNum;
        
        vec3 nor = vec3( 0.0f, 0.0f, 0.0f );
        for( int j=0; j<ft; j++ )
        {
            const vec3 va = *((vec3*)piMesh_GetVertexData( me, face->mIndex[ j      ], ppos ));
            const vec3 vb = *((vec3*)piMesh_GetVertexData( me, face->mIndex[(j+1)%ft], ppos ));

            nor += cross( va, vb );
        }

        for( int j=0; j<ft; j++ )
        {
            vec3 *n = (vec3*)piMesh_GetVertexData( me, face->mIndex[j], npos );
            n->x += nor.x;
            n->y += nor.y;
            n->z += nor.z;
        }
    }

    for( var i=0; i<numv; i++ )
    {
        vec3 *v = (vec3*)piMesh_GetVertexData( me, i, npos );
        *v = normalize( *v );
    }
}
*/

piMesh.prototype.createCube = function(renderer)
{
    this.mPrimitiveType = 0;

    this.mChunks[0] = { mVerts : new Float32Array([ -1.0, -1.0, -1.0,
                                       1.0, -1.0, -1.0,
                                      -1.0,  1.0, -1.0,
                                       1.0,  1.0, -1.0,
                                      -1.0, -1.0,  1.0,
                                       1.0, -1.0,  1.0,
                                      -1.0,  1.0,  1.0,
                                       1.0,  1.0,  1.0 ]),

                        mIndices : new Uint16Array([ 0, 2, 1,   1, 2, 3,   5, 1, 3,   5, 3, 7,   4, 5, 7,   4, 7, 6,   4, 6, 2,   4, 2, 0,   6, 7, 3,   6, 3, 2,   4, 0, 1,   4, 1, 5 ]),
                        mNumVertices : 8,
                        mNumFaces : 12, 
                        mTransform : setIdentity(),
                        mVBO : null, 
                        mIBO : null };

    this.mVertexFormat = { mStride:12, mChannels:[ { mNumComponents:3, mType: renderer.TYPE.FLOAT32, mNormalize: false } ] };

    return true;
}

piMesh.prototype.createCubeSharp = function (renderer)
{
    this.mPrimitiveType = 0;

    this.mChunks[0] = { mVerts : new Float32Array([-1.0, 1.0,-1.0,   0.0, 1.0, 0.0,   0.0, 0.0,
                                    -1.0, 1.0, 1.0,   0.0, 1.0, 0.0,   0.0, 1.0,
                                     1.0, 1.0, 1.0,   0.0, 1.0, 0.0,   1.0, 1.0,
                                     1.0, 1.0,-1.0,   0.0, 1.0, 0.0,   1.0, 0.0,

                                    -1.0,-1.0, 1.0,   0.0, 0.0, 1.0,   0.0, 0.0,
                                     1.0,-1.0, 1.0,   0.0, 0.0, 1.0,   0.0, 1.0,
                                     1.0, 1.0, 1.0,   0.0, 0.0, 1.0,   1.0, 1.0,
                                    -1.0, 1.0, 1.0,   0.0, 0.0, 1.0,   1.0, 0.0,

                                     1.0, 1.0, 1.0,   1.0, 0.0, 0.0,   0.0, 0.0,
                                     1.0,-1.0, 1.0,   1.0, 0.0, 0.0,   0.0, 1.0,
                                     1.0,-1.0,-1.0,   1.0, 0.0, 0.0,   1.0, 1.0,
                                     1.0, 1.0,-1.0,   1.0, 0.0, 0.0,   1.0, 0.0,

                                     1.0,-1.0,-1.0,   0.0, 0.0,-1.0,   0.0, 0.0,
                                    -1.0,-1.0,-1.0,   0.0, 0.0,-1.0,   0.0, 1.0,
                                    -1.0, 1.0,-1.0,   0.0, 0.0,-1.0,   1.0, 1.0,
                                     1.0, 1.0,-1.0,   0.0, 0.0,-1.0,   1.0, 0.0,

                                    -1.0,-1.0, 1.0,   0.0,-1.0, 0.0,   0.0, 0.0,
                                    -1.0,-1.0,-1.0,   0.0,-1.0, 0.0,   0.0, 1.0,
                                     1.0,-1.0,-1.0,   0.0,-1.0, 0.0,   1.0, 1.0,
                                     1.0,-1.0, 1.0,   0.0,-1.0, 0.0,   1.0, 0.0,

                                    -1.0, 1.0, 1.0,  -1.0, 0.0, 0.0,   0.0, 0.0,
                                    -1.0, 1.0,-1.0,  -1.0, 0.0, 0.0,   0.0, 1.0,
                                    -1.0,-1.0,-1.0,  -1.0, 0.0, 0.0,   1.0, 1.0,
                                    -1.0,-1.0, 1.0,  -1.0, 0.0, 0.0,   1.0, 0.0 ]),

                        mIndices : new Uint16Array([0,1,2, 0,2,3,   4,5,6, 4,6,7,    8,9,10,8,10,11,   12,13,14,12,14,15,   16,17,18,16,18,19,   20,21,22,20,22,23]),
                        mNumVertices : 24,
                        mNumFaces : 12, 
                        mTransform : setIdentity(),
                        mVBO : null, 
                        mIBO : null };


    this.mVertexFormat = { mStride:32, mChannels:[ { mNumComponents:3, mType: renderer.TYPE.FLOAT32, mNormalize: false },
                                                   { mNumComponents:3, mType: renderer.TYPE.FLOAT32, mNormalize: false },
                                                   { mNumComponents:2, mType: renderer.TYPE.FLOAT32, mNormalize: false } ] };

    return true;
}


piMesh.prototype.createUnitQuad = function (renderer)
{
    this.mPrimitiveType = 0;
    this.mVertexFormat = { mStride:8, mChannels: [ {mNumComponents:2, mType: renderer.TYPE.FLOAT32, mNormalize: false} ] };

    this.mChunks[0] = { mVerts : new Float32Array([-1.0, -1.0, 1.0, -1.0, -1.0,  1.0, 1.0,  1.0]),
                        mIndices : new Uint16Array([0, 2, 1, 1, 2, 3]),
                        mNumVertices : 4,
                        mNumFaces : 2, 
                        mTransform : setIdentity(),
                        mVBO : null, 
                        mIBO : null };
 
    return true;
}




piMesh.prototype.destroy = function()
{
    //delete this.mVerts;   this.mVerts = null;
    //delete this.mIndices; this.mIndices = null;
}

piMesh.prototype.scale = function (x, y, z)
{
    var stride = this.mVertexFormat.mStride/4;
    for( var j=0; j<this.mChunks.length; j++ )
    {
        var nv = this.mChunks[j].mNumVertices;
        for (var i = 0; i < nv; i++) 
        {
            this.mChunks[j].mVerts[stride * i + 0] *= x;
            this.mChunks[j].mVerts[stride * i + 1] *= y;
            this.mChunks[j].mVerts[stride * i + 2] *= z;
        }
    }
}

piMesh.prototype.translate = function (x, y, z) 
{
    var stride = this.mVertexFormat.mStride/4;
    for( var j=0; j<this.mChunks.length; j++ )
    {
        var nv = this.mChunks[j].mNumVertices;
        for (var i = 0; i < nv; i++) 
        {
            this.mChunks[j].mVerts[stride * i + 0] += x;
            this.mChunks[j].mVerts[stride * i + 1] += y;
            this.mChunks[j].mVerts[stride * i + 2] += z;
        }
    }
}

piMesh.prototype.GPULoad = function (renderer)
{
    for( var i=0; i<this.mChunks.length; i++ )
    {
        var vbo = renderer.CreateVertexArray(this.mChunks[i].mVerts, renderer.BUFTYPE.STATIC );
        if (vbo == null)
            return false;

        var ibo = renderer.CreateIndexArray(this.mChunks[i].mIndices, renderer.BUFTYPE.STATIC);
        if (ibo == null)
            return false;

        this.mChunks[i].mVBO = vbo;
        this.mChunks[i].mIBO = ibo;
    }
    return true;
}

piMesh.prototype.GPURender = function (renderer, positions )//, matPrj, matCam )
{
    //renderer.SetShaderConstantMat4F("unMPrj", matPrj, false );

    var num = this.mChunks.length;
    for( var i=0; i<num; i++ )
    {
        //var mat =  matMul( matCam, this.mChunks[i].mTransform );
        //renderer.SetShaderConstantMat4F("unMMod", mat, false);

        renderer.AttachVertexArray(this.mChunks[i].mVBO, this.mVertexFormat, positions );
        renderer.AttachIndexArray(this.mChunks[i].mIBO );
        renderer.DrawPrimitive(renderer.PRIMTYPE.TRIANGLES, this.mChunks[i].mNumFaces * 3, true, 1);
        renderer.DetachIndexArray(this.mChunks[i].mIBO);
        renderer.DetachVertexArray(this.mChunks[i].mVBO, this.mVertexFormat );
    }
}
//==============================================================================
//
// piLibs 2014-2017 - http://www.iquilezles.org/www/material/piLibs/piLibs.htm
//
// piRenderer
//
//==============================================================================

function piRenderer()
{
    // private members

    var mGL = null;
    var mBindedShader = null;
    var mIs20 = false;
    var mFloat32Textures;
    var mFloat32Filter;
    var mFloat16Textures;
    var mDrawBuffers;
    var mDepthTextures;
    var mDerivatives;
    var mFloat16Filter;
    var mShaderTextureLOD;
    var mAnisotropic;
    var mRenderToFloat32F;
    var mDebugShader;
    var mAsynchCompile;

    var mVBO_Quad = null;
    var mVBO_Tri = null;
    var mVBO_CubePosNor = null;
    var mVBO_CubePos = null;
    var mShaderHeader = ["",""];
    var mShaderHeaderLines = [0,0];

    // public members
    var me = {};

    me.CLEAR      = { Color: 1, Zbuffer : 2, Stencil : 4 };
    me.TEXFMT     = { C4I8 : 0, C1I8 : 1, C1F16 : 2, C4F16 : 3, C1F32 : 4, C4F32 : 5, Z16 : 6, Z24 : 7, Z32 : 8, C3F32:9 };
    me.TEXWRP     = { CLAMP : 0, REPEAT : 1 };
    me.BUFTYPE    = { STATIC : 0, DYNAMIC : 1 };
    me.PRIMTYPE   = { POINTS : 0, LINES : 1, LINE_LOOP : 2, LINE_STRIP : 3, TRIANGLES : 4, TRIANGLE_STRIP : 5 };
    me.RENDSTGATE = { WIREFRAME : 0, FRONT_FACE : 1, CULL_FACE : 2, DEPTH_TEST : 3, ALPHA_TO_COVERAGE : 4 };
    me.TEXTYPE    = { T2D : 0, T3D : 1, CUBEMAP : 2 };
    me.FILTER     = { NONE : 0, LINEAR : 1, MIPMAP : 2, NONE_MIPMAP : 3 };
    me.TYPE       = { UINT8 : 0, UINT16 : 1, UINT32 : 2, FLOAT16: 3, FLOAT32 : 4, FLOAT64: 5 };

    // private functions

    var iFormatPI2GL = function( format )
    {
        if( mIs20 )
        {
             if (format === me.TEXFMT.C4I8)  return { mGLFormat: mGL.RGBA8,           mGLExternal: mGL.RGBA,             mGLType: mGL.UNSIGNED_BYTE }
        else if (format === me.TEXFMT.C1I8)  return { mGLFormat: mGL.R8,              mGLExternal: mGL.RED,              mGLType: mGL.UNSIGNED_BYTE }
        else if (format === me.TEXFMT.C1F16) return { mGLFormat: mGL.R16F,            mGLExternal: mGL.RED,              mGLType: mGL.FLOAT }
        else if (format === me.TEXFMT.C4F16) return { mGLFormat: mGL.RGBA16F,         mGLExternal: mGL.RGBA,             mGLType: mGL.FLOAT }
        else if (format === me.TEXFMT.C1F32) return { mGLFormat: mGL.R32F,            mGLExternal: mGL.RED,              mGLType: mGL.FLOAT }
        else if (format === me.TEXFMT.C4F32) return { mGLFormat: mGL.RGBA32F,         mGLExternal: mGL.RGBA,             mGLType: mGL.FLOAT }
        else if (format === me.TEXFMT.C3F32) return { mGLFormat: mGL.RGB32F,          mGLExternal: mGL.RGB,              mGLType: mGL.FLOAT }
        else if (format === me.TEXFMT.Z16)   return { mGLFormat: mGL.DEPTH_COMPONENT16, mGLExternal: mGL.DEPTH_COMPONENT,  mGLType: mGL.UNSIGNED_SHORT }
        else if (format === me.TEXFMT.Z24)   return { mGLFormat: mGL.DEPTH_COMPONENT24, mGLExternal: mGL.DEPTH_COMPONENT,  mGLType: mGL.UNSIGNED_SHORT }
        else if (format === me.TEXFMT.Z32)   return { mGLFormat: mGL.DEPTH_COMPONENT32F, mGLExternal: mGL.DEPTH_COMPONENT,  mGLType: mGL.UNSIGNED_SHORT }
        }
        else
        {
             if (format === me.TEXFMT.C4I8)  return { mGLFormat: mGL.RGBA,            mGLExternal: mGL.RGBA,            mGLType: mGL.UNSIGNED_BYTE }
        else if (format === me.TEXFMT.C1I8)  return { mGLFormat: mGL.LUMINANCE,       mGLExternal: mGL.LUMINANCE,       mGLType: mGL.UNSIGNED_BYTE }
        else if (format === me.TEXFMT.C1F16) return { mGLFormat: mGL.LUMINANCE,       mGLExternal: mGL.LUMINANCE,       mGLType: mGL.FLOAT }
        else if (format === me.TEXFMT.C4F16) return { mGLFormat: mGL.RGBA,            mGLExternal: mGL.RGBA,            mGLType: mGL.FLOAT }
        else if (format === me.TEXFMT.C1F32) return { mGLFormat: mGL.LUMINANCE,       mGLExternal: mGL.RED,             mGLType: mGL.FLOAT }
        else if (format === me.TEXFMT.C4F32) return { mGLFormat: mGL.RGBA,            mGLExternal: mGL.RGBA,            mGLType: mGL.FLOAT }
        else if (format === me.TEXFMT.Z16)   return { mGLFormat: mGL.DEPTH_COMPONENT, mGLExternal: mGL.DEPTH_COMPONENT, mGLType: mGL.UNSIGNED_SHORT }
        }

        return null;
     }

    // public functions

    me.Initialize = function( gl )
                    {
                        mGL = gl;

                        mIs20 = !(gl instanceof WebGLRenderingContext);

                        if( mIs20 )
                        {
                            mFloat32Textures  = true;
                            mFloat32Filter    = mGL.getExtension( 'OES_texture_float_linear');
                            mFloat16Textures  = true;
                            mFloat16Filter    = mGL.getExtension( 'OES_texture_half_float_linear' );
                            mDerivatives      = true;
                            mDrawBuffers      = true;
                            mDepthTextures    = true;
                            mShaderTextureLOD = true;
                            mAnisotropic = mGL.getExtension( 'EXT_texture_filter_anisotropic' );
                            mRenderToFloat32F = mGL.getExtension( 'EXT_color_buffer_float');
                            mDebugShader = mGL.getExtension('WEBGL_debug_shaders');
                            mAsynchCompile = mGL.getExtension('KHR_parallel_shader_compile');

							mGL.hint( mGL.FRAGMENT_SHADER_DERIVATIVE_HINT, mGL.NICEST);
                        }
                        else
                        {
                            mFloat32Textures  = mGL.getExtension( 'OES_texture_float' );
                            mFloat32Filter    = mGL.getExtension( 'OES_texture_float_linear');
                            mFloat16Textures  = mGL.getExtension( 'OES_texture_half_float' );
                            mFloat16Filter    = mGL.getExtension( 'OES_texture_half_float_linear' );
                            mDerivatives      = mGL.getExtension( 'OES_standard_derivatives' );
                            mDrawBuffers      = mGL.getExtension( 'WEBGL_draw_buffers' );
                            mDepthTextures    = mGL.getExtension( 'WEBGL_depth_texture' );
                            mShaderTextureLOD = mGL.getExtension( 'EXT_shader_texture_lod' );
                            mAnisotropic      = mGL.getExtension( 'EXT_texture_filter_anisotropic' );
                            mRenderToFloat32F = mFloat32Textures;
                            mDebugShader      = null;
                            mAsynchCompile    = null;
							
							if( mDerivatives !== null) mGL.hint( mDerivatives.FRAGMENT_SHADER_DERIVATIVE_HINT_OES, mGL.NICEST);
                        }
                        
                        
                        var maxTexSize = mGL.getParameter( mGL.MAX_TEXTURE_SIZE );
                        var maxCubeSize = mGL.getParameter( mGL.MAX_CUBE_MAP_TEXTURE_SIZE );
                        var maxRenderbufferSize = mGL.getParameter( mGL.MAX_RENDERBUFFER_SIZE );
                        var extensions = mGL.getSupportedExtensions();
                        var textureUnits = mGL.getParameter( mGL.MAX_TEXTURE_IMAGE_UNITS );
                        console.log("WebGL (2.0=" + mIs20 + "):" +
                                    " Asynch Compile: "  + ((mAsynchCompile !==null) ? "yes" : "no") +
                                    ", Textures: F32 ["   + ((mFloat32Textures !==null) ? "yes" : "no") +
                                    "], F16 ["   + ((mFloat16Textures !==null) ? "yes" : "no") +
                                    "], Depth [" + ((mDepthTextures   !==null) ? "yes" : "no") +
                                    "], LOD ["    + ((mShaderTextureLOD!==null) ? "yes" : "no") +
                                    "], Aniso ["   + ((mAnisotropic     !==null) ? "yes" : "no") +
                                    "], Units [" + textureUnits +
                                    "], Max Size [" + maxTexSize +
                                    "], Cube Max Size [" + maxCubeSize +
                                    "], Targets: MRT ["            + ((mDrawBuffers     !==null) ? "yes" : "no") +
                                    "], F32 ["     + ((mRenderToFloat32F!==null) ? "yes" : "no") +
                                    "], Max Size [" + maxRenderbufferSize + "]");

                        // create a 2D quad Vertex Buffer
                        var vertices = new Float32Array( [ -1.0, -1.0,   1.0, -1.0,    -1.0,  1.0,     1.0, -1.0,    1.0,  1.0,    -1.0,  1.0] );
                        mVBO_Quad = mGL.createBuffer();
                        mGL.bindBuffer( mGL.ARRAY_BUFFER, mVBO_Quad );
                        mGL.bufferData( mGL.ARRAY_BUFFER, vertices, mGL.STATIC_DRAW );
                        mGL.bindBuffer( mGL.ARRAY_BUFFER, null );

                        // create a 2D triangle Vertex Buffer
                        mVBO_Tri = mGL.createBuffer();
                        mGL.bindBuffer( mGL.ARRAY_BUFFER, mVBO_Tri );
                        mGL.bufferData( mGL.ARRAY_BUFFER, new Float32Array( [ -1.0, -1.0,   3.0, -1.0,    -1.0,  3.0] ), mGL.STATIC_DRAW );
                        mGL.bindBuffer( mGL.ARRAY_BUFFER, null );

                        // create a 3D cube Vertex Buffer
                        mVBO_CubePosNor = mGL.createBuffer();
                        mGL.bindBuffer( mGL.ARRAY_BUFFER, mVBO_CubePosNor );
                        mGL.bufferData( mGL.ARRAY_BUFFER, new Float32Array( [ -1.0, -1.0, -1.0,  -1.0,  0.0,  0.0,
                                                                              -1.0, -1.0,  1.0,  -1.0,  0.0,  0.0,
                                                                              -1.0,  1.0, -1.0,  -1.0,  0.0,  0.0,
                                                                              -1.0,  1.0,  1.0,  -1.0,  0.0,  0.0,
                                                                               1.0,  1.0, -1.0,   1.0,  0.0,  0.0,
                                                                               1.0,  1.0,  1.0,   1.0,  0.0,  0.0,
                                                                               1.0, -1.0, -1.0,   1.0,  0.0,  0.0,
                                                                               1.0, -1.0,  1.0,   1.0,  0.0,  0.0,
                                                                               1.0,  1.0,  1.0,   0.0,  1.0,  0.0,
                                                                               1.0,  1.0, -1.0,   0.0,  1.0,  0.0,
                                                                              -1.0,  1.0,  1.0,   0.0,  1.0,  0.0,
                                                                              -1.0,  1.0, -1.0,   0.0,  1.0,  0.0,
                                                                               1.0, -1.0, -1.0,   0.0, -1.0,  0.0,
                                                                               1.0, -1.0,  1.0,   0.0, -1.0,  0.0,
                                                                              -1.0, -1.0, -1.0,   0.0, -1.0,  0.0,
                                                                              -1.0, -1.0,  1.0,   0.0, -1.0,  0.0,
                                                                              -1.0,  1.0,  1.0,   0.0,  0.0,  1.0,
                                                                              -1.0, -1.0,  1.0,   0.0,  0.0,  1.0,
                                                                               1.0,  1.0,  1.0,   0.0,  0.0,  1.0,
                                                                               1.0, -1.0,  1.0,   0.0,  0.0,  1.0,
                                                                              -1.0, -1.0, -1.0,   0.0,  0.0, -1.0,
                                                                              -1.0,  1.0, -1.0,   0.0,  0.0, -1.0,
                                                                               1.0, -1.0, -1.0,   0.0,  0.0, -1.0,
                                                                               1.0,  1.0, -1.0,   0.0,  0.0, -1.0 ] ), mGL.STATIC_DRAW );
                        mGL.bindBuffer( mGL.ARRAY_BUFFER, null );

                        // create a 3D cube Vertex Buffer
                        mVBO_CubePos = mGL.createBuffer();
                        mGL.bindBuffer( mGL.ARRAY_BUFFER, mVBO_CubePos );
                        mGL.bufferData( mGL.ARRAY_BUFFER, new Float32Array( [ -1.0, -1.0, -1.0,
                                                                              -1.0, -1.0,  1.0,
                                                                              -1.0,  1.0, -1.0,
                                                                              -1.0,  1.0,  1.0,
                                                                               1.0,  1.0, -1.0,
                                                                               1.0,  1.0,  1.0,
                                                                               1.0, -1.0, -1.0,
                                                                               1.0, -1.0,  1.0,
                                                                               1.0,  1.0,  1.0,
                                                                               1.0,  1.0, -1.0,
                                                                              -1.0,  1.0,  1.0,
                                                                              -1.0,  1.0, -1.0,
                                                                               1.0, -1.0, -1.0,
                                                                               1.0, -1.0,  1.0,
                                                                              -1.0, -1.0, -1.0,
                                                                              -1.0, -1.0,  1.0,
                                                                              -1.0,  1.0,  1.0,
                                                                              -1.0, -1.0,  1.0,
                                                                               1.0,  1.0,  1.0,
                                                                               1.0, -1.0,  1.0,
                                                                              -1.0, -1.0, -1.0,
                                                                              -1.0,  1.0, -1.0,
                                                                               1.0, -1.0, -1.0,
                                                                               1.0,  1.0, -1.0 ] ), mGL.STATIC_DRAW );
                        mGL.bindBuffer( mGL.ARRAY_BUFFER, null );

                        //-------------------------------------------------------------------

                        mShaderHeader[0] = "";
                        mShaderHeaderLines[0] = 0;
                        if( mIs20 ) 
                        { 
                            mShaderHeader[0] += "#version 300 es\n" +
                                                "#ifdef GL_ES\n"+
                                                "precision highp float;\n" +
                                                "precision highp int;\n"+
                                                "precision mediump sampler3D;\n"+
                                                "#endif\n"; 
                            mShaderHeaderLines[0] += 6;
                        }
                        else
                        {
                            mShaderHeader[0] += "#ifdef GL_ES\n"+
                                                "precision highp float;\n" +
                                                "precision highp int;\n"+
                                                "#endif\n"+
                                                "float round( float x ) { return floor(x+0.5); }\n"+
                                                "vec2 round(vec2 x) { return floor(x + 0.5); }\n"+
                                                "vec3 round(vec3 x) { return floor(x + 0.5); }\n"+
                                                "vec4 round(vec4 x) { return floor(x + 0.5); }\n"+
                                                "float trunc( float x, float n ) { return floor(x*n)/n; }\n"+
                                                "mat3 transpose(mat3 m) { return mat3(m[0].x, m[1].x, m[2].x, m[0].y, m[1].y, m[2].y, m[0].z, m[1].z, m[2].z); }\n"+
                                                "float determinant( in mat2 m ) { return m[0][0]*m[1][1] - m[0][1]*m[1][0]; }\n"+
                                                "float determinant( mat4 m ) { float b00 = m[0][0] * m[1][1] - m[0][1] * m[1][0], b01 = m[0][0] * m[1][2] - m[0][2] * m[1][0], b02 = m[0][0] * m[1][3] - m[0][3] * m[1][0], b03 = m[0][1] * m[1][2] - m[0][2] * m[1][1], b04 = m[0][1] * m[1][3] - m[0][3] * m[1][1], b05 = m[0][2] * m[1][3] - m[0][3] * m[1][2], b06 = m[2][0] * m[3][1] - m[2][1] * m[3][0], b07 = m[2][0] * m[3][2] - m[2][2] * m[3][0], b08 = m[2][0] * m[3][3] - m[2][3] * m[3][0], b09 = m[2][1] * m[3][2] - m[2][2] * m[3][1], b10 = m[2][1] * m[3][3] - m[2][3] * m[3][1], b11 = m[2][2] * m[3][3] - m[2][3] * m[3][2];  return b00 * b11 - b01 * b10 + b02 * b09 + b03 * b08 - b04 * b07 + b05 * b06;}\n"+
                                                "mat2 inverse(mat2 m) { float det = determinant(m); return mat2(m[1][1], -m[0][1], -m[1][0], m[0][0]) / det; }\n"+
                                                "mat4 inverse(mat4 m ) { float inv0 = m[1].y*m[2].z*m[3].w - m[1].y*m[2].w*m[3].z - m[2].y*m[1].z*m[3].w + m[2].y*m[1].w*m[3].z + m[3].y*m[1].z*m[2].w - m[3].y*m[1].w*m[2].z; float inv4 = -m[1].x*m[2].z*m[3].w + m[1].x*m[2].w*m[3].z + m[2].x*m[1].z*m[3].w - m[2].x*m[1].w*m[3].z - m[3].x*m[1].z*m[2].w + m[3].x*m[1].w*m[2].z; float inv8 = m[1].x*m[2].y*m[3].w - m[1].x*m[2].w*m[3].y - m[2].x  * m[1].y * m[3].w + m[2].x  * m[1].w * m[3].y + m[3].x * m[1].y * m[2].w - m[3].x * m[1].w * m[2].y; float inv12 = -m[1].x  * m[2].y * m[3].z + m[1].x  * m[2].z * m[3].y +m[2].x  * m[1].y * m[3].z - m[2].x  * m[1].z * m[3].y - m[3].x * m[1].y * m[2].z + m[3].x * m[1].z * m[2].y; float inv1 = -m[0].y*m[2].z * m[3].w + m[0].y*m[2].w * m[3].z + m[2].y  * m[0].z * m[3].w - m[2].y  * m[0].w * m[3].z - m[3].y * m[0].z * m[2].w + m[3].y * m[0].w * m[2].z; float inv5 = m[0].x  * m[2].z * m[3].w - m[0].x  * m[2].w * m[3].z - m[2].x  * m[0].z * m[3].w + m[2].x  * m[0].w * m[3].z + m[3].x * m[0].z * m[2].w - m[3].x * m[0].w * m[2].z; float inv9 = -m[0].x  * m[2].y * m[3].w +  m[0].x  * m[2].w * m[3].y + m[2].x  * m[0].y * m[3].w - m[2].x  * m[0].w * m[3].y - m[3].x * m[0].y * m[2].w + m[3].x * m[0].w * m[2].y; float inv13 = m[0].x  * m[2].y * m[3].z - m[0].x  * m[2].z * m[3].y - m[2].x  * m[0].y * m[3].z + m[2].x  * m[0].z * m[3].y + m[3].x * m[0].y * m[2].z - m[3].x * m[0].z * m[2].y; float inv2 = m[0].y  * m[1].z * m[3].w - m[0].y  * m[1].w * m[3].z - m[1].y  * m[0].z * m[3].w + m[1].y  * m[0].w * m[3].z + m[3].y * m[0].z * m[1].w - m[3].y * m[0].w * m[1].z; float inv6 = -m[0].x  * m[1].z * m[3].w + m[0].x  * m[1].w * m[3].z + m[1].x  * m[0].z * m[3].w - m[1].x  * m[0].w * m[3].z - m[3].x * m[0].z * m[1].w + m[3].x * m[0].w * m[1].z; float inv10 = m[0].x  * m[1].y * m[3].w - m[0].x  * m[1].w * m[3].y - m[1].x  * m[0].y * m[3].w + m[1].x  * m[0].w * m[3].y + m[3].x * m[0].y * m[1].w - m[3].x * m[0].w * m[1].y; float inv14 = -m[0].x  * m[1].y * m[3].z + m[0].x  * m[1].z * m[3].y + m[1].x  * m[0].y * m[3].z - m[1].x  * m[0].z * m[3].y - m[3].x * m[0].y * m[1].z + m[3].x * m[0].z * m[1].y; float inv3 = -m[0].y * m[1].z * m[2].w + m[0].y * m[1].w * m[2].z + m[1].y * m[0].z * m[2].w - m[1].y * m[0].w * m[2].z - m[2].y * m[0].z * m[1].w + m[2].y * m[0].w * m[1].z; float inv7 = m[0].x * m[1].z * m[2].w - m[0].x * m[1].w * m[2].z - m[1].x * m[0].z * m[2].w + m[1].x * m[0].w * m[2].z + m[2].x * m[0].z * m[1].w - m[2].x * m[0].w * m[1].z; float inv11 = -m[0].x * m[1].y * m[2].w + m[0].x * m[1].w * m[2].y + m[1].x * m[0].y * m[2].w - m[1].x * m[0].w * m[2].y - m[2].x * m[0].y * m[1].w + m[2].x * m[0].w * m[1].y; float inv15 = m[0].x * m[1].y * m[2].z - m[0].x * m[1].z * m[2].y - m[1].x * m[0].y * m[2].z + m[1].x * m[0].z * m[2].y + m[2].x * m[0].y * m[1].z - m[2].x * m[0].z * m[1].y; float det = m[0].x * inv0 + m[0].y * inv4 + m[0].z * inv8 + m[0].w * inv12; det = 1.0 / det; return det*mat4( inv0, inv1, inv2, inv3,inv4, inv5, inv6, inv7,inv8, inv9, inv10, inv11,inv12, inv13, inv14, inv15);}\n"+                                                
                                                "float sinh(float x)  { return (exp(x)-exp(-x))/2.; }\n"+
                                                "float cosh(float x)  { return (exp(x)+exp(-x))/2.; }\n"+
                                                "float tanh(float x)  { return sinh(x)/cosh(x); }\n"+
                                                "float coth(float x)  { return cosh(x)/sinh(x); }\n"+
                                                "float sech(float x)  { return 1./cosh(x); }\n"+
                                                "float csch(float x)  { return 1./sinh(x); }\n"+
                                                "float asinh(float x) { return    log(x+sqrt(x*x+1.)); }\n"+
                                                "float acosh(float x) { return    log(x+sqrt(x*x-1.)); }\n"+
                                                "float atanh(float x) { return .5*log((1.+x)/(1.-x)); }\n"+
                                                "float acoth(float x) { return .5*log((x+1.)/(x-1.)); }\n"+
                                                "float asech(float x) { return    log((1.+sqrt(1.-x*x))/x); }\n"+
                                                "float acsch(float x) { return    log((1.+sqrt(1.+x*x))/x); }\n";
                            mShaderHeaderLines[0] += 26;
                        }

                        //-------------------------------------------------------

                        mShaderHeader[1] = "";
                        mShaderHeaderLines[1] = 0;
                        if( mIs20 ) 
                        { 
                            mShaderHeader[1] += "#version 300 es\n"+
                                                "#ifdef GL_ES\n"+
                                                "precision highp float;\n"+
                                                "precision highp int;\n"+
                                                "precision mediump sampler3D;\n"+
                                                "#endif\n"; 
                            mShaderHeaderLines[1] += 6;
                        }
                        else
                        {
                            if( mDerivatives ) { mShaderHeader[1] += "#ifdef GL_OES_standard_derivatives\n#extension GL_OES_standard_derivatives : enable\n#endif\n"; mShaderHeaderLines[1]+=3; }
                            if( mShaderTextureLOD  ) { mShaderHeader[1] += "#extension GL_EXT_shader_texture_lod : enable\n"; mShaderHeaderLines[1]++; }
                            mShaderHeader[1] += "#ifdef GL_ES\n"+
                                                "precision highp float;\n"+
                                                "precision highp int;\n"+
                                                "#endif\n"+ 
                                                "vec4 texture(     sampler2D   s, vec2 c)                   { return texture2D(s,c); }\n"+
                                                "vec4 texture(     sampler2D   s, vec2 c, float b)          { return texture2D(s,c,b); }\n"+
                                                "vec4 texture(     samplerCube s, vec3 c )                  { return textureCube(s,c); }\n"+
                                                "vec4 texture(     samplerCube s, vec3 c, float b)          { return textureCube(s,c,b); }\n"+
                                                "float round( float x ) { return floor(x+0.5); }\n"+
                                                "vec2 round(vec2 x) { return floor(x + 0.5); }\n"+
                                                "vec3 round(vec3 x) { return floor(x + 0.5); }\n"+
                                                "vec4 round(vec4 x) { return floor(x + 0.5); }\n"+
                                                "float trunc( float x, float n ) { return floor(x*n)/n; }\n"+
                                                "mat3 transpose(mat3 m) { return mat3(m[0].x, m[1].x, m[2].x, m[0].y, m[1].y, m[2].y, m[0].z, m[1].z, m[2].z); }\n"+
                                                "float determinant( in mat2 m ) { return m[0][0]*m[1][1] - m[0][1]*m[1][0]; }\n"+
                                                "float determinant( mat4 m ) { float b00 = m[0][0] * m[1][1] - m[0][1] * m[1][0], b01 = m[0][0] * m[1][2] - m[0][2] * m[1][0], b02 = m[0][0] * m[1][3] - m[0][3] * m[1][0], b03 = m[0][1] * m[1][2] - m[0][2] * m[1][1], b04 = m[0][1] * m[1][3] - m[0][3] * m[1][1], b05 = m[0][2] * m[1][3] - m[0][3] * m[1][2], b06 = m[2][0] * m[3][1] - m[2][1] * m[3][0], b07 = m[2][0] * m[3][2] - m[2][2] * m[3][0], b08 = m[2][0] * m[3][3] - m[2][3] * m[3][0], b09 = m[2][1] * m[3][2] - m[2][2] * m[3][1], b10 = m[2][1] * m[3][3] - m[2][3] * m[3][1], b11 = m[2][2] * m[3][3] - m[2][3] * m[3][2];  return b00 * b11 - b01 * b10 + b02 * b09 + b03 * b08 - b04 * b07 + b05 * b06;}\n"+
                                                "mat2 inverse(mat2 m) { float det = determinant(m); return mat2(m[1][1], -m[0][1], -m[1][0], m[0][0]) / det; }\n"+
                                                "mat4 inverse(mat4 m ) { float inv0 = m[1].y*m[2].z*m[3].w - m[1].y*m[2].w*m[3].z - m[2].y*m[1].z*m[3].w + m[2].y*m[1].w*m[3].z + m[3].y*m[1].z*m[2].w - m[3].y*m[1].w*m[2].z; float inv4 = -m[1].x*m[2].z*m[3].w + m[1].x*m[2].w*m[3].z + m[2].x*m[1].z*m[3].w - m[2].x*m[1].w*m[3].z - m[3].x*m[1].z*m[2].w + m[3].x*m[1].w*m[2].z; float inv8 = m[1].x*m[2].y*m[3].w - m[1].x*m[2].w*m[3].y - m[2].x  * m[1].y * m[3].w + m[2].x  * m[1].w * m[3].y + m[3].x * m[1].y * m[2].w - m[3].x * m[1].w * m[2].y; float inv12 = -m[1].x  * m[2].y * m[3].z + m[1].x  * m[2].z * m[3].y +m[2].x  * m[1].y * m[3].z - m[2].x  * m[1].z * m[3].y - m[3].x * m[1].y * m[2].z + m[3].x * m[1].z * m[2].y; float inv1 = -m[0].y*m[2].z * m[3].w + m[0].y*m[2].w * m[3].z + m[2].y  * m[0].z * m[3].w - m[2].y  * m[0].w * m[3].z - m[3].y * m[0].z * m[2].w + m[3].y * m[0].w * m[2].z; float inv5 = m[0].x  * m[2].z * m[3].w - m[0].x  * m[2].w * m[3].z - m[2].x  * m[0].z * m[3].w + m[2].x  * m[0].w * m[3].z + m[3].x * m[0].z * m[2].w - m[3].x * m[0].w * m[2].z; float inv9 = -m[0].x  * m[2].y * m[3].w +  m[0].x  * m[2].w * m[3].y + m[2].x  * m[0].y * m[3].w - m[2].x  * m[0].w * m[3].y - m[3].x * m[0].y * m[2].w + m[3].x * m[0].w * m[2].y; float inv13 = m[0].x  * m[2].y * m[3].z - m[0].x  * m[2].z * m[3].y - m[2].x  * m[0].y * m[3].z + m[2].x  * m[0].z * m[3].y + m[3].x * m[0].y * m[2].z - m[3].x * m[0].z * m[2].y; float inv2 = m[0].y  * m[1].z * m[3].w - m[0].y  * m[1].w * m[3].z - m[1].y  * m[0].z * m[3].w + m[1].y  * m[0].w * m[3].z + m[3].y * m[0].z * m[1].w - m[3].y * m[0].w * m[1].z; float inv6 = -m[0].x  * m[1].z * m[3].w + m[0].x  * m[1].w * m[3].z + m[1].x  * m[0].z * m[3].w - m[1].x  * m[0].w * m[3].z - m[3].x * m[0].z * m[1].w + m[3].x * m[0].w * m[1].z; float inv10 = m[0].x  * m[1].y * m[3].w - m[0].x  * m[1].w * m[3].y - m[1].x  * m[0].y * m[3].w + m[1].x  * m[0].w * m[3].y + m[3].x * m[0].y * m[1].w - m[3].x * m[0].w * m[1].y; float inv14 = -m[0].x  * m[1].y * m[3].z + m[0].x  * m[1].z * m[3].y + m[1].x  * m[0].y * m[3].z - m[1].x  * m[0].z * m[3].y - m[3].x * m[0].y * m[1].z + m[3].x * m[0].z * m[1].y; float inv3 = -m[0].y * m[1].z * m[2].w + m[0].y * m[1].w * m[2].z + m[1].y * m[0].z * m[2].w - m[1].y * m[0].w * m[2].z - m[2].y * m[0].z * m[1].w + m[2].y * m[0].w * m[1].z; float inv7 = m[0].x * m[1].z * m[2].w - m[0].x * m[1].w * m[2].z - m[1].x * m[0].z * m[2].w + m[1].x * m[0].w * m[2].z + m[2].x * m[0].z * m[1].w - m[2].x * m[0].w * m[1].z; float inv11 = -m[0].x * m[1].y * m[2].w + m[0].x * m[1].w * m[2].y + m[1].x * m[0].y * m[2].w - m[1].x * m[0].w * m[2].y - m[2].x * m[0].y * m[1].w + m[2].x * m[0].w * m[1].y; float inv15 = m[0].x * m[1].y * m[2].z - m[0].x * m[1].z * m[2].y - m[1].x * m[0].y * m[2].z + m[1].x * m[0].z * m[2].y + m[2].x * m[0].y * m[1].z - m[2].x * m[0].z * m[1].y; float det = m[0].x * inv0 + m[0].y * inv4 + m[0].z * inv8 + m[0].w * inv12; det = 1.0 / det; return det*mat4( inv0, inv1, inv2, inv3,inv4, inv5, inv6, inv7,inv8, inv9, inv10, inv11,inv12, inv13, inv14, inv15);}\n"+
                                                "float sinh(float x)  { return (exp(x)-exp(-x))/2.; }\n"+
                                                "float cosh(float x)  { return (exp(x)+exp(-x))/2.; }\n"+
                                                "float tanh(float x)  { return sinh(x)/cosh(x); }\n"+
                                                "float coth(float x)  { return cosh(x)/sinh(x); }\n"+
                                                "float sech(float x)  { return 1./cosh(x); }\n"+
                                                "float csch(float x)  { return 1./sinh(x); }\n"+
                                                "float asinh(float x) { return    log(x+sqrt(x*x+1.)); }\n"+
                                                "float acosh(float x) { return    log(x+sqrt(x*x-1.)); }\n"+
                                                "float atanh(float x) { return .5*log((1.+x)/(1.-x)); }\n"+
                                                "float acoth(float x) { return .5*log((x+1.)/(x-1.)); }\n"+
                                                "float asech(float x) { return    log((1.+sqrt(1.-x*x))/x); }\n"+
                                                "float acsch(float x) { return    log((1.+sqrt(1.+x*x))/x); }\n";
                            mShaderHeaderLines[1] += 30;
                            if( mShaderTextureLOD )
                            {
                            mShaderHeader[1] += "vec4 textureLod(  sampler2D   s, vec2 c, float b)          { return texture2DLodEXT(s,c,b); }\n";
                            mShaderHeader[1] += "vec4 textureGrad( sampler2D   s, vec2 c, vec2 dx, vec2 dy) { return texture2DGradEXT(s,c,dx,dy); }\n";
                            mShaderHeaderLines[1] += 2;

                            //mShaderHeader[1] += "vec4 texelFetch( sampler2D s, ivec2 c, int l) { return texture2DLodEXT(s,(vec2(c)+0.5)/vec2(800,450),float(l)); }\n";
                            //mShaderHeaderLines[1] += 1;
                            }
                        }

                        return true;
                    };

        me.GetCaps =    function ()
                        {   
                            return { mIsGL20 : mIs20,
                                     mFloat32Textures: mFloat32Textures != null,
                                     mFloat16Textures: mFloat16Textures != null,
                                     mDrawBuffers: mDrawBuffers != null,
                                     mDepthTextures: mDepthTextures != null,
                                     mDerivatives: mDerivatives != null,
                                     mShaderTextureLOD: mShaderTextureLOD != null };
                        };

        me.GetShaderHeaderLines = function (shaderType)
                        {   
                            return mShaderHeaderLines[shaderType];
                        };

        me.CheckErrors = function()
                         {
                                var error = mGL.getError();
                                if( error != mGL.NO_ERROR ) 
                                { 
                                    for( var prop in mGL ) 
                                    {
                                        if( typeof mGL[prop] == 'number' ) 
                                        {
                                            if( mGL[prop] == error )
                                            {
                                                console.log( "GL Error " + error + ": " + prop );
                                                break;
                                            }
                                        }
                                    }
                                }
                         };

        me.Clear =  function( flags, ccolor, cdepth, cstencil )
                    {
                        var mode = 0;
                        if( flags & 1 ) { mode |= mGL.COLOR_BUFFER_BIT;   mGL.clearColor( ccolor[0], ccolor[1], ccolor[2], ccolor[3] ); }
                        if( flags & 2 ) { mode |= mGL.DEPTH_BUFFER_BIT;   mGL.clearDepth( cdepth ); }
                        if( flags & 4 ) { mode |= mGL.STENCIL_BUFFER_BIT; mGL.clearStencil( cstencil ); }
                        mGL.clear( mode );
                    };


        me.CreateTexture = function ( type, xres, yres, format, filter, wrap, buffer)
                           {
                                if( mGL===null ) return null;

                                var id = mGL.createTexture();

                                var glFoTy = iFormatPI2GL( format );
                                var glWrap = mGL.REPEAT; if (wrap === me.TEXWRP.CLAMP) glWrap = mGL.CLAMP_TO_EDGE;

                                if( type===me.TEXTYPE.T2D )
                                {
                                    mGL.bindTexture( mGL.TEXTURE_2D, id );
//if( buffer==null )
    //mGL.texStorage2D(mGL.TEXTURE_2D, 0, glFoTy.mGLFormat, xres, yres);
//else
                                    mGL.texImage2D( mGL.TEXTURE_2D, 0, glFoTy.mGLFormat, xres, yres, 0, glFoTy.mGLExternal, glFoTy.mGLType, buffer );
                                    mGL.texParameteri( mGL.TEXTURE_2D, mGL.TEXTURE_WRAP_S, glWrap );
                                    mGL.texParameteri( mGL.TEXTURE_2D, mGL.TEXTURE_WRAP_T, glWrap );

                                    if (filter === me.FILTER.NONE)
                                    {
                                        mGL.texParameteri(mGL.TEXTURE_2D, mGL.TEXTURE_MAG_FILTER, mGL.NEAREST);
                                        mGL.texParameteri(mGL.TEXTURE_2D, mGL.TEXTURE_MIN_FILTER, mGL.NEAREST);
                                    }
                                    else if (filter === me.FILTER.LINEAR)
                                    {
                                        mGL.texParameteri(mGL.TEXTURE_2D, mGL.TEXTURE_MAG_FILTER, mGL.LINEAR);
                                        mGL.texParameteri(mGL.TEXTURE_2D, mGL.TEXTURE_MIN_FILTER, mGL.LINEAR);
                                    }
                                    else if (filter === me.FILTER.MIPMAP)
                                    {
                                        mGL.texParameteri(mGL.TEXTURE_2D, mGL.TEXTURE_MAG_FILTER, mGL.LINEAR);
                                        mGL.texParameteri(mGL.TEXTURE_2D, mGL.TEXTURE_MIN_FILTER, mGL.LINEAR_MIPMAP_LINEAR);
                                        mGL.generateMipmap(mGL.TEXTURE_2D);
                                    }
                                    else
                                    {
                                        mGL.texParameteri(mGL.TEXTURE_2D, mGL.TEXTURE_MAG_FILTER, mGL.NEAREST);
                                        mGL.texParameteri(mGL.TEXTURE_2D, mGL.TEXTURE_MIN_FILTER, mGL.NEAREST_MIPMAP_LINEAR);
                                        mGL.generateMipmap(mGL.TEXTURE_2D);
                                    }

                                    mGL.bindTexture( mGL.TEXTURE_2D, null );
                                }
                                else if( type===me.TEXTYPE.T3D )
                                {
                                    if( mIs20 )
                                    {
                                        mGL.bindTexture( mGL.TEXTURE_3D, id );
                                        mGL.texParameteri(mGL.TEXTURE_3D, mGL.TEXTURE_BASE_LEVEL, 0);
                                        mGL.texParameteri(mGL.TEXTURE_3D, mGL.TEXTURE_MAX_LEVEL, Math.log2(xres));
                                        if (filter === me.FILTER.NONE)
                                        {
                                            mGL.texParameteri(mGL.TEXTURE_3D, mGL.TEXTURE_MAG_FILTER, mGL.NEAREST);
                                            mGL.texParameteri(mGL.TEXTURE_3D, mGL.TEXTURE_MIN_FILTER, mGL.NEAREST);
                                        }
                                        else if (filter === me.FILTER.LINEAR)
                                        {
                                            mGL.texParameteri(mGL.TEXTURE_3D, mGL.TEXTURE_MAG_FILTER, mGL.LINEAR);
                                            mGL.texParameteri(mGL.TEXTURE_3D, mGL.TEXTURE_MIN_FILTER, mGL.LINEAR);
                                        }
                                        else if (filter === me.FILTER.MIPMAP)
                                        {
                                            mGL.texParameteri(mGL.TEXTURE_3D, mGL.TEXTURE_MAG_FILTER, mGL.LINEAR);
                                            mGL.texParameteri(mGL.TEXTURE_3D, mGL.TEXTURE_MIN_FILTER, mGL.LINEAR_MIPMAP_LINEAR);
                                        }
                                        else
                                        {
                                            mGL.texParameteri(mGL.TEXTURE_3D, mGL.TEXTURE_MAG_FILTER, mGL.NEAREST);
                                            mGL.texParameteri(mGL.TEXTURE_3D, mGL.TEXTURE_MIN_FILTER, mGL.NEAREST_MIPMAP_LINEAR);
                                            mGL.generateMipmap(mGL.TEXTURE_3D);
                                        }
                                        mGL.texImage3D( mGL.TEXTURE_3D, 0, glFoTy.mGLFormat, xres, yres, yres, 0, glFoTy.mGLExternal, glFoTy.mGLType, buffer );

                                        mGL.texParameteri( mGL.TEXTURE_3D, mGL.TEXTURE_WRAP_R, glWrap );
                                        mGL.texParameteri( mGL.TEXTURE_3D, mGL.TEXTURE_WRAP_S, glWrap );
                                        mGL.texParameteri( mGL.TEXTURE_3D, mGL.TEXTURE_WRAP_T, glWrap );

                                        if (filter === me.FILTER.MIPMAP)
                                            mGL.generateMipmap( mGL.TEXTURE_3D );
                                        mGL.bindTexture( mGL.TEXTURE_3D, null );
                                    }
                                    else 
                                    {
                                        return null;
                                    }
                                }
                                else 
                                {
                                    mGL.bindTexture( mGL.TEXTURE_CUBE_MAP, id );

                                    // this works great if we know the number of required mipmaps in advance (1, or other)
                                   //mGL.texStorage2D( mGL.TEXTURE_CUBE_MAP, 1, glFoTy.mGLFormat, xres, yres );

                                    mGL.texImage2D( mGL.TEXTURE_CUBE_MAP_POSITIVE_X, 0, glFoTy.mGLFormat, xres, yres, 0, glFoTy.mGLExternal, glFoTy.mGLType, buffer );
                                    mGL.texImage2D( mGL.TEXTURE_CUBE_MAP_NEGATIVE_X, 0, glFoTy.mGLFormat, xres, yres, 0, glFoTy.mGLExternal, glFoTy.mGLType, buffer );
                                    mGL.texImage2D( mGL.TEXTURE_CUBE_MAP_POSITIVE_Y, 0, glFoTy.mGLFormat, xres, yres, 0, glFoTy.mGLExternal, glFoTy.mGLType, buffer );
                                    mGL.texImage2D( mGL.TEXTURE_CUBE_MAP_NEGATIVE_Y, 0, glFoTy.mGLFormat, xres, yres, 0, glFoTy.mGLExternal, glFoTy.mGLType, buffer );
                                    mGL.texImage2D( mGL.TEXTURE_CUBE_MAP_POSITIVE_Z, 0, glFoTy.mGLFormat, xres, yres, 0, glFoTy.mGLExternal, glFoTy.mGLType, buffer );
                                    mGL.texImage2D( mGL.TEXTURE_CUBE_MAP_NEGATIVE_Z, 0, glFoTy.mGLFormat, xres, yres, 0, glFoTy.mGLExternal, glFoTy.mGLType, buffer );

                                    if( filter === me.FILTER.NONE)
                                    {
                                        mGL.texParameteri(mGL.TEXTURE_CUBE_MAP, mGL.TEXTURE_MAG_FILTER, mGL.NEAREST);
                                        mGL.texParameteri(mGL.TEXTURE_CUBE_MAP, mGL.TEXTURE_MIN_FILTER, mGL.NEAREST);
                                    }
                                    else if (filter === me.FILTER.LINEAR)
                                    {
                                        mGL.texParameteri( mGL.TEXTURE_CUBE_MAP, mGL.TEXTURE_MAG_FILTER, mGL.LINEAR );
                                        mGL.texParameteri( mGL.TEXTURE_CUBE_MAP, mGL.TEXTURE_MIN_FILTER, mGL.LINEAR );
                                    }
                                    else if (filter === me.FILTER.MIPMAP)
                                    {
                                        mGL.texParameteri(mGL.TEXTURE_CUBE_MAP, mGL.TEXTURE_MAG_FILTER, mGL.LINEAR);
                                        mGL.texParameteri(mGL.TEXTURE_CUBE_MAP, mGL.TEXTURE_MIN_FILTER, mGL.LINEAR_MIPMAP_LINEAR);
                                    }

                                    if (filter === me.FILTER.MIPMAP)
                                        mGL.generateMipmap( mGL.TEXTURE_CUBE_MAP );

                                    mGL.bindTexture( mGL.TEXTURE_CUBE_MAP, null );
                                }
                        return { mObjectID: id, mXres: xres, mYres: yres, mFormat: format, mType: type, mFilter: filter, mWrap: wrap, mVFlip:false };
                        };

        me.CreateTextureFromImage = function ( type, image, format, filter, wrap, flipY) 
                                {
                                    if( mGL===null ) return null;

                                    var id = mGL.createTexture();

                                    var glFoTy = iFormatPI2GL( format );

                                    var glWrap = mGL.REPEAT; if (wrap === me.TEXWRP.CLAMP) glWrap = mGL.CLAMP_TO_EDGE;

                                    if( type===me.TEXTYPE.T2D )
                                    {
                                        mGL.bindTexture(mGL.TEXTURE_2D, id);

                                        mGL.pixelStorei(mGL.UNPACK_FLIP_Y_WEBGL, flipY);
                                        mGL.pixelStorei(mGL.UNPACK_PREMULTIPLY_ALPHA_WEBGL, false);
                                        if( mIs20 ) mGL.pixelStorei(mGL.UNPACK_COLORSPACE_CONVERSION_WEBGL, mGL.NONE );

                                        mGL.texImage2D(mGL.TEXTURE_2D, 0, glFoTy.mGLFormat, glFoTy.mGLExternal, glFoTy.mGLType, image);

                                        mGL.texParameteri(mGL.TEXTURE_2D, mGL.TEXTURE_WRAP_S, glWrap);
                                        mGL.texParameteri(mGL.TEXTURE_2D, mGL.TEXTURE_WRAP_T, glWrap);

                                        if (filter === me.FILTER.NONE)
                                        {
                                            mGL.texParameteri(mGL.TEXTURE_2D, mGL.TEXTURE_MAG_FILTER, mGL.NEAREST);
                                            mGL.texParameteri(mGL.TEXTURE_2D, mGL.TEXTURE_MIN_FILTER, mGL.NEAREST);
                                        }
                                        else if (filter === me.FILTER.LINEAR)
                                        {
                                            mGL.texParameteri(mGL.TEXTURE_2D, mGL.TEXTURE_MAG_FILTER, mGL.LINEAR);
                                            mGL.texParameteri(mGL.TEXTURE_2D, mGL.TEXTURE_MIN_FILTER, mGL.LINEAR);
                                        }
                                        else if( filter === me.FILTER.MIPMAP)
                                        {
                                            mGL.texParameteri(mGL.TEXTURE_2D, mGL.TEXTURE_MAG_FILTER, mGL.LINEAR);
                                            mGL.texParameteri(mGL.TEXTURE_2D, mGL.TEXTURE_MIN_FILTER, mGL.LINEAR_MIPMAP_LINEAR);
                                            mGL.generateMipmap(mGL.TEXTURE_2D);
                                        }
                                        else
                                        {
                                            mGL.texParameteri(mGL.TEXTURE_2D, mGL.TEXTURE_MAG_FILTER, mGL.LINEAR);
                                            mGL.texParameteri(mGL.TEXTURE_2D, mGL.TEXTURE_MIN_FILTER, mGL.NEAREST_MIPMAP_LINEAR);
                                            mGL.generateMipmap(mGL.TEXTURE_2D);
                                        }
                                        mGL.pixelStorei(mGL.UNPACK_FLIP_Y_WEBGL, false);
                                        mGL.bindTexture(mGL.TEXTURE_2D, null);
                                    }
                                    else if( type===me.TEXTYPE.T3D )
                                    {
                                        return null;
                                    }
                                    else 
                                    {
                                        mGL.bindTexture( mGL.TEXTURE_CUBE_MAP, id );
                                        mGL.pixelStorei(mGL.UNPACK_FLIP_Y_WEBGL, flipY);
                                        mGL.activeTexture( mGL.TEXTURE0 );
                                        mGL.texImage2D(  mGL.TEXTURE_CUBE_MAP_POSITIVE_X, 0, glFoTy.mGLFormat, glFoTy.mGLExternal, glFoTy.mGLType, image[0] );
                                        mGL.texImage2D(  mGL.TEXTURE_CUBE_MAP_NEGATIVE_X, 0, glFoTy.mGLFormat, glFoTy.mGLExternal, glFoTy.mGLType, image[1] );
                                        mGL.texImage2D(  mGL.TEXTURE_CUBE_MAP_POSITIVE_Y, 0, glFoTy.mGLFormat, glFoTy.mGLExternal, glFoTy.mGLType, (flipY ? image[3] : image[2]) );
                                        mGL.texImage2D(  mGL.TEXTURE_CUBE_MAP_NEGATIVE_Y, 0, glFoTy.mGLFormat, glFoTy.mGLExternal, glFoTy.mGLType, (flipY ? image[2] : image[3]) );
                                        mGL.texImage2D(  mGL.TEXTURE_CUBE_MAP_POSITIVE_Z, 0, glFoTy.mGLFormat, glFoTy.mGLExternal, glFoTy.mGLType, image[4] );
                                        mGL.texImage2D(  mGL.TEXTURE_CUBE_MAP_NEGATIVE_Z, 0, glFoTy.mGLFormat, glFoTy.mGLExternal, glFoTy.mGLType, image[5] );

                                        if( filter === me.FILTER.NONE)
                                        {
                                            mGL.texParameteri(mGL.TEXTURE_CUBE_MAP, mGL.TEXTURE_MAG_FILTER, mGL.NEAREST);
                                            mGL.texParameteri(mGL.TEXTURE_CUBE_MAP, mGL.TEXTURE_MIN_FILTER, mGL.NEAREST);
                                        }
                                        else if (filter === me.FILTER.LINEAR)
                                        {
                                            mGL.texParameteri( mGL.TEXTURE_CUBE_MAP, mGL.TEXTURE_MAG_FILTER, mGL.LINEAR );
                                            mGL.texParameteri( mGL.TEXTURE_CUBE_MAP, mGL.TEXTURE_MIN_FILTER, mGL.LINEAR );
                                        }
                                        else if (filter === me.FILTER.MIPMAP)
                                        {
                                            mGL.texParameteri(mGL.TEXTURE_CUBE_MAP, mGL.TEXTURE_MAG_FILTER, mGL.LINEAR);
                                            mGL.texParameteri(mGL.TEXTURE_CUBE_MAP, mGL.TEXTURE_MIN_FILTER, mGL.LINEAR_MIPMAP_LINEAR);
                                            mGL.generateMipmap( mGL.TEXTURE_CUBE_MAP );
                                        }
                                        mGL.pixelStorei(mGL.UNPACK_FLIP_Y_WEBGL, false);
                                        mGL.bindTexture( mGL.TEXTURE_CUBE_MAP, null );
                                    }
                                    return { mObjectID: id, mXres: image.width, mYres: image.height, mFormat: format, mType: type, mFilter: filter, mWrap:wrap, mVFlip:flipY };
                                };

        me.SetSamplerFilter = function (te, filter, doGenerateMipsIfNeeded) 
                            {
                                if (te.mFilter === filter) return;

                                if (te.mType === me.TEXTYPE.T2D) 
                                {
                                    mGL.bindTexture(mGL.TEXTURE_2D, te.mObjectID);

                                    if (filter === me.FILTER.NONE) 
                                    {
                                        mGL.texParameteri(mGL.TEXTURE_2D, mGL.TEXTURE_MAG_FILTER, mGL.NEAREST);
                                        mGL.texParameteri(mGL.TEXTURE_2D, mGL.TEXTURE_MIN_FILTER, mGL.NEAREST);
                                    }
                                    else if (filter === me.FILTER.LINEAR) 
                                    {
                                        mGL.texParameteri(mGL.TEXTURE_2D, mGL.TEXTURE_MAG_FILTER, mGL.LINEAR);
                                        mGL.texParameteri(mGL.TEXTURE_2D, mGL.TEXTURE_MIN_FILTER, mGL.LINEAR);
                                    }
                                    else if (filter === me.FILTER.MIPMAP) 
                                    {
                                        mGL.texParameteri(mGL.TEXTURE_2D, mGL.TEXTURE_MAG_FILTER, mGL.LINEAR);
                                        mGL.texParameteri(mGL.TEXTURE_2D, mGL.TEXTURE_MIN_FILTER, mGL.LINEAR_MIPMAP_LINEAR);
                                        if( doGenerateMipsIfNeeded ) mGL.generateMipmap(mGL.TEXTURE_2D);
                                    }
                                    else
                                    {
                                        mGL.texParameteri(mGL.TEXTURE_2D, mGL.TEXTURE_MAG_FILTER, mGL.NEAREST);
                                        mGL.texParameteri(mGL.TEXTURE_2D, mGL.TEXTURE_MIN_FILTER, mGL.NEAREST_MIPMAP_LINEAR);
                                        if( doGenerateMipsIfNeeded ) mGL.generateMipmap(mGL.TEXTURE_2D);
                                    }

                                    mGL.bindTexture(mGL.TEXTURE_2D, null);

                                }
                                else if (te.mType === me.TEXTYPE.T3D) 
                                {
                                    mGL.bindTexture(mGL.TEXTURE_3D, te.mObjectID);

                                    if (filter === me.FILTER.NONE) 
                                    {
                                        mGL.texParameteri(mGL.TEXTURE_3D, mGL.TEXTURE_MAG_FILTER, mGL.NEAREST);
                                        mGL.texParameteri(mGL.TEXTURE_3D, mGL.TEXTURE_MIN_FILTER, mGL.NEAREST);
                                    }
                                    else if (filter === me.FILTER.LINEAR) 
                                    {
                                        mGL.texParameteri(mGL.TEXTURE_3D, mGL.TEXTURE_MAG_FILTER, mGL.LINEAR);
                                        mGL.texParameteri(mGL.TEXTURE_3D, mGL.TEXTURE_MIN_FILTER, mGL.LINEAR);
                                    }
                                    else if (filter === me.FILTER.MIPMAP) 
                                    {
                                        mGL.texParameteri(mGL.TEXTURE_3D, mGL.TEXTURE_MAG_FILTER, mGL.LINEAR);
                                        mGL.texParameteri(mGL.TEXTURE_3D, mGL.TEXTURE_MIN_FILTER, mGL.LINEAR_MIPMAP_LINEAR);
                                        if( doGenerateMipsIfNeeded ) mGL.generateMipmap(mGL.TEXTURE_3D);
                                    }
                                    else
                                    {
                                        mGL.texParameteri(mGL.TEXTURE_3D, mGL.TEXTURE_MAG_FILTER, mGL.NEAREST);
                                        mGL.texParameteri(mGL.TEXTURE_3D, mGL.TEXTURE_MIN_FILTER, mGL.NEAREST_MIPMAP_LINEAR);
                                        if( doGenerateMipsIfNeeded ) mGL.generateMipmap(mGL.TEXTURE_3D);
                                    }

                                    mGL.bindTexture(mGL.TEXTURE_3D, null);

                                }
                                else
                                {
                                    mGL.bindTexture(mGL.TEXTURE_CUBE_MAP, te.mObjectID);

                                    if (filter === me.FILTER.NONE) 
                                    {
                                        mGL.texParameteri(mGL.TEXTURE_CUBE_MAP, mGL.TEXTURE_MAG_FILTER, mGL.NEAREST);
                                        mGL.texParameteri(mGL.TEXTURE_CUBE_MAP, mGL.TEXTURE_MIN_FILTER, mGL.NEAREST);
                                    }
                                    else if (filter === me.FILTER.LINEAR) 
                                    {
                                        mGL.texParameteri(mGL.TEXTURE_CUBE_MAP, mGL.TEXTURE_MAG_FILTER, mGL.LINEAR);
                                        mGL.texParameteri(mGL.TEXTURE_CUBE_MAP, mGL.TEXTURE_MIN_FILTER, mGL.LINEAR);
                                    }
                                    else if (filter === me.FILTER.MIPMAP) 
                                    {
                                        mGL.texParameteri(mGL.TEXTURE_CUBE_MAP, mGL.TEXTURE_MAG_FILTER, mGL.LINEAR);
                                        mGL.texParameteri(mGL.TEXTURE_CUBE_MAP, mGL.TEXTURE_MIN_FILTER, mGL.LINEAR_MIPMAP_LINEAR);
                                        if( doGenerateMipsIfNeeded ) mGL.generateMipmap(mGL.TEXTURE_CUBE_MAP);
                                    }
                                    else
                                    {
                                        mGL.texParameteri(mGL.TEXTURE_CUBE_MAP, mGL.TEXTURE_MAG_FILTER, mGL.NEAREST);
                                        mGL.texParameteri(mGL.TEXTURE_CUBE_MAP, mGL.TEXTURE_MIN_FILTER, mGL.NEAREST_MIPMAP_LINEAR);
                                        if( doGenerateMipsIfNeeded ) mGL.generateMipmap(mGL.TEXTURE_CUBE_MAP);
                                    }

                                    mGL.bindTexture(mGL.TEXTURE_CUBE_MAP, null);
                                }


                                te.mFilter = filter;
                            };

        me.SetSamplerWrap = function (te, wrap)
                            {
                                if (te.mWrap === wrap) return;

                                var glWrap = mGL.REPEAT; if (wrap === me.TEXWRP.CLAMP) glWrap = mGL.CLAMP_TO_EDGE;

                                var id = te.mObjectID;

                                if (te.mType === me.TEXTYPE.T2D)
                                {
                                    mGL.bindTexture(mGL.TEXTURE_2D, id);
                                    mGL.texParameteri(mGL.TEXTURE_2D, mGL.TEXTURE_WRAP_S, glWrap);
                                    mGL.texParameteri(mGL.TEXTURE_2D, mGL.TEXTURE_WRAP_T, glWrap);
                                    mGL.bindTexture(mGL.TEXTURE_2D, null);

                                }
                                else if (te.mType === me.TEXTYPE.T3D)
                                {
                                    mGL.bindTexture(mGL.TEXTURE_3D, id);
                                    mGL.texParameteri(mGL.TEXTURE_3D, mGL.TEXTURE_WRAP_R, glWrap);
                                    mGL.texParameteri(mGL.TEXTURE_3D, mGL.TEXTURE_WRAP_S, glWrap);
                                    mGL.texParameteri(mGL.TEXTURE_3D, mGL.TEXTURE_WRAP_T, glWrap);
                                    mGL.bindTexture(mGL.TEXTURE_3D, null);
                                }

                                te.mWrap = wrap;
                            };

        me.SetSamplerVFlip = function (te, vflip, image)
                            {
                                if (te.mVFlip === vflip) return;

                                var id = te.mObjectID;

                                if (te.mType === me.TEXTYPE.T2D)
                                {
                                    if( image != null)
                                    {
                                        mGL.activeTexture( mGL.TEXTURE0 );
                                        mGL.bindTexture(mGL.TEXTURE_2D, id);
                                        mGL.pixelStorei(mGL.UNPACK_FLIP_Y_WEBGL, vflip);
                                        var glFoTy = iFormatPI2GL( te.mFormat );
                                        mGL.texImage2D(mGL.TEXTURE_2D, 0, glFoTy.mGLFormat, glFoTy.mGLExternal, glFoTy.mGLType, image);
                                        mGL.bindTexture(mGL.TEXTURE_2D, null);
                                        mGL.pixelStorei(mGL.UNPACK_FLIP_Y_WEBGL, false);
                                    }
                                }
                                else if (te.mType === me.TEXTYPE.CUBEMAP)
                                {
                                    if( image != null)
                                    {
                                        var glFoTy = iFormatPI2GL( te.mFormat );
                                        mGL.activeTexture( mGL.TEXTURE0 );
                                        mGL.bindTexture( mGL.TEXTURE_CUBE_MAP, id );
                                        mGL.pixelStorei( mGL.UNPACK_FLIP_Y_WEBGL, vflip);
                                        mGL.texImage2D(  mGL.TEXTURE_CUBE_MAP_POSITIVE_X, 0, glFoTy.mGLFormat, glFoTy.mGLExternal, glFoTy.mGLType, image[0] );
                                        mGL.texImage2D(  mGL.TEXTURE_CUBE_MAP_NEGATIVE_X, 0, glFoTy.mGLFormat, glFoTy.mGLExternal, glFoTy.mGLType, image[1] );
                                        mGL.texImage2D(  mGL.TEXTURE_CUBE_MAP_POSITIVE_Y, 0, glFoTy.mGLFormat, glFoTy.mGLExternal, glFoTy.mGLType, (vflip ? image[3] : image[2]) );
                                        mGL.texImage2D(  mGL.TEXTURE_CUBE_MAP_NEGATIVE_Y, 0, glFoTy.mGLFormat, glFoTy.mGLExternal, glFoTy.mGLType, (vflip ? image[2] : image[3]) );
                                        mGL.texImage2D(  mGL.TEXTURE_CUBE_MAP_POSITIVE_Z, 0, glFoTy.mGLFormat, glFoTy.mGLExternal, glFoTy.mGLType, image[4] );
                                        mGL.texImage2D(  mGL.TEXTURE_CUBE_MAP_NEGATIVE_Z, 0, glFoTy.mGLFormat, glFoTy.mGLExternal, glFoTy.mGLType, image[5] );
                                        mGL.bindTexture( mGL.TEXTURE_CUBE_MAP, null );
                                        mGL.pixelStorei(mGL.UNPACK_FLIP_Y_WEBGL, false);
                                    }
        
                                }

                                te.mVFlip = vflip;
                            };

        me.CreateMipmaps =  function (te)
                            {
                                if( te.mType===me.TEXTYPE.T2D )
                                {
                                    mGL.activeTexture(mGL.TEXTURE0);
                                    mGL.bindTexture(mGL.TEXTURE_2D, te.mObjectID);
                                    mGL.generateMipmap(mGL.TEXTURE_2D);
                                    mGL.bindTexture(mGL.TEXTURE_2D, null);
                                }
                                else if( te.mType===me.TEXTYPE.CUBEMAP )
                                {
                                    mGL.activeTexture(mGL.TEXTURE0);
                                    mGL.bindTexture(mGL.TEXTURE_CUBE_MAP, te.mObjectID);
                                    mGL.generateMipmap( mGL.TEXTURE_CUBE_MAP );
                                    mGL.bindTexture(mGL.TEXTURE_CUBE_MAP, null);
                                }
                            };

        me.UpdateTexture =  function( tex, x0, y0, xres, yres, buffer )
                            {
                                var glFoTy = iFormatPI2GL( tex.mFormat );
                                if( tex.mType===me.TEXTYPE.T2D )
                                {
                                    mGL.activeTexture( mGL.TEXTURE0);
                                    mGL.bindTexture( mGL.TEXTURE_2D, tex.mObjectID );
                                    mGL.pixelStorei(mGL.UNPACK_FLIP_Y_WEBGL, tex.mVFlip );
                                    mGL.texSubImage2D( mGL.TEXTURE_2D, 0, x0, y0, xres, yres, glFoTy.mGLExternal, glFoTy.mGLType, buffer );
                                    mGL.bindTexture( mGL.TEXTURE_2D, null );
                                    mGL.pixelStorei(mGL.UNPACK_FLIP_Y_WEBGL, false);
                                }
                            };

        me.UpdateTextureFromImage = function( tex, image )
                                {
                                    var glFoTy = iFormatPI2GL( tex.mFormat );
                                    if( tex.mType===me.TEXTYPE.T2D )
                                    {
                                        mGL.activeTexture( mGL.TEXTURE0 );
                                        mGL.bindTexture( mGL.TEXTURE_2D, tex.mObjectID );
                                        mGL.pixelStorei(mGL.UNPACK_FLIP_Y_WEBGL, tex.mVFlip );
                                        mGL.texImage2D(  mGL.TEXTURE_2D, 0, glFoTy.mGLFormat, glFoTy.mGLExternal, glFoTy.mGLType, image );
                                        mGL.bindTexture( mGL.TEXTURE_2D, null );
                                        mGL.pixelStorei(mGL.UNPACK_FLIP_Y_WEBGL, false);
                                    }
                                };

        me.DestroyTexture = function( te )
                            {
                                 mGL.deleteTexture( te.mObjectID );
                            };

        me.AttachTextures = function (num, t0, t1, t2, t3) 
                            {
                                if (num > 0 && t0 != null) 
                                {
                                    mGL.activeTexture(mGL.TEXTURE0);
                                         if (t0.mType === me.TEXTYPE.T2D) mGL.bindTexture(mGL.TEXTURE_2D, t0.mObjectID);
                                    else if (t0.mType === me.TEXTYPE.T3D) mGL.bindTexture(mGL.TEXTURE_3D, t0.mObjectID);
                                    else if (t0.mType === me.TEXTYPE.CUBEMAP) mGL.bindTexture(mGL.TEXTURE_CUBE_MAP, t0.mObjectID);
                                }

                                if (num > 1 && t1 != null) 
                                {
                                    mGL.activeTexture(mGL.TEXTURE1);
                                         if (t1.mType === me.TEXTYPE.T2D) mGL.bindTexture(mGL.TEXTURE_2D, t1.mObjectID);
                                    else if (t1.mType === me.TEXTYPE.T3D) mGL.bindTexture(mGL.TEXTURE_3D, t1.mObjectID);
                                    else if (t1.mType === me.TEXTYPE.CUBEMAP) mGL.bindTexture(mGL.TEXTURE_CUBE_MAP, t1.mObjectID);
                                }

                                if (num > 2 && t2 != null) 
                                {
                                    mGL.activeTexture(mGL.TEXTURE2);
                                         if (t2.mType === me.TEXTYPE.T2D) mGL.bindTexture(mGL.TEXTURE_2D, t2.mObjectID);
                                    else if (t2.mType === me.TEXTYPE.T3D) mGL.bindTexture(mGL.TEXTURE_3D, t2.mObjectID);
                                    else if (t2.mType === me.TEXTYPE.CUBEMAP) mGL.bindTexture(mGL.TEXTURE_CUBE_MAP, t2.mObjectID);
                                }

                                if (num > 3 && t3 != null) 
                                {
                                    mGL.activeTexture(mGL.TEXTURE3);
                                         if (t3.mType === me.TEXTYPE.T2D) mGL.bindTexture(mGL.TEXTURE_2D, t3.mObjectID);
                                    else if (t3.mType === me.TEXTYPE.T3D) mGL.bindTexture(mGL.TEXTURE_3D, t3.mObjectID);
                                    else if (t3.mType === me.TEXTYPE.CUBEMAP) mGL.bindTexture(mGL.TEXTURE_CUBE_MAP, t3.mObjectID);
                                }
                            };

        me.DettachTextures = function()
                             {
                                mGL.activeTexture(mGL.TEXTURE0);
                                mGL.bindTexture(mGL.TEXTURE_2D, null);
                                mGL.bindTexture(mGL.TEXTURE_CUBE_MAP, null);

                                mGL.activeTexture(mGL.TEXTURE1);
                                mGL.bindTexture(mGL.TEXTURE_2D, null);
                                mGL.bindTexture(mGL.TEXTURE_CUBE_MAP, null);

                                mGL.activeTexture(mGL.TEXTURE2);
                                mGL.bindTexture(mGL.TEXTURE_2D, null);
                                mGL.bindTexture(mGL.TEXTURE_CUBE_MAP, null);

                                mGL.activeTexture(mGL.TEXTURE3);
                                mGL.bindTexture(mGL.TEXTURE_2D, null);
                                mGL.bindTexture(mGL.TEXTURE_CUBE_MAP, null);
                             };

        me.CreateRenderTarget = function ( color0, color1, color2, color3, depth, wantZbuffer )
                                {
                                    var id =  mGL.createFramebuffer();
                                    mGL.bindFramebuffer(mGL.FRAMEBUFFER, id);

                                    if (depth === null)
                                    {
                                        if( wantZbuffer===true )
                                        {
                                            var zb = mGL.createRenderbuffer();
                                            mGL.bindRenderbuffer(mGL.RENDERBUFFER, zb);
                                            mGL.renderbufferStorage(mGL.RENDERBUFFER, mGL.DEPTH_COMPONENT16, color0.mXres, color0.mYres);

                                            mGL.framebufferRenderbuffer(mGL.FRAMEBUFFER, mGL.DEPTH_ATTACHMENT, mGL.RENDERBUFFER, zb);
                                        }
                                    }
                                    else
                                    {
                                        mGL.framebufferTexture2D(mGL.FRAMEBUFFER, mGL.DEPTH_ATTACHMENT, mGL.TEXTURE_2D, depth.mObjectID, 0);
                                    }

                                    if( color0 !=null ) mGL.framebufferTexture2D(mGL.FRAMEBUFFER, mGL.COLOR_ATTACHMENT0, mGL.TEXTURE_2D, color0.mObjectID, 0);

                                    if (mGL.checkFramebufferStatus(mGL.FRAMEBUFFER) != mGL.FRAMEBUFFER_COMPLETE)
                                        return null;

                                    mGL.bindRenderbuffer(mGL.RENDERBUFFER, null);
                                    mGL.bindFramebuffer(mGL.FRAMEBUFFER, null);
                                    return { mObjectID: id, mTex0: color0 };
                                };

        me.DestroyRenderTarget = function ( tex )
                                 {
                                     mGL.deleteFramebuffer(tex.mObjectID);
                                 };

        me.SetRenderTarget = function (tex)
                             {
                                if( tex===null )
                                    mGL.bindFramebuffer(mGL.FRAMEBUFFER, null);
                                else
                                    mGL.bindFramebuffer(mGL.FRAMEBUFFER, tex.mObjectID);

                                //mGL.drawBuffers([mGL.COLOR_ATTACHMENT0, mGL.COLOR_ATTACHMENT1]);
                             };

        me.CreateRenderTargetNew = function ( wantColor0, wantZbuffer, xres, yres, samples )
                                {
                                    var id =  mGL.createFramebuffer();
                                    mGL.bindFramebuffer(mGL.FRAMEBUFFER, id);

                                    if( wantZbuffer===true )
                                    {
                                        var zb = mGL.createRenderbuffer();
                                        mGL.bindRenderbuffer(mGL.RENDERBUFFER, zb);

                                        if( samples==1 )
                                        mGL.renderbufferStorage(mGL.RENDERBUFFER, mGL.DEPTH_COMPONENT16, xres, yres);
                                        else
                                        mGL.renderbufferStorageMultisample(mGL.RENDERBUFFER, samples, mGL.DEPTH_COMPONENT16, xres, yres);
                                        mGL.framebufferRenderbuffer(mGL.FRAMEBUFFER, mGL.DEPTH_ATTACHMENT, mGL.RENDERBUFFER, zb);
                                    }

                                    if( wantColor0 )
                                    {
                                        var cb = mGL.createRenderbuffer();
                                        mGL.bindRenderbuffer(mGL.RENDERBUFFER, cb);
                                        if( samples==1 )
                                        mGL.renderbufferStorage(mGL.RENDERBUFFER, mGL.RGBA8, xres, yres);
                                        else
                                        mGL.renderbufferStorageMultisample(mGL.RENDERBUFFER, samples, mGL.RGBA8, xres, yres);
                                        mGL.framebufferRenderbuffer(mGL.FRAMEBUFFER, mGL.COLOR_ATTACHMENT0, mGL.RENDERBUFFER, cb);
                                    }

                                    if (mGL.checkFramebufferStatus(mGL.FRAMEBUFFER) != mGL.FRAMEBUFFER_COMPLETE)
                                    {
                                        return null;
                                    }
                                    mGL.bindRenderbuffer(mGL.RENDERBUFFER, null);
                                    mGL.bindFramebuffer(mGL.FRAMEBUFFER, null);
                                    return { mObjectID: id, mXres: xres, mYres:yres, mTex0: color0 };
                                };

        me.CreateRenderTargetCubeMap = function ( color0, depth, wantZbuffer )
                                {
                                    var id =  mGL.createFramebuffer();
                                    mGL.bindFramebuffer(mGL.FRAMEBUFFER, id);

                                    if (depth === null)
                                    {
                                        if( wantZbuffer===true )
                                        {
                                            var zb = mGL.createRenderbuffer();
                                            mGL.bindRenderbuffer(mGL.RENDERBUFFER, zb);
                                            mGL.renderbufferStorage(mGL.RENDERBUFFER, mGL.DEPTH_COMPONENT16, color0.mXres, color0.mYres);
                                            mGL.framebufferRenderbuffer(mGL.FRAMEBUFFER, mGL.DEPTH_ATTACHMENT, mGL.RENDERBUFFER, zb);
                                        }
                                    }
                                    else
                                    {
                                        mGL.framebufferTexture2D(mGL.FRAMEBUFFER, mGL.DEPTH_ATTACHMENT, mGL.TEXTURE_2D, depth.mObjectID, 0);
                                    }

                                    if( color0 !=null ) mGL.framebufferTexture2D(mGL.FRAMEBUFFER, mGL.COLOR_ATTACHMENT0, mGL.TEXTURE_CUBE_MAP_POSITIVE_X, color0.mObjectID, 0);

                                    if (mGL.checkFramebufferStatus(mGL.FRAMEBUFFER) != mGL.FRAMEBUFFER_COMPLETE)
                                        return null;

                                    mGL.bindRenderbuffer(mGL.RENDERBUFFER, null);
                                    mGL.bindFramebuffer(mGL.FRAMEBUFFER, null);
                                    return { mObjectID: id, mTex0: color0 };
                                };

        me.SetRenderTargetCubeMap = function (fbo, face)
                             {
                                if( fbo===null )
                                    mGL.bindFramebuffer(mGL.FRAMEBUFFER, null);
                                else
                                {
                                    mGL.bindFramebuffer(mGL.FRAMEBUFFER, fbo.mObjectID);
                                    mGL.framebufferTexture2D(mGL.FRAMEBUFFER, mGL.COLOR_ATTACHMENT0, mGL.TEXTURE_CUBE_MAP_POSITIVE_X+face, fbo.mTex0.mObjectID, 0);
                                }
                             };


        me.BlitRenderTarget = function( dst, src )
                                {
                                    mGL.bindFramebuffer(mGL.READ_FRAMEBUFFER, src.mObjectID);
                                    mGL.bindFramebuffer(mGL.DRAW_FRAMEBUFFER, dst.mObjectID);
                                    mGL.clearBufferfv(mGL.COLOR, 0, [0.0, 0.0, 0.0, 1.0]);
                                    mGL.blitFramebuffer( 0, 0, src.mXres, src.mYres,
                                                         0, 0, src.mXres, src.mYres,
                                                         mGL.COLOR_BUFFER_BIT, mGL.LINEAR
                                    );
                                };

        me.SetViewport = function( vp )
                         {
                              mGL.viewport( vp[0], vp[1], vp[2], vp[3] );
                         };

        me.SetWriteMask = function( c0, c1, c2, c3, z )
                          {
                              mGL.depthMask(z);
                              mGL.colorMask(c0,c0,c0,c0);
                          };

        me.SetState = function( stateName, stateValue )
                      {
                            if (stateName === me.RENDSTGATE.WIREFRAME)
                            {
                                if( stateValue ) mGL.polygonMode( mGL.FRONT_AND_BACK, mGL.LINE );
                                else             mGL.polygonMode( mGL.FRONT_AND_BACK, mGL.FILL );
                            }
                            else if (stateName === me.RENDSTGATE.FRONT_FACE)
                            {
                                if( stateValue ) mGL.cullFace( mGL.BACK );
                                else             mGL.cullFace( mGL.FRONT );
                            }
                            else if (stateName === me.RENDSTGATE.CULL_FACE)
                            {
                                if( stateValue ) mGL.enable( mGL.CULL_FACE );
                                else             mGL.disable( mGL.CULL_FACE );
                            }
                            else if (stateName === me.RENDSTGATE.DEPTH_TEST)
                            {
                                if( stateValue ) mGL.enable( mGL.DEPTH_TEST );
                                else             mGL.disable( mGL.DEPTH_TEST );
                            }
                            else if (stateName === me.RENDSTGATE.ALPHA_TO_COVERAGE)
                            {
                                if( stateValue ) { mGL.enable(  mGL.SAMPLE_ALPHA_TO_COVERAGE ); }
                                else             { mGL.disable( mGL.SAMPLE_ALPHA_TO_COVERAGE ); }
                            }
                      };

        me.SetMultisample = function( v)
                    {
                        if( v===true )
                        {
                            mGL.enable(mGL.SAMPLE_COVERAGE);
                            mGL.sampleCoverage(1.0, false);
                        }
                        else
                        {
                            mGL.disable(mGL.SAMPLE_COVERAGE);
                        }
                    };

        me.GetTranslatedShaderSource = function (shader) 
                          {
                            if( mGL===null ) return null;
                            if( mDebugShader===null ) return null;
                            let vfs = mGL.getAttachedShaders(shader.mProgram);
                            let str = mDebugShader.getTranslatedShaderSource(vfs[1]);
                            let parts = str.split("GLSL END"); str = (parts.length<2) ? str : parts[1];
                            return str;
                          };

        me.CreateShader = function (vsSource, fsSource, preventCache, forceSynch, onResolve) 
                          {
                            if( mGL===null ) return;

                            var vs = mGL.createShader( mGL.VERTEX_SHADER   );
                            var fs = mGL.createShader( mGL.FRAGMENT_SHADER );

                            vsSource = mShaderHeader[0] + vsSource;
                            fsSource = mShaderHeader[1] + fsSource;

                            if( preventCache )
                            {
                                let vran = Math.random().toString(36).substring(7);
                                let fran = Math.random().toString(36).substring(7);
                                vsSource += "\n#define K" + vran + "\n";
                                fsSource += "\n#define K" + fran + "\n";
                            }

                            var timeStart = getRealTime();

                            mGL.shaderSource(vs, vsSource);
                            mGL.shaderSource(fs, fsSource);
                            mGL.compileShader(vs);
                            mGL.compileShader(fs);

                            var pr = mGL.createProgram();
                            mGL.attachShader(pr, vs);
                            mGL.attachShader(pr, fs);
                            mGL.linkProgram(pr);

                            //-------------
                            let checkErrors = function()
                            {
                                if (!mGL.getProgramParameter(pr, mGL.LINK_STATUS))
                                {
                                    // vs error
                                    if (!mGL.getShaderParameter(vs, mGL.COMPILE_STATUS))
                                    {
                                        let vsLog = mGL.getShaderInfoLog(vs);
                                        onResolve(false, { mErrorType: 0, mErrorStr: vsLog });
                                        mGL.deleteProgram(pr);
                                    }
                                    // fs error
                                    else if (!mGL.getShaderParameter(fs, mGL.COMPILE_STATUS))
                                    {
                                        let fsLog = mGL.getShaderInfoLog(fs);
                                        onResolve(false, { mErrorType: 1, mErrorStr: fsLog });
                                        mGL.deleteProgram(pr);
                                    }
                                    // link error
                                    else
                                    {
                                        let infoLog = mGL.getProgramInfoLog(pr);
                                        onResolve(false, { mErrorType: 2, mErrorStr: infoLog });
                                        mGL.deleteProgram(pr);
                                    }
                                }
                                // no errors
                                else
                                {
                                    let compilationTime = getRealTime() - timeStart;
                                    onResolve(true, { mProgram: pr, mTime: compilationTime });
                                }
                            };

                            // check compilation
                            if (mAsynchCompile === null || forceSynch===true )
                            {
                                checkErrors();
                            }
                            else
                            {
                                let loopCheckCompletion = function ()
                                {
                                    if( mGL.getProgramParameter(pr, mAsynchCompile.COMPLETION_STATUS_KHR) === true )
                                        checkErrors();
                                    else
                                        setTimeout(loopCheckCompletion, 10);
                                };
                                setTimeout(loopCheckCompletion, 10);
                            }
                        };

        me.AttachShader = function( shader )
                          {
                                if( shader===null )
                                {
                                    mBindedShader = null;
                                    mGL.useProgram( null );
                                }
                                else
                                {
                                    mBindedShader = shader;
                                    mGL.useProgram(shader.mProgram);
                                }
                          };

        me.DetachShader = function ()
                        {
                            mGL.useProgram(null);
                        };

        me.DestroyShader = function( tex )
                        {
                            mGL.deleteProgram(tex.mProgram);
                        };

        me.GetAttribLocation = function (shader, name)
                        {
                            return mGL.getAttribLocation(shader.mProgram, name);
                        };

        me.SetShaderConstantLocation = function (shader, name)
                        {
                            return mGL.getUniformLocation(shader.mProgram, name);
                        };

        me.SetShaderConstantMat4F = function( uname, params, istranspose )
                        {
                            var program = mBindedShader;

                            let pos = mGL.getUniformLocation( program.mProgram, uname );
                            if( pos===null )
                                return false;

                            if( istranspose===false )
                            {
                                var tmp = new Float32Array( [ params[0], params[4], params[ 8], params[12],
                                                              params[1], params[5], params[ 9], params[13],
                                                              params[2], params[6], params[10], params[14],
                                                              params[3], params[7], params[11], params[15] ] );
	                            mGL.uniformMatrix4fv(pos,false,tmp);
                            }
                            else
                                mGL.uniformMatrix4fv(pos,false,new Float32Array(params) );
                            return true;
                        };

        me.SetShaderConstant1F_Pos = function(pos, x)
                        {
                            mGL.uniform1f(pos, x);
                            return true;
                        };

        me.SetShaderConstant1FV_Pos = function(pos, x)
                        {
                            mGL.uniform1fv(pos, x);
                            return true;
                        };

        me.SetShaderConstant1F = function( uname, x )
                        {
                            var pos = mGL.getUniformLocation(mBindedShader.mProgram, uname);
                            if (pos === null)
                                return false;
                            mGL.uniform1f(pos, x);
                            return true;
                        };

        me.SetShaderConstant1I = function(uname, x)
                        {
                            let pos = mGL.getUniformLocation(mBindedShader.mProgram, uname);
                            if (pos === null)
                                return false;
                            mGL.uniform1i(pos, x);
                            return true;
                        };
        me.SetShaderConstant1I_Pos = function(pos, x)
                        {
                            mGL.uniform1i(pos, x);
                            return true;
                        };


        me.SetShaderConstant2F = function(uname, x)
                        {
                            let pos = mGL.getUniformLocation(mBindedShader.mProgram, uname);
                            if (pos === null)
                                return false;
                            mGL.uniform2fv(pos, x);
                            return true;
                        };

        me.SetShaderConstant3F = function(uname, x, y, z)
                        {
                            let pos = mGL.getUniformLocation(mBindedShader.mProgram, uname);
                            if (pos === null)
                                return false;
                            mGL.uniform3f(pos, x, y, z);
                            return true;
                        };

        me.SetShaderConstant1FV = function(uname, x)
                        {
                            let pos = mGL.getUniformLocation(mBindedShader.mProgram, uname);
                            if (pos === null)
                                return false;
                            mGL.uniform1fv(pos, new Float32Array(x));
                            return true;
                        };

        me.SetShaderConstant3FV = function(uname, x) 
                        {
                            let pos = mGL.getUniformLocation(mBindedShader.mProgram, uname);
                            if (pos === null) return false;
                            mGL.uniform3fv(pos, new Float32Array(x) );
                            return true;
                        };

        me.SetShaderConstant4FV = function(uname, x) 
                        {
                            let pos = mGL.getUniformLocation(mBindedShader.mProgram, uname);
                            if (pos === null) return false;
                            mGL.uniform4fv(pos, new Float32Array(x) );
                            return true;
                        };

        me.SetShaderTextureUnit = function( uname, unit )
                        {
                            var program = mBindedShader;
                            let pos = mGL.getUniformLocation(program.mProgram, uname);
                            if (pos === null) return false;
                            mGL.uniform1i(pos, unit);
                            return true;
                        };

        me.CreateVertexArray = function( data, mode )
                        {
                            let id = mGL.createBuffer();
                            mGL.bindBuffer(mGL.ARRAY_BUFFER, id);
                            if (mode === me.BUFTYPE.STATIC)
                                mGL.bufferData(mGL.ARRAY_BUFFER, data, mGL.STATIC_DRAW);
                            else
                                mGL.bufferData(mGL.ARRAY_BUFFER, data, mGL.DYNAMIC_DRAW);
                            return { mObject: id };
                        };

        me.CreateIndexArray = function( data, mode )
                        {
                            let id = mGL.createBuffer();
                            mGL.bindBuffer(mGL.ELEMENT_ARRAY_BUFFER, id );
                            if (mode === me.BUFTYPE.STATIC)
                                mGL.bufferData(mGL.ELEMENT_ARRAY_BUFFER, data, mGL.STATIC_DRAW);
                            else
                                mGL.bufferData(mGL.ELEMENT_ARRAY_BUFFER, data, mGL.DYNAMIC_DRAW);
                            return { mObject: id };
                        };

        me.DestroyArray = function( tex )
                        {
                            mGL.destroyBuffer(tex.mObject);
                        };

        me.AttachVertexArray = function( tex, attribs, pos )
                        {
                            let shader = mBindedShader;

                            mGL.bindBuffer( mGL.ARRAY_BUFFER, tex.mObject);

                            var num = attribs.mChannels.length;
                            var stride = attribs.mStride;

                            var offset = 0;
                            for (var i = 0; i < num; i++)
                            {
                                var id = pos[i];
                                mGL.enableVertexAttribArray(id);
                                var dtype = mGL.FLOAT;
                                var dsize = 4;
                                     if( attribs.mChannels[i].mType === me.TYPE.UINT8   ) { dtype = mGL.UNSIGNED_BYTE;  dsize = 1; }
                                else if( attribs.mChannels[i].mType === me.TYPE.UINT16  ) { dtype = mGL.UNSIGNED_SHORT; dsize = 2; }
                                else if( attribs.mChannels[i].mType === me.TYPE.FLOAT32 ) { dtype = mGL.FLOAT;          dsize = 4; }
                                mGL.vertexAttribPointer(id, attribs.mChannels[i].mNumComponents, dtype, attribs.mChannels[i].mNormalize, stride, offset);
                                offset += attribs.mChannels[i].mNumComponents * dsize;
                            }
                        };

        me.AttachIndexArray = function( tex )
                        {
                            mGL.bindBuffer(mGL.ELEMENT_ARRAY_BUFFER, tex.mObject);
                        };

        me.DetachVertexArray = function (tex, attribs)
                        {
                            let num = attribs.mChannels.length;
                            for (let i = 0; i < num; i++)
                                mGL.disableVertexAttribArray(i);
                            mGL.bindBuffer(mGL.ARRAY_BUFFER, null);
                        };

        me.DetachIndexArray = function( tex )
                        {
                            mGL.bindBuffer(mGL.ELEMENT_ARRAY_BUFFER, null);
                        };

        me.DrawPrimitive = function( typeOfPrimitive, num, useIndexArray, numInstances )
                        {
                            let glType = mGL.POINTS;
                            if( typeOfPrimitive===me.PRIMTYPE.POINTS ) glType = mGL.POINTS;
                            if( typeOfPrimitive===me.PRIMTYPE.LINES ) glType = mGL.LINES;
                            if( typeOfPrimitive===me.PRIMTYPE.LINE_LOOP ) glType = mGL.LINE_LOOP;
                            if( typeOfPrimitive===me.PRIMTYPE.LINE_STRIP ) glType = mGL.LINE_STRIP;
                            if( typeOfPrimitive===me.PRIMTYPE.TRIANGLES ) glType = mGL.TRIANGLES;
                            if( typeOfPrimitive===me.PRIMTYPE.TRIANGLE_STRIP ) glType = mGL.TRIANGLE_STRIP;

                            if( numInstances<=1 )
                            {
  	                            if( useIndexArray ) mGL.drawElements( glType, num, mGL.UNSIGNED_SHORT, 0 );
	                            else                mGL.drawArrays( glType, 0, num );
                            }
                            else
                            {
                                mGL.drawArraysInstanced(glType, 0, num, numInstances);
                                mGL.drawElementsInstanced( glType, num, mGL.UNSIGNED_SHORT, 0, numInstances);
                            }
                        };


        me.DrawFullScreenTriangle_XY = function( vpos )
                        {
                            mGL.bindBuffer( mGL.ARRAY_BUFFER, mVBO_Tri );
                            mGL.vertexAttribPointer( vpos, 2, mGL.FLOAT, false, 0, 0 );
                            mGL.enableVertexAttribArray( vpos );
                            mGL.drawArrays( mGL.TRIANGLES, 0, 3 );
                            mGL.disableVertexAttribArray( vpos );
                            mGL.bindBuffer( mGL.ARRAY_BUFFER, null );
                        };


        me.DrawUnitQuad_XY = function( vpos )
                        {
                            mGL.bindBuffer( mGL.ARRAY_BUFFER, mVBO_Quad );
                            mGL.vertexAttribPointer( vpos, 2, mGL.FLOAT, false, 0, 0 );
                            mGL.enableVertexAttribArray( vpos );
                            mGL.drawArrays( mGL.TRIANGLES, 0, 6 );
                            mGL.disableVertexAttribArray( vpos );
                            mGL.bindBuffer( mGL.ARRAY_BUFFER, null );
                        };

        me.DrawUnitCube_XYZ_NOR = function( vpos )
                        {
                            mGL.bindBuffer( mGL.ARRAY_BUFFER, mVBO_CubePosNor );
                            mGL.vertexAttribPointer( vpos[0], 3, mGL.FLOAT, false, 0, 0 );
                            mGL.vertexAttribPointer( vpos[1], 3, mGL.FLOAT, false, 0, 0 );
                            mGL.enableVertexAttribArray( vpos[0] );
                            mGL.enableVertexAttribArray( vpos[1] );
                            mGL.drawArrays(mGL.TRIANGLE_STRIP, 0, 4);
                            mGL.drawArrays(mGL.TRIANGLE_STRIP, 4, 4);
                            mGL.drawArrays(mGL.TRIANGLE_STRIP, 8, 4);
                            mGL.drawArrays(mGL.TRIANGLE_STRIP, 12, 4);
                            mGL.drawArrays(mGL.TRIANGLE_STRIP, 16, 4);
                            mGL.drawArrays(mGL.TRIANGLE_STRIP, 20, 4);
                            mGL.disableVertexAttribArray( vpos[0] );
                            mGL.disableVertexAttribArray( vpos[1] );
                            mGL.bindBuffer( mGL.ARRAY_BUFFER, null );
                        }

        me.DrawUnitCube_XYZ = function( vpos )
                        {
                            mGL.bindBuffer( mGL.ARRAY_BUFFER, mVBO_CubePos );
                            mGL.vertexAttribPointer( vpos, 3, mGL.FLOAT, false, 0, 0 );
                            mGL.enableVertexAttribArray( vpos );
                            mGL.drawArrays(mGL.TRIANGLE_STRIP, 0, 4);
                            mGL.drawArrays(mGL.TRIANGLE_STRIP, 4, 4);
                            mGL.drawArrays(mGL.TRIANGLE_STRIP, 8, 4);
                            mGL.drawArrays(mGL.TRIANGLE_STRIP, 12, 4);
                            mGL.drawArrays(mGL.TRIANGLE_STRIP, 16, 4);
                            mGL.drawArrays(mGL.TRIANGLE_STRIP, 20, 4);
                            mGL.disableVertexAttribArray( vpos );
                            mGL.bindBuffer( mGL.ARRAY_BUFFER, null );
                        }

        me.SetBlend = function( enabled )
                    {
                        if( enabled )
                        {
                            mGL.enable( mGL.BLEND );
                            mGL.blendEquationSeparate( mGL.FUNC_ADD, mGL.FUNC_ADD );
                            mGL.blendFuncSeparate( mGL.SRC_ALPHA, mGL.ONE_MINUS_SRC_ALPHA, mGL.ONE, mGL.ONE_MINUS_SRC_ALPHA );
                        }
                        else
                        {
                            mGL.disable( mGL.BLEND );
                        }
                    };

        me.GetPixelData = function( data, offset, xres, yres )
                        {
                            mGL.readPixels(0, 0, xres, yres, mGL.RGBA, mGL.UNSIGNED_BYTE, data, offset);
                        };

        me.GetPixelDataRenderTarget = function( obj, data, xres, yres )
                        {
                            mGL.bindFramebuffer(mGL.FRAMEBUFFER, obj.mObjectID);
                            mGL.readBuffer(mGL.COLOR_ATTACHMENT0);
                            mGL.readPixels(0, 0, xres, yres, mGL.RGBA, mGL.FLOAT, data, 0);
                            mGL.bindFramebuffer(mGL.FRAMEBUFFER, null);
                        };
    return me;
}
//==============================================================================
//
// piLibs 2015-2017 - http://www.iquilezles.org/www/material/piLibs/piLibs.htm
//
// piShading
//
//==============================================================================

function smoothstep(a, b, x)
{
    x = (x - a) / (b - a);
    if (x < 0) x = 0; else if (x > 1) x = 1;
    return x * x * (3.0 - 2.0 * x);
}

function clamp01(x)
{
    if( x < 0.0 ) x = 0.0;
    if( x > 1.0 ) x = 1.0;
    return x;
}

function clamp(x, a, b)
{
    if( x < a ) x = a;
    if( x > b ) x = b;
    return x;
}

function screen(a, b)
{
    return 1.0 - (1.0 - a) * (1.0 - b);
}

function parabola(x)
{
    return 4.0 * x * (1.0 - x);
}

function min(a, b)
{
    return (a < b) ? a : b;
}

function max(a, b)
{
    return (a > b) ? a : b;
}

function noise( x )
{
    function grad(i, j, x, y)
    {
        var h = 7 * i + 131 * j;
        h = (h << 13) ^ h;
        h = (h * (h * h * 15731 + 789221) + 1376312589);

        var rx = (h & 0x20000000) ? x : -x;
        var ry = (h & 0x10000000) ? y : -y;

        return rx + ry;
    }

    var i = [ Math.floor(x[0]), Math.floor(x[1]) ];
    var f = [ x[0] - i[0], x[1] - i[1] ];
    var w = [ f[0]*f[0]*(3.0-2.0*f[0]), f[1]*f[1]*(3.0-2.0*f[1]) ];

    var a = grad( i[0]+0, i[1]+0, f[0]+0.0, f[1]+0.0 );
    var b = grad( i[0]+1, i[1]+0, f[0]-1.0, f[1]+0.0 );
    var c = grad( i[0]+0, i[1]+1, f[0]+0.0, f[1]-1.0 );
    var d = grad( i[0]+1, i[1]+1, f[0]-1.0, f[1]-1.0 );

    return a + (b-a)*w[0] + (c-a)*w[1] + (a-b-c+d)*w[0]*w[1];
}//==============================================================================
//
// piLibs 2015-2017 - http://www.iquilezles.org/www/material/piLibs/piLibs.htm
//
// piVecTypes
//
//==============================================================================


function vec3( a, b, c )
{
    return [ a, b, c ];
}

function add( a, b )
{
    return [ a[0]+b[0], a[1]+b[1], a[2]+b[2] ];
}

function sub( a, b )
{
    return [ a[0]-b[0], a[1]-b[1], a[2]-b[2] ];
}

function mul( a, s ) 
{
    return [ a[0]*s, a[1]*s, a[2]*s ];
}

function cross( a, b )
{
    return [ a[1]*b[2] - a[2]*b[1],
             a[2]*b[0] - a[0]*b[2],
             a[0]*b[1] - a[1]*b[0] ];
}

function dot( a, b ) 
{
    return a[0]*b[0] + a[1]*b[1] + a[2]*b[2];
}

function normalize( v ) 
{
    var is = 1.0 / Math.sqrt( v[0]*v[0] + v[1]*v[1] + v[2]*v[2] );
    return [ v[0]*is, v[1]*is, v[2]*is ];
}

function createCirclePoint( cen, uuu, vvv, rad, s, t )
{
    return [ cen[0] + rad*(uuu[0]*s + vvv[0]*t),
             cen[1] + rad*(uuu[1]*s + vvv[1]*t),
             cen[2] + rad*(uuu[2]*s + vvv[2]*t) ];
}

function createTangent( a, b, c )
{
    var cb = normalize( [ c[0]-b[0], c[1]-b[1], c[2]-b[2] ] );
    var ba = normalize( [ b[0]-a[0], b[1]-a[1], b[2]-a[2] ] );
    return normalize( [ ba[0]+cb[0], ba[1]+cb[1], ba[2]+cb[2] ] );

}

//===================================

function vec4( a, b, c, d )
{
    return [ a, b, c, d ];
}

function getXYZ( v )
{
    return [ v[0], v[1], v[2] ];
}

//===================================

function setIdentity()
{
    return [ 1.0, 0.0, 0.0, 0.0,
             0.0, 1.0, 0.0, 0.0,
             0.0, 0.0, 1.0, 0.0,
             0.0, 0.0, 0.0, 1.0 ];
}

function setRotationX( t )
{
    var sint = Math.sin(t);
    var cost = Math.cos(t);

    return [ 1.0,   0.0,   0.0, 0.0,
             0.0,  cost, -sint, 0.0, 
             0.0,  sint,  cost, 0.0,
             0.0,   0.0,   0.0, 1.0 ];
}

function setRotationY( t )
{
    var sint = Math.sin(t);
    var cost = Math.cos(t);

    return [ cost, 0.0, -sint, 0.0,
              0.0, 1.0,   0.0, 0.0, 
             sint, 0.0,  cost, 0.0,
              0.0, 0.0,   0.0, 1.0 ];
}

function extractRotationEuler( m)
{
    var res = [];
    if (m[0] == 1.0)
    {
        res[0] = Math.atan2(m[2], m[11]);
        res[1] = 0.0;
        res[2] = 0.0;

    }
    else if (m[0] == -1.0)
    {
        res[0] = Math.atan2( m[2], m[11]);
        res[1] = 0.0;
        res[2] = 0.0;
    }
    else
    {
        res[0] = Math.atan2( -m[9], m[10]);
        res[1] = Math.atan2( m[8], Math.sqrt(m[9]*m[9] + m[10]*m[10]));
        res[2] = Math.atan2( m[4], m[0]);
    }
    return res;
}

function setFromQuaternion( q )
{
    var ww = q[3]*q[3];
    var xx = q[0]*q[0];
    var yy = q[1]*q[1];
    var zz = q[2]*q[2];

    return [ ww+xx-yy-zz,                   2.0*(q[0]*q[1] - q[3]*q[2]), 2.0*(q[0]*q[2] + q[3]*q[1]), 0.0,
               2.0*(q[0]*q[1] + q[3]*q[2]),   ww-xx+yy-zz,                 2.0*(q[1]*q[2] - q[3]*q[0]), 0.0,
               2.0*(q[0]*q[2] - q[3]*q[1]),   2.0*(q[1]*q[2] + q[3]*q[0]), ww-xx-yy+zz,                 0.0,
               0.0,                           0.0,                         0.0,                         1.0 ];
}

function setPerspective( fovy, aspect, znear, zfar )
{
    var tan = Math.tan(fovy * Math.PI/180.0);
    var x = 1.0 / (tan*aspect);
    var y = 1.0 / (tan);
    var c = -(zfar + znear) / ( zfar - znear);
    var d = -(2.0 * zfar * znear) / (zfar - znear);

    return [ x,    0.0,  0.0,  0.0,
             0.0,  y,    0.0,  0.0,
             0.0,  0.0,  c,     d,
             0.0,  0.0, -1.0,  0.0 ];
}

function setLookAt( eye, tar, up )
{
    var dir = [ -tar[0]+eye[0], -tar[1]+eye[1], -tar[2]+eye[2] ];

	var m00 = dir[2]*up[1] - dir[1]*up[2]; 
    var m01 = dir[0]*up[2] - dir[2]*up[0];
    var m02 = dir[1]*up[0] - dir[0]*up[1];
    var im = 1.0/Math.sqrt( m00*m00 + m01*m01 + m02*m02 );
    m00 *= im;
    m01 *= im;
    m02 *= im;

	var m04 = m02*dir[1] - m01*dir[2]; 
    var m05 = m00*dir[2] - m02*dir[0];
    var m06 = m01*dir[0] - m00*dir[1];
    im = 1.0/Math.sqrt( m04*m04 + m05*m05 + m06*m06 );
    m04 *= im;
    m05 *= im;
    m06 *= im;

	var m08 = dir[0];
	var m09 = dir[1];
	var m10 = dir[2];
    im = 1.0/Math.sqrt( m08*m08 + m09*m09 + m10*m10 );
    m08 *= im;
    m09 *= im;
    m10 *= im;

	var m03 = -(m00*eye[0] + m01*eye[1] + m02*eye[2] );
	var m07 = -(m04*eye[0] + m05*eye[1] + m06*eye[2] );
	var m11 = -(m08*eye[0] + m09*eye[1] + m10*eye[2] );

    return [ m00, m01, m02, m03,
             m04, m05, m06, m07,
             m08, m09, m10, m11,
             0.0, 0.0, 0.0, 1.0 ];
}


function setOrtho( left, right, bottom, top, znear, zfar )
{
   var x = 2.0 / (right - left);
   var y = 2.0 / (top - bottom);
   var a = (right + left) / (right - left);
   var b = (top + bottom) / (top - bottom);
   var c = -2.0 / (zfar - znear);
   var d = -(zfar + znear) / ( zfar - znear);

   return [  x, 0.0, 0.0,   a,
           0.0,   y, 0.0,   b,
           0.0, 0.0,   c,   d,
           0.0, 0.0, 0.0, 1.0 ];
}

function setTranslation( p )
{
    return [ 1.0, 0.0, 0.0, p[0],
             0.0, 1.0, 0.0, p[1],
             0.0, 0.0, 1.0, p[2],
             0.0, 0.0, 0.0, 1.0 ];
}

function setScale( s )
{
    return [ s[0], 0.0,  0.0,  0.0,
             0.0,  s[1], 0.0,  0.0,
             0.0,  0.0,  s[2], 0.0,
             0.0,  0.0,  0.0,  1.0];
}

function setProjection( fov, znear, zfar )
{
    var x = 2.0 / (fov[3]+fov[2]);
    var y = 2.0 / (fov[0]+fov[1]);
    var a = (fov[3]-fov[2]) / (fov[3]+fov[2]);
    var b = (fov[0]-fov[1]) / (fov[0]+fov[1]);
    var c = -(zfar + znear) / ( zfar - znear);
    var d = -(2.0*zfar*znear) / (zfar - znear);
    return [   x, 0.0,    a, 0.0,
             0.0,   y,    b, 0.0,
             0.0, 0.0,    c,   d,
             0.0, 0.0, -1.0, 0.0 ];
   // inverse is:
   //return mat4x4( 1.0/x, 0.0f,  0.0f,   a/x,
   //               0.0f,  1.0/y, 0.0f,   b/x,
   //               0.0f,  0.0f,  0.0f,   -1.0,
   //               0.0f,  0.0f,  1.0f/d, c/d );
}


function invertFast( m )
{
    var inv = [
   
             m[5]  * m[10] * m[15] - 
             m[5]  * m[11] * m[14] - 
             m[9]  * m[6]  * m[15] + 
             m[9]  * m[7]  * m[14] +
             m[13] * m[6]  * m[11] - 
             m[13] * m[7]  * m[10],

             -m[1]  * m[10] * m[15] + 
              m[1]  * m[11] * m[14] + 
              m[9]  * m[2] * m[15] - 
              m[9]  * m[3] * m[14] - 
              m[13] * m[2] * m[11] + 
              m[13] * m[3] * m[10],

             m[1]  * m[6] * m[15] - 
             m[1]  * m[7] * m[14] - 
             m[5]  * m[2] * m[15] + 
             m[5]  * m[3] * m[14] + 
             m[13] * m[2] * m[7] - 
             m[13] * m[3] * m[6],

             -m[1] * m[6] * m[11] + 
              m[1] * m[7] * m[10] + 
              m[5] * m[2] * m[11] - 
              m[5] * m[3] * m[10] - 
              m[9] * m[2] * m[7] + 
              m[9] * m[3] * m[6],

             -m[4]  * m[10] * m[15] + 
              m[4]  * m[11] * m[14] + 
              m[8]  * m[6]  * m[15] - 
              m[8]  * m[7]  * m[14] - 
              m[12] * m[6]  * m[11] + 
              m[12] * m[7]  * m[10],

             m[0]  * m[10] * m[15] - 
             m[0]  * m[11] * m[14] - 
             m[8]  * m[2] * m[15] + 
             m[8]  * m[3] * m[14] + 
             m[12] * m[2] * m[11] - 
             m[12] * m[3] * m[10],

             -m[0]  * m[6] * m[15] + 
              m[0]  * m[7] * m[14] + 
              m[4]  * m[2] * m[15] - 
              m[4]  * m[3] * m[14] - 
              m[12] * m[2] * m[7] + 
              m[12] * m[3] * m[6],


             m[0] * m[6] * m[11] - 
             m[0] * m[7] * m[10] - 
             m[4] * m[2] * m[11] + 
             m[4] * m[3] * m[10] + 
             m[8] * m[2] * m[7] - 
             m[8] * m[3] * m[6],


             m[4]  * m[9] * m[15] - 
             m[4]  * m[11] * m[13] - 
             m[8]  * m[5] * m[15] + 
             m[8]  * m[7] * m[13] + 
             m[12] * m[5] * m[11] - 
             m[12] * m[7] * m[9],



             -m[0]  * m[9] * m[15] + 
              m[0]  * m[11] * m[13] + 
              m[8]  * m[1] * m[15] - 
              m[8]  * m[3] * m[13] - 
              m[12] * m[1] * m[11] + 
              m[12] * m[3] * m[9],

              m[0]  * m[5] * m[15] - 
              m[0]  * m[7] * m[13] - 
              m[4]  * m[1] * m[15] + 
              m[4]  * m[3] * m[13] + 
              m[12] * m[1] * m[7] - 
              m[12] * m[3] * m[5],

              -m[0] * m[5] * m[11] + 
               m[0] * m[7] * m[9] + 
               m[4] * m[1] * m[11] - 
               m[4] * m[3] * m[9] - 
               m[8] * m[1] * m[7] + 
               m[8] * m[3] * m[5],

              -m[4]  * m[9] * m[14] + 
               m[4]  * m[10] * m[13] +
               m[8]  * m[5] * m[14] - 
               m[8]  * m[6] * m[13] - 
               m[12] * m[5] * m[10] + 
               m[12] * m[6] * m[9],

              m[0]  * m[9] * m[14] - 
              m[0]  * m[10] * m[13] - 
              m[8]  * m[1] * m[14] + 
              m[8]  * m[2] * m[13] + 
              m[12] * m[1] * m[10] - 
              m[12] * m[2] * m[9],

              -m[0]  * m[5] * m[14] + 
               m[0]  * m[6] * m[13] + 
               m[4]  * m[1] * m[14] - 
               m[4]  * m[2] * m[13] - 
               m[12] * m[1] * m[6] + 
               m[12] * m[2] * m[5],

              m[0] * m[5] * m[10] - 
              m[0] * m[6] * m[9] - 
              m[4] * m[1] * m[10] + 
              m[4] * m[2] * m[9] + 
              m[8] * m[1] * m[6] - 
              m[8] * m[2] * m[5] ];

    var det = m[0] * inv[0] + m[1] * inv[4] + m[2] * inv[8] + m[3] * inv[12];

    det = 1.0/det;

    for( var i = 0; i<16; i++ ) inv[i] = inv[i] * det;

    return inv;
}

function matMul( a, b )
{
    var res = [];
    for( var i=0; i<4; i++ )
    {
        var x = a[4*i+0];
        var y = a[4*i+1];
        var z = a[4*i+2];
        var w = a[4*i+3];

        res[4*i+0] = x * b[ 0] + y * b[ 4] + z * b[ 8] + w * b[12];
        res[4*i+1] = x * b[ 1] + y * b[ 5] + z * b[ 9] + w * b[13];
        res[4*i+2] = x * b[ 2] + y * b[ 6] + z * b[10] + w * b[14];
        res[4*i+3] = x * b[ 3] + y * b[ 7] + z * b[11] + w * b[15];
    }

    return res;
}

function matMulpoint( m, v )
{
    return [ m[0]*v[0] + m[1]*v[1] + m[ 2]*v[2] + m[ 3],
             m[4]*v[0] + m[5]*v[1] + m[ 6]*v[2] + m[ 7],
             m[8]*v[0] + m[9]*v[1] + m[10]*v[2] + m[11] ];
}

function matMulvec( m, v )
{
    return [ m[0]*v[0] + m[1]*v[1] + m[ 2]*v[2],
             m[4]*v[0] + m[5]*v[1] + m[ 6]*v[2],
             m[8]*v[0] + m[9]*v[1] + m[10]*v[2] ];
}


function bound3( infi )
{
    return [ infi, -infi, infi, -infi, infi, -infi ];
}

function bound3_include( a, p )
{
    return [
        (p[0]<a[0]) ? p[0] : a[0],
        (p[0]>a[1]) ? p[0] : a[1],
        (p[1]<a[2]) ? p[1] : a[2],
        (p[1]>a[3]) ? p[1] : a[3],
        (p[2]<a[4]) ? p[2] : a[4],
        (p[2]>a[5]) ? p[2] : a[5] ];
}

function bound3_center( b )
{
    return [ 0.5*(b[0]+b[1]),
             0.5*(b[2]+b[3]),
             0.5*(b[4]+b[5]) ];
}

function bound3_radius( b )
{
    return [ 0.5*(b[1]-b[0]),
             0.5*(b[3]-b[2]),
             0.5*(b[5]-b[4]) ];
}
//==============================================================================
//
// piLibs 2015-2017 - http://www.iquilezles.org/www/material/piLibs/piLibs.htm
//
// piWebVR
//
//==============================================================================

function WebVR( isVREnabledCallback, canvasElement )
{
    isVREnabledCallback(false);
    /*


    this.mSupportVR = false;
    this.mHMD = null;

    var me = this;
    var listVRDisplays = function (vrdevs) {
        for (var i = 0; i < vrdevs.length; i++)
        {
            if (vrdevs[i] instanceof VRDisplay)
            {
                me.mHMD = vrdevs[i];
                console.log("WebVR is available.");
                console.log(me.mHMD);
                break;
            }
        }

        isVREnabledCallback(true);
        me.mSupportVR = true;
    }

    if (navigator.getVRDisplays)
    {
        navigator.getVRDisplays().then(listVRDisplays);
    }

    isVREnabledCallback(false);
    this.mCanvas = canvasElement;
    */
}

WebVR.prototype.IsSupported = function()
{
    return false;
    //return this.mSupportVR;
}

WebVR.prototype.GetData = function( id )
{
    return {};
    /*
    var frameData = new VRFrameData();
    var s = this.mHMD.getFrameData(frameData);
    var ss = frameData.pose;
    
    var fovL = this.mHMD.getEyeParameters("left");
    var fovR = this.mHMD.getEyeParameters( "right" );

    // camera info
    var cPos = vec3(0.0, 0.0, 0.0);
    if (ss.position)
        cPos = vec3(-ss.position[0], -ss.position[1], -ss.position[2]);
    var rot = vec4(0.0, 0.0, 0.0, 0.0);
    if (ss.orientation)
        rot = vec4(ss.orientation[0], ss.orientation[1], ss.orientation[2], ss.orientation[3]);
    var cRot = setFromQuaternion(rot);
    var cTra = setTranslation(cPos);
    var cMat = matMul(invertFast(cRot), cTra);
    
    // per eye info
    var lTra = setTranslation( vec3(-fovL.offset[0], -fovL.offset[1], -fovL.offset[2]) );
    var lMat = matMul(lTra, cMat);
    var lPrj = [ Math.tan( fovL.fieldOfView.upDegrees * Math.PI/180.0),
                 Math.tan(fovL.fieldOfView.downDegrees * Math.PI / 180.0),
                 Math.tan(fovL.fieldOfView.leftDegrees * Math.PI / 180.0),
                 Math.tan(fovL.fieldOfView.rightDegrees * Math.PI / 180.0)];

    var rTra = setTranslation(vec3(-fovR.offset[0], -fovR.offset[1], -fovR.offset[2]));
    var rMat = matMul(rTra, cMat);
    var rPrj = [Math.tan(fovR.fieldOfView.upDegrees * Math.PI / 180.0),
                 Math.tan(fovR.fieldOfView.downDegrees * Math.PI / 180.0),
                 Math.tan(fovR.fieldOfView.leftDegrees * Math.PI / 180.0),
                 Math.tan(fovR.fieldOfView.rightDegrees * Math.PI / 180.0)];

    return {
        mCamera   : { mCamera: cMat },
        mLeftEye  : { mVP:[0,0,fovL.renderWidth,fovL.renderHeight], mProjection:lPrj, mCamera:lMat },
        mRightEye : { mVP:[fovR.renderWidth/2,0,fovR.renderWidth,fovR.renderHeight], mProjection:rPrj, mCamera:rMat }
           };
    */
}

WebVR.prototype.Enable = function( id )
{
    /*
    this.mHMD.requestPresent([{ source: this.mCanvas }]).then(
        function ()
        {
        },
        function (err)
        {
            console.log("webVR : requestPresent failed.");
        }
    );
    */
}

WebVR.prototype.Disable = function( id )
{
    /*
    if (!this.mHMD.isPresenting)
    {
        return;
    }

    this.mHMD.exitPresent().then(
        function ()
        {
        },
        function (err)
        {
            console.log("webVR : exitPresent failed.");
        }
    );
    */
}

WebVR.prototype.RequestAnimationFrame = function (id)
{
    //this.mHMD.requestAnimationFrame(id);
}

WebVR.prototype.IsPresenting = function (id)
{
    /*
    if (this.mHMD.isPresenting)
    {
        return true;
    }
    */
    return false;
}

WebVR.prototype.Finish = function (id)
{
    /*
    if (this.mHMD.isPresenting)
    {
        this.mHMD.submitFrame();
    }
    */
}

//==============================================================================
//
// piLibs 2015-2017 - http://www.iquilezles.org/www/material/piLibs/piLibs.htm
//
// piWebUtils
//
//==============================================================================


// RequestAnimationFrame
window.requestAnimFrame = ( function () { return window.requestAnimationFrame    || window.webkitRequestAnimationFrame ||
                                                 window.mozRequestAnimationFrame || window.oRequestAnimationFrame ||
                                                 window.msRequestAnimationFrame  || function( cb ) { window.setTimeout(cb,1000/60); };
                                        } )();

// performance.now
window.getRealTime = ( function() { if ("performance" in window ) return function() { return window.performance.now(); }
                                                                  return function() { return (new Date()).getTime(); }
                                  } )();

window.URL = window.URL || window.webkitURL;

navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia;

function htmlEntities(str) 
{
    return String(str).replace(/&/g, '&amp;').replace(/</g, '&lt;').replace(/>/g, '&gt;').replace(/"/g, '&quot;').replace(/'/g,'&apos;');
}

function piDisableTouch()
{
    document.body.addEventListener('touchstart', function(e){ e.preventDefault(); });
}

var piGetTime = function ( timestamp )
{
    if (timestamp == 0)
        return "";
    return new Date(timestamp * 1000).toISOString().substr(0, 10);
}

function piGetCoords( obj )
{
    var x = 0;
    var y = 0; 
    do
    {
         x += obj.offsetLeft;
         y += obj.offsetTop;
    }while( obj = obj.offsetParent );

    return { mX:x, mY:y };
}

function piGetMouseCoords( ev, canvasElement )
{
    var pos = piGetCoords(canvasElement );
    var mcx =                        (ev.pageX - pos.mX) * canvasElement.width / canvasElement.offsetWidth;
    var mcy = canvasElement.height - (ev.pageY - pos.mY) * canvasElement.height / canvasElement.offsetHeight;

    return { mX: mcx, mY: mcy };

}

function piGetSourceElement( e )
{
    var ele = null;
    if( e.target )     ele = e.target;
    if( e.srcElement ) ele = e.srcElement;
    return ele;
}

function piRequestFullScreen( ele )
{
    if( ele==null ) ele =   document.documentElement;
         if( ele.requestFullscreen       ) ele.requestFullscreen();
    else if( ele.msRequestFullscreen     ) ele.msRequestFullscreen();
    else if( ele.mozRequestFullScreen    ) ele.mozRequestFullScreen();
    else if( ele.webkitRequestFullscreen ) ele.webkitRequestFullscreen( Element.ALLOW_KEYBOARD_INPUT );
}

function piIsFullScreen()
{
    return document.fullscreen || document.mozFullScreen || document.webkitIsFullScreen || document.msFullscreenElement || false;
}

function piExitFullScreen()
{
       if( document.exitFullscreen       ) document.exitFullscreen();
  else if( document.msExitFullscreen     ) document.msExitFullscreen();
  else if( document.mozCancelFullScreen  ) document.mozCancelFullScreen();
  else if( document.webkitExitFullscreen ) document.webkitExitFullscreen();
}

function piIsMobile()
{
    return (navigator.userAgent.match(/Android/i) ||
            navigator.userAgent.match(/webOS/i) ||
            navigator.userAgent.match(/iPhone/i) ||
            navigator.userAgent.match(/iPad/i) ||
            navigator.userAgent.match(/iPod/i) ||
            navigator.userAgent.match(/BlackBerry/i) ||
            navigator.userAgent.match(/Windows Phone/i)) ? true : false;
}

function piCreateGlContext( cv, useAlpha, useDepth, usePreserveBuffer, useSupersampling )
{
    var opts = { alpha: useAlpha, 
                 depth: useDepth, 
                 stencil: false, 
                 premultipliedAlpha: false, 
                 antialias: useSupersampling, 
                 preserveDrawingBuffer: usePreserveBuffer, 
                 powerPreference: "high-performance" }; // "low_power", "high_performance", "default"

    var gl = null;
    if( gl === null) gl = cv.getContext( "webgl2", opts );
    if( gl === null) gl = cv.getContext( "experimental-webgl2", opts );
    if( gl === null) gl = cv.getContext( "webgl", opts );
    if( gl === null) gl = cv.getContext( "experimental-webgl", opts );

    return gl;
}

function piCreateAudioContext()
{
    var res = null;
    try
    {
        if( window.AudioContext ) res = new AudioContext();
        if( res==null && window.webkitAudioContext ) res = new webkitAudioContext();
    }
    catch( e )
    {
        res = null;
    }
    return res;
}

function piHexColorToRGB(str) // "#ff3041"
{
    var rgb = parseInt(str.slice(1), 16);
    var r = (rgb >> 16) & 255;
    var g = (rgb >> 8) & 255;
    var b = (rgb >> 0) & 255;
    return [r, g, b];
}

function piCreateFPSCounter()
{
    var mFrame;
    var mTo;
    var mFPS;

    var iReset = function( time )
    {
        mFrame = 0;
        mTo = time;
        mFPS = 60.0;
    }

    var iCount = function( time )
    {
        mFrame++;

        if( (time-mTo)>500.0 )
        {
            mFPS = 1000.0*mFrame/(time-mTo);
            mFrame = 0;
            mTo = time;
            return true;
        }
        return false;
    }

    var iGetFPS = function()
    {
        return mFPS;
    }
    
    return { Reset : iReset, Count : iCount, GetFPS : iGetFPS };
}

function piCanMediaRecorded(canvas)
{
    if (typeof window.MediaRecorder !== 'function' || typeof canvas.captureStream !== 'function') {
        return false;
    }
    return true;
}

function piCreateMediaRecorder(isRecordingCallback, canvas) 
{
    if (piCanMediaRecorded(canvas) == false)
    {
        return null;
    }
    
    var options = { audioBitsPerSecond : 0, videoBitsPerSecond : 8000000 }; 
	     if (MediaRecorder.isTypeSupported('video/webm;codecs=h264')) options.mimeType = 'video/webm;codecs=h264';
    else if (MediaRecorder.isTypeSupported('video/webm;codecs=vp9' )) options.mimeType = 'video/webm;codecs=vp9';
    else if (MediaRecorder.isTypeSupported('video/webm;codecs=vp8' )) options.mimeType = 'video/webm;codecs=vp8';
    else                                                              options.mimeType = 'video/webm;';

    var mediaRecorder = new MediaRecorder(canvas.captureStream(), options);
    var chunks = [];
    
    mediaRecorder.ondataavailable = function(e) 
    {
        if (e.data.size > 0) 
        {
            chunks.push(e.data);
        }
    };
 
    mediaRecorder.onstart = function(){ 
        isRecordingCallback( true );
    };
    
    mediaRecorder.onstop = function()
    {
         isRecordingCallback( false );
         let blob     = new Blob(chunks, {type: "video/webm"});
         chunks       = [];
         let videoURL = window.URL.createObjectURL(blob);
         let url      = window.URL.createObjectURL(blob);
         let a        = document.createElement("a");
         document.body.appendChild(a);
         a.style      = "display: none";
         a.href       = url;
         a.download   = "capture.webm";
         a.click();
         window.URL.revokeObjectURL(url);
     };
    
    return mediaRecorder;
}

function piExportToEXR(width, height, numComponents, type, bytes)
{
    var bytesPerComponent = 0;
    if      (type=="Uint")   bytesPerComponent = 4; 
    else if (type=="Half")   bytesPerComponent = 2;
    else if (type=="Float")  bytesPerComponent = 4;

    var tHeader = 258 + (18 * numComponents + 1);
    var tTable = 8 * height;
    var tScanlines = height * (4 + 4 + (numComponents * bytesPerComponent * width));
    var tTotal = tHeader + tTable + tScanlines;

    //console.log("    header size = " + tHeader);
    //console.log("    table size = " + tTable);
    //console.log("    scanlines size = " + tScanlines);
    //console.log("    total = " + tTotal);

    var buffer = new ArrayBuffer(tTotal); 
    var data = new DataView(buffer);

    // Header
    {
        // Header : 4 bytes -> 0x76, 0x2f, 0x31, 0x01
        var c = 0;
        data.setUint8 (c++, 0x76);
        data.setUint8 (c++, 0x2f);
        data.setUint8 (c++, 0x31);
        data.setUint8 (c++, 0x01);

        // Version : 4 bytes -> 2, 0, 0, 0
        data.setUint8 (c++, 0x02);
        data.setUint8 (c++, 0x0);
        data.setUint8 (c++, 0x0);
        data.setUint8 (c++, 0x0);
        
        // Write channel info
        // Write attribute name : "channels"
            data.setUint8 (c++, 0x63); 
            data.setUint8 (c++, 0x68); 
            data.setUint8 (c++, 0x61); 
            data.setUint8 (c++, 0x6e); 
            data.setUint8 (c++, 0x6e); 
            data.setUint8 (c++, 0x65); 
            data.setUint8 (c++, 0x6c); 
            data.setUint8 (c++, 0x73);
            data.setUint8 (c++, 0x0);

            // Write attribute type : "chlist"
            data.setUint8 (c++, 0x63); 
            data.setUint8 (c++, 0x68); 
            data.setUint8 (c++, 0x6c); 
            data.setUint8 (c++, 0x69); 
            data.setUint8 (c++, 0x73); 
            data.setUint8 (c++, 0x74); 
            data.setUint8 (c++, 0x00);

            // Write attribute size : 18 x 3 + 1 = 55
            var attribSize = 18 * numComponents + 1;
            data.setUint8 (c++, attribSize); 
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x00);

            var i;
            for (i = 0; i < numComponents; i++)
            {
                // Attribute : "B" (42) "G" (47) "R" (52)
                if (i==0)       data.setUint8 (c++, 0x42);
                else if (i==1)  data.setUint8 (c++, 0x47);
                else if (i==2)  data.setUint8 (c++, 0x52);
                data.setUint8 (c++, 0x00);
                
                // Value : Float (2), Half (1), Uint (0)
                if      (type=="Uint")   data.setUint8 (c++, 0x00); 
                else if (type=="Half")   data.setUint8 (c++, 0x01);
                else if (type=="Float")  data.setUint8 (c++, 0x02);
                data.setUint8 (c++, 0x00);
                data.setUint8 (c++, 0x00);
                data.setUint8 (c++, 0x00);

                // Plinear
                data.setUint8 (c++, 0x01);

                // Reserved
                data.setUint8 (c++, 0x00); 
                data.setUint8 (c++, 0x00); 
                data.setUint8 (c++, 0x00); 

                // X sampling
                data.setUint8 (c++, 0x01); 
                data.setUint8 (c++, 0x00); 
                data.setUint8 (c++, 0x00); 
                data.setUint8 (c++, 0x00); 
                
                // Y sampling
                data.setUint8 (c++, 0x01);
                data.setUint8 (c++, 0x00);
                data.setUint8 (c++, 0x00);
                data.setUint8 (c++, 0x00);
            }
            // End attribute
            data.setUint8 (c++, 0x00);
    
        // Write attribute name : "compression"
            data.setUint8 (c++, 0x63); 
            data.setUint8 (c++, 0x6f); 
            data.setUint8 (c++, 0x6d); 
            data.setUint8 (c++, 0x70); 
            data.setUint8 (c++, 0x72); 
            data.setUint8 (c++, 0x65); 
            data.setUint8 (c++, 0x73); 
            data.setUint8 (c++, 0x73); 
            data.setUint8 (c++, 0x69); 
            data.setUint8 (c++, 0x6f); 
            data.setUint8 (c++, 0x6e); 
            data.setUint8 (c++, 0x00);

            // Write attribute type : "compression"
            data.setUint8 (c++, 0x63); 
            data.setUint8 (c++, 0x6f); 
            data.setUint8 (c++, 0x6d); 
            data.setUint8 (c++, 0x70); 
            data.setUint8 (c++, 0x72); 
            data.setUint8 (c++, 0x65); 
            data.setUint8 (c++, 0x73); 
            data.setUint8 (c++, 0x73); 
            data.setUint8 (c++, 0x69); 
            data.setUint8 (c++, 0x6f); 
            data.setUint8 (c++, 0x6e); 
            data.setUint8 (c++, 0x00);

            // Write attribute size : "1"
            data.setUint8 (c++, 0x01); 
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x00);

            // Write attribute value : "0" (None)
            data.setUint8 (c++, 0x00);

        // datawindow
            data.setUint8 (c++, 0x64); 
            data.setUint8 (c++, 0x61); 
            data.setUint8 (c++, 0x74); 
            data.setUint8 (c++, 0x61); 
            data.setUint8 (c++, 0x57); 
            data.setUint8 (c++, 0x69); 
            data.setUint8 (c++, 0x6e); 
            data.setUint8 (c++, 0x64); 
            data.setUint8 (c++, 0x6f); 
            data.setUint8 (c++, 0x77); 
            data.setUint8 (c++, 0x00); 

            // box2i
            data.setUint8 (c++, 0x62); 
            data.setUint8 (c++, 0x6f); 
            data.setUint8 (c++, 0x78); 
            data.setUint8 (c++, 0x32); 
            data.setUint8 (c++, 0x69); 
            data.setUint8 (c++, 0x00);

            // size 16
            data.setUint8 (c++, 0x10); 
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x00);

            // value 0 0 3 2
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x00); 

            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x00); 
            
            data.setUint32 (c, width-1, true);
            c += 4;
            
            data.setUint32 (c, height-1, true); 
            c += 4;

        // displayWindow
            data.setUint8 (c++, 0x64); 
            data.setUint8 (c++, 0x69); 
            data.setUint8 (c++, 0x73); 
            data.setUint8 (c++, 0x70); 
            data.setUint8 (c++, 0x6c); 
            data.setUint8 (c++, 0x61); 
            data.setUint8 (c++, 0x79); 
            data.setUint8 (c++, 0x57); 
            data.setUint8 (c++, 0x69); 
            data.setUint8 (c++, 0x6e); 
            data.setUint8 (c++, 0x64); 
            data.setUint8 (c++, 0x6f); 
            data.setUint8 (c++, 0x77); 
            data.setUint8 (c++, 0x00);

            // box2i
            data.setUint8 (c++, 0x62); 
            data.setUint8 (c++, 0x6f); 
            data.setUint8 (c++, 0x78); 
            data.setUint8 (c++, 0x32); 
            data.setUint8 (c++, 0x69); 
            data.setUint8 (c++, 0x00); 

            // size 16
            data.setUint8 (c++, 0x10); 
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x00);

            // value 0 0 3 2
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x00); 
            
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x00); 
            
            data.setUint32 (c, width-1, true);
            c += 4;
            
            data.setUint32 (c, height-1, true); 
            c += 4;

        // lineOrder
            data.setUint8 (c++, 0x6c); 
            data.setUint8 (c++, 0x69); 
            data.setUint8 (c++, 0x6e); 
            data.setUint8 (c++, 0x65); 
            data.setUint8 (c++, 0x4f); 
            data.setUint8 (c++, 0x72); 
            data.setUint8 (c++, 0x64); 
            data.setUint8 (c++, 0x65); 
            data.setUint8 (c++, 0x72); 
            data.setUint8 (c++, 0x00); 
            
            // lineOrder
            data.setUint8 (c++, 0x6c); 
            data.setUint8 (c++, 0x69); 
            data.setUint8 (c++, 0x6e); 
            data.setUint8 (c++, 0x65); 
            data.setUint8 (c++, 0x4f); 
            data.setUint8 (c++, 0x72); 
            data.setUint8 (c++, 0x64); 
            data.setUint8 (c++, 0x65); 
            data.setUint8 (c++, 0x72); 
            data.setUint8 (c++, 0x00); 
            
            // size
            data.setUint8 (c++, 0x01);
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x00);
            
            // value 
            data.setUint8 (c++, 0x00);

        // PixelAspectRatio
            data.setUint8 (c++, 0x70); 
            data.setUint8 (c++, 0x69); 
            data.setUint8 (c++, 0x78); 
            data.setUint8 (c++, 0x65); 
            data.setUint8 (c++, 0x6c); 
            data.setUint8 (c++, 0x41); 
            data.setUint8 (c++, 0x73); 
            data.setUint8 (c++, 0x70); 
            data.setUint8 (c++, 0x65); 
            data.setUint8 (c++, 0x63); 
            data.setUint8 (c++, 0x74); 
            data.setUint8 (c++, 0x52); 
            data.setUint8 (c++, 0x61); 
            data.setUint8 (c++, 0x74); 
            data.setUint8 (c++, 0x69); 
            data.setUint8 (c++, 0x6f); 
            data.setUint8 (c++, 0x00); 

            // float
            data.setUint8 (c++, 0x66); 
            data.setUint8 (c++, 0x6c); 
            data.setUint8 (c++, 0x6f); 
            data.setUint8 (c++, 0x61); 
            data.setUint8 (c++, 0x74); 
            data.setUint8 (c++, 0x00);
        
            // size 4
            data.setUint8 (c++, 0x04); 
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x00);

            // value 1.0
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x80); 
            data.setUint8 (c++, 0x3f);
        
        // screenWindowCenter
            data.setUint8 (c++, 0x73); 
            data.setUint8 (c++, 0x63);
            data.setUint8 (c++, 0x72); 
            data.setUint8 (c++, 0x65); 
            data.setUint8 (c++, 0x65); 
            data.setUint8 (c++, 0x6e); 
            data.setUint8 (c++, 0x57); 
            data.setUint8 (c++, 0x69); 
            data.setUint8 (c++, 0x6e); 
            data.setUint8 (c++, 0x64); 
            data.setUint8 (c++, 0x6f); 
            data.setUint8 (c++, 0x77); 
            data.setUint8 (c++, 0x43); 
            data.setUint8 (c++, 0x65); 
            data.setUint8 (c++, 0x6e);
            data.setUint8 (c++, 0x74); 
            data.setUint8 (c++, 0x65); 
            data.setUint8 (c++, 0x72); 
            data.setUint8 (c++, 0x00);

            // v2f
            data.setUint8 (c++, 0x76); 
            data.setUint8 (c++, 0x32); 
            data.setUint8 (c++, 0x66); 
            data.setUint8 (c++, 0x00);

            // size 8
            data.setUint8 (c++, 0x08); 
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x00);

            // value 0 0
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x00); 
            
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x00);

        // screenWindowWidth
            data.setUint8 (c++, 0x73); 
            data.setUint8 (c++, 0x63); 
            data.setUint8 (c++, 0x72); 
            data.setUint8 (c++, 0x65); 
            data.setUint8 (c++, 0x65); 
            data.setUint8 (c++, 0x6e); 
            data.setUint8 (c++, 0x57); 
            data.setUint8 (c++, 0x69); 
            data.setUint8 (c++, 0x6e); 
            data.setUint8 (c++, 0x64); 
            data.setUint8 (c++, 0x6f); 
            data.setUint8 (c++, 0x77); 
            data.setUint8 (c++, 0x57); 
            data.setUint8 (c++, 0x69); 
            data.setUint8 (c++, 0x64); 
            data.setUint8 (c++, 0x74); 
            data.setUint8 (c++, 0x68); 
            data.setUint8 (c++, 0x00); 
            
            // float
            data.setUint8 (c++, 0x66); 
            data.setUint8 (c++, 0x6c); 
            data.setUint8 (c++, 0x6f); 
            data.setUint8 (c++, 0x61); 
            data.setUint8 (c++, 0x74); 
            data.setUint8 (c++, 0x00); 

            // size
            data.setUint8 (c++, 0x04); 
            data.setUint8 (c++, 0x00);
            data.setUint8 (c++, 0x00);
            data.setUint8 (c++, 0x00);

            // value
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x00); 
            data.setUint8 (c++, 0x80); 
            data.setUint8 (c++, 0x3f);

        // End of header
        data.setUint8 (c++, 0x00);
    }
    //console.log("header size = " + c);

    // Scanline table
    var initc = c + height * 8;
    for (var scanline = 0 ; scanline < height ; scanline ++)
    {
        var jump = initc + scanline * (8 + width * bytesPerComponent * numComponents); 
        data.setUint32 (c, jump, true);
        c += 4; 

        data.setUint32 (c, 0x00, true);
        c += 4;
    }
    //console.log("header + scanlines table size = " + c);

    // Scanlines
    for (var scanline = 0 ; scanline < height ; scanline ++)
    {
        // Scanline
        data.setUint32(c, scanline, true);
        c += 4;

        // size 24
        var size = width * numComponents * bytesPerComponent; 
        data.setUint32(c, size, true);
        c += 4;

        var numComponentsSource = 4; // number of components in the SOURCE image
        for (var component = 0; component < numComponents ; component ++) 
        {
            for (var pixel = 0 ; pixel < width ; pixel ++) 
            {
                // flip vertical, so we read OpenGL buffers without JS image flipping
                var v = bytes[(height-1-scanline) * width *numComponentsSource + pixel * numComponentsSource + (2-component)];
                if      (type=="Float") data.setFloat32(c, v, true);
                else if (type=="Half")  data.setUint16(c, v, true);

                c += bytesPerComponent;
            }
        }
    }
    //console.log("total size = " + c);
    return new Blob([buffer], {type: 'application/octet-stream'});
}


function piExportToWAV(numSamples, rate, bits, numChannels, words)
{
    let numBytes = numSamples * numChannels * bits/8;

    let buffer = new ArrayBuffer(44 + numBytes); 
    let data = new DataView(buffer);

    {
        data.setUint32( 0, 0x46464952, true );  // RIFF
        data.setUint32( 4, numBytes + 36, true);
        {
            data.setUint32( 8, 0x45564157, true );  // WAV_WAVE
            data.setUint32( 12, 0x20746D66, true );  // WAV_FMT
            {
                data.setUint32( 16, 16, true);
                data.setUint16( 20, 1, true ); // WAV_FORMAT_PCM
                data.setUint16( 22, numChannels, true);
                data.setUint32( 24, rate, true);
                data.setUint32( 28, rate*numChannels*bits / 8, true);
                data.setUint16( 32, numChannels*bits / 8, true);
                data.setUint16( 34, bits, true);
            }

            data.setUint32( 36, 0x61746164, true);  // WAV_DATA
            {
                data.setUint32( 40, numBytes, true);
                let numWords = numSamples * numChannels;
                for(let i=0; i<numWords; i++ )
                {
                    data.setInt16( 44 + i*2, words[i], true );
                }
            }
        }
    }


    //console.log("total size = " + c);
    return new Blob([buffer], {type: 'application/octet-stream'});
}

function piTriggerDownload(name, blob)
{
    let url = URL.createObjectURL(blob);
    let aElement = document.createElement("a");
    aElement.href     = url;
    aElement.target   = "_self";
    aElement.download = name;
    document.body.appendChild(aElement);
    aElement.click();
    document.body.removeChild(aElement);
}</script>
    <script>"use strict"

function bufferID_to_assetID( id )
{
    if( id===0 ) return '4dXGR8';
    if( id===1 ) return 'XsXGR8';
    if( id===2 ) return '4sXGR8';
    if( id===3 ) return 'XdfGR8';
    return 'none';
}
function assetID_to_bufferID( id )
{
    if( id==='4dXGR8' ) return 0;
    if( id==='XsXGR8' ) return 1;
    if( id==='4sXGR8' ) return 2;
    if( id==='XdfGR8' ) return 3;
    return -1;
}

function assetID_to_cubemapBuferID( id )
{
    if( id==='4dX3Rr' ) return 0;
    return -1;
}
function cubamepBufferID_to_assetID( id )
{
    if( id===0 ) return '4dX3Rr';
    return 'none';
}

function EffectPass( renderer, is20, isLowEnd, hasShaderTextureLOD, callback, obj, forceMuted, forcePaused, outputGainNode, copyProgram, id, effect  )
{
    this.mID = id;
    this.mInputs  = [null, null, null, null ];
    this.mOutputs = [null, null, null, null ];
    this.mSource = null;

    this.mGainNode = outputGainNode;
    this.mSoundShaderCompiled = false;

    this.mEffect = effect;
    this.mRenderer = renderer;
    this.mProgramCopy = copyProgram; 
    this.mCompilationTime = 0;

    this.mType = "none";
    this.mName = "none";
    this.mFrame = 0;

    this.mShaderTextureLOD = hasShaderTextureLOD;
    this.mIs20 = is20;
    this.mIsLowEnd = isLowEnd;
    this.mTextureCallbackFun = callback;
    this.mTextureCallbackObj = obj;
    this.mForceMuted = forceMuted;
    this.mForcePaused = forcePaused;
}

EffectPass.prototype.MakeHeader_Image = function()
{
    let header = "";

    header += "#define HW_PERFORMANCE " + ((this.mIsLowEnd===true)?"0":"1") + "\n";

    header += "uniform vec3      iResolution;\n" +
              "uniform float     iTime;\n" +
              "uniform float     iChannelTime[4];\n" +
              "uniform vec4      iMouse;\n" +
              "uniform vec4      iDate;\n" +
              "uniform float     iSampleRate;\n" +
              "uniform vec3      iChannelResolution[4];\n" +
              "uniform int       iFrame;\n" +
              "uniform float     iTimeDelta;\n" +
              "uniform float     iFrameRate;\n";

    for( let i=0; i<this.mInputs.length; i++ )
    {
        let inp = this.mInputs[i];

        // old API
             if( inp===null )                  header += "uniform sampler2D iChannel" + i + ";\n";
        else if( inp.mInfo.mType==="cubemap" ) header += "uniform samplerCube iChannel" + i + ";\n";
        else if( inp.mInfo.mType==="volume"  ) header += "uniform sampler3D iChannel" + i + ";\n";
        else                                  header += "uniform sampler2D iChannel" + i + ";\n";

        // new API (see shadertoy.com/view/wtdGW8)
        header += "uniform struct {\n";
             if( inp===null )                  header += "  sampler2D";
        else if( inp.mInfo.mType==="cubemap" ) header += "  samplerCube";
        else if( inp.mInfo.mType==="volume"  ) header += "  sampler3D";
        else                                  header += "  sampler2D";
        header +=        " sampler;\n";
        header += "  vec3  size;\n";
        header += "  float time;\n";
        header += "  int   loaded;\n";
        header += "}iCh" + i + ";\n";
    }
	header += "void mainImage( out vec4 c, in vec2 f );\n";
    header += "void st_assert( bool cond );\n";
    header += "void st_assert( bool cond, int v );\n";

    if( this.mIs20 ) 
    {
        header += "\nout vec4 shadertoy_out_color;\n" +
        "void st_assert( bool cond, int v ) {if(!cond){if(v==0)shadertoy_out_color.x=-1.0;else if(v==1)shadertoy_out_color.y=-1.0;else if(v==2)shadertoy_out_color.z=-1.0;else shadertoy_out_color.w=-1.0;}}\n" +
        "void st_assert( bool cond        ) {if(!cond)shadertoy_out_color.x=-1.0;}\n" +
        "void main( void )" +
        "{" +
            "shadertoy_out_color = vec4(1.0,1.0,1.0,1.0);" + 
            "vec4 color = vec4(0.0,0.0,0.0,1.0);" +
            "mainImage( color, gl_FragCoord.xy );" +
            "if(shadertoy_out_color.x<0.0) color=vec4(1.0,0.0,0.0,1.0);" +
            "if(shadertoy_out_color.y<0.0) color=vec4(0.0,1.0,0.0,1.0);" +
            "if(shadertoy_out_color.z<0.0) color=vec4(0.0,0.0,1.0,1.0);" +
            "if(shadertoy_out_color.w<0.0) color=vec4(1.0,1.0,0.0,1.0);" +
            "shadertoy_out_color = vec4(color.xyz,1.0);" +
        "}";
    }
    else
    {
        header += "" +
        "void st_assert( bool cond, int v ) {if(!cond){if(v==0)gl_FragColor.x=-1.0;else if(v==1)gl_FragColor.y=-1.0;else if(v==2)gl_FragColor.z=-1.0;else gl_FragColor.w=-1.0;}}\n" +
        "void st_assert( bool cond        ) {if(!cond)gl_FragColor.x=-1.0;}\n" +
        "void main( void )" +
        "{" +
            "gl_FragColor = vec4(0.0,0.0,0.0,1.0);" + 
            "vec4 color = vec4(0.0,0.0,0.0,1.0);" +
            "mainImage( color, gl_FragCoord.xy );" +
            "color.w = 1.0;" +
            "if(gl_FragColor.w<0.0) color=vec4(1.0,0.0,0.0,1.0);" +
            "if(gl_FragColor.x<0.0) color=vec4(1.0,0.0,0.0,1.0);" +
            "if(gl_FragColor.y<0.0) color=vec4(0.0,1.0,0.0,1.0);" +
            "if(gl_FragColor.z<0.0) color=vec4(0.0,0.0,1.0,1.0);" +
            "if(gl_FragColor.w<0.0) color=vec4(1.0,1.0,0.0,1.0);" +
            "gl_FragColor = vec4(color.xyz,1.0);"+
        "}";
    }
    header += "\n";

    /*
    this.mImagePassFooterVR = "\n" +
    "uniform vec4 unViewport;\n" +
    "uniform vec3 unCorners[5];\n";
    if( this.mIs20 ) 
        this.mImagePassFooterVR += "\nout vec4 outColor;\n";
    this.mImagePassFooterVR += "void main( void )" +
    "{" +
        "vec4 color = vec4(0.0,0.0,0.0,1.0);" +

        "vec3 ro = unCorners[4];" +
        "vec2 uv = (gl_FragCoord.xy - unViewport.xy)/unViewport.zw;" + 
        "vec3 rd = normalize( mix( mix( unCorners[0], unCorners[1], uv.x )," +
                                  "mix( unCorners[3], unCorners[2], uv.x ), uv.y ) - ro);" + 

        "mainVR( color, gl_FragCoord.xy-unViewport.xy, ro, rd );" +
        "color.w = 1.0;"
    if( this.mIs20 ) 
        this.mImagePassFooterVR +=  "outColor = color;}";
    else
        this.mImagePassFooterVR +=  "gl_FragColor = color;}";
    */
    this.mHeader = header;
    this.mHeaderLength = 0;
}

EffectPass.prototype.MakeHeader_Buffer = function()
{
    let header = "";
    
    header += "#define HW_PERFORMANCE " + ((this.mIsLowEnd===true)?"0":"1") + "\n";

    header += "uniform vec3      iResolution;\n" +
              "uniform float     iTime;\n" +
              "uniform float     iChannelTime[4];\n" +
              "uniform vec4      iMouse;\n" +
              "uniform vec4      iDate;\n" +
              "uniform float     iSampleRate;\n" +
              "uniform vec3      iChannelResolution[4];\n" +
              "uniform int       iFrame;\n" +
              "uniform float     iTimeDelta;\n" +
              "uniform float     iFrameRate;\n";

    for (let i = 0; i < this.mInputs.length; i++)
    {
        let inp = this.mInputs[i];
             if( inp===null )                  header += "uniform sampler2D iChannel" + i + ";\n";
        else if( inp.mInfo.mType==="cubemap" ) header += "uniform samplerCube iChannel" + i + ";\n";
        else if( inp.mInfo.mType==="volume"  ) header += "uniform sampler3D iChannel" + i + ";\n";
        else                                  header += "uniform sampler2D iChannel" + i + ";\n";
    }

	header += "void mainImage( out vec4 c,  in vec2 f );\n"

    if( this.mIs20 )
        header += "\nout vec4 outColor;\n";
    header += "\nvoid main( void )\n" +
    "{" +
        "vec4 color = vec4(0.0,0.0,0.0,1.0);" +
        "mainImage( color, gl_FragCoord.xy );";
    if( this.mIs20 )
        header +="outColor = color; }";
    else
        header +="gl_FragColor = color; }";
    header += "\n";

    /*
    this.mImagePassFooterVR = "\n" +
    "uniform vec4 unViewport;\n" +
    "uniform vec3 unCorners[5];\n";
    if( this.mIs20 )
    this.mImagePassFooterVR += "\nout vec4 outColor;\n";
    this.mImagePassFooterVR += "\nvoid main( void )\n" +
    "{" +
        "vec4 color = vec4(0.0,0.0,0.0,1.0);" +

        "vec3 ro = unCorners[4];" +
        "vec2 uv = (gl_FragCoord.xy - unViewport.xy)/unViewport.zw;" + 
        "vec3 rd = normalize( mix( mix( unCorners[0], unCorners[1], uv.x )," +
                                  "mix( unCorners[3], unCorners[2], uv.x ), uv.y ) - ro);" + 

        "mainVR( color, gl_FragCoord.xy-unViewport.xy, ro, rd );";
    if( this.mIs20 )
        this.mImagePassFooterVR +="outColor = color; }";
    else
        this.mImagePassFooterVR +="gl_FragColor = color; }";
    */
    this.mHeader = header;
    this.mHeaderLength = 0;
}


EffectPass.prototype.MakeHeader_Cubemap = function()
{
    let header = "";
    
    header += "#define HW_PERFORMANCE " + ((this.mIsLowEnd===true)?"0":"1") + "\n";

    header += "uniform vec3      iResolution;\n" +
              "uniform float     iTime;\n" +
              "uniform float     iChannelTime[4];\n" +
              "uniform vec4      iMouse;\n" +
              "uniform vec4      iDate;\n" +
              "uniform float     iSampleRate;\n" +
              "uniform vec3      iChannelResolution[4];\n" +
              "uniform int       iFrame;\n" +
              "uniform float     iTimeDelta;\n" +
              "uniform float     iFrameRate;\n";

    for (let i = 0; i < this.mInputs.length; i++)
    {
        let inp = this.mInputs[i];
             if( inp===null )                  header += "uniform sampler2D iChannel" + i + ";\n";
        else if( inp.mInfo.mType==="cubemap" ) header += "uniform samplerCube iChannel" + i + ";\n";
        else if( inp.mInfo.mType==="volume"  ) header += "uniform sampler3D iChannel" + i + ";\n";
        else                                   header += "uniform sampler2D iChannel" + i + ";\n";
    }

	header += "void mainCubemap( out vec4 c, in vec2 f, in vec3 ro, in vec3 rd );\n"

    header += "\n" +
    "uniform vec4 unViewport;\n" +
    "uniform vec3 unCorners[5];\n";
    if( this.mIs20 )
        header += "\nout vec4 outColor;\n";
    header += "\nvoid main( void )\n" +
    "{" +
        "vec4 color = vec4(0.0,0.0,0.0,1.0);" +

        "vec3 ro = unCorners[4];" +
        "vec2 uv = (gl_FragCoord.xy - unViewport.xy)/unViewport.zw;" + 
        "vec3 rd = normalize( mix( mix( unCorners[0], unCorners[1], uv.x )," +
                                  "mix( unCorners[3], unCorners[2], uv.x ), uv.y ) - ro);" + 

        "mainCubemap( color, gl_FragCoord.xy-unViewport.xy, ro, rd );";
    if( this.mIs20 )
        header +="outColor = color; }";
    else
        header +="gl_FragColor = color; }";
    header += "\n";

    this.mHeader = header;
    this.mHeaderLength = 0;
}

EffectPass.prototype.MakeHeader_Sound = function()
{
    let header = "";

    header += "#define HW_PERFORMANCE " + ((this.mIsLowEnd===true)?"0":"1") + "\n";

    header += "uniform float     iChannelTime[4];\n" +
              "uniform float     iTimeOffset;\n" +
              "uniform int       iSampleOffset;\n" +
              "uniform vec4      iDate;\n" +
              "uniform float     iSampleRate;\n" +
              "uniform vec3      iChannelResolution[4];\n";

    for (let i=0; i<this.mInputs.length; i++ )
    {
        let inp = this.mInputs[i];

        if( inp!==null && inp.mInfo.mType==="cubemap" )
            header += "uniform samplerCube iChannel" + i + ";\n";
        else
            header += "uniform sampler2D iChannel" + i + ";\n";
    }
    header += "\n";
    header += "vec2 mainSound( in int samp, float time );\n";

    if( this.mIs20 )
    {
        header += "out vec4 outColor; void main()" +
            "{" +
            "float t = iTimeOffset + ((gl_FragCoord.x-0.5) + (gl_FragCoord.y-0.5)*512.0)/iSampleRate;" +
            "int   s = iSampleOffset + int(gl_FragCoord.y-0.2)*512 + int(gl_FragCoord.x-0.2);" +
            "vec2 y = mainSound( s, t );" +
            "vec2 v  = floor((0.5+0.5*y)*65536.0);" +
            "vec2 vl =   mod(v,256.0)/255.0;" +
            "vec2 vh = floor(v/256.0)/255.0;" +
            "outColor = vec4(vl.x,vh.x,vl.y,vh.y);" +
            "}";
    }
    else
    {
        header += "void main()" +
            "{" +
            "float t = iTimeOffset + ((gl_FragCoord.x-0.5) + (gl_FragCoord.y-0.5)*512.0)/iSampleRate;" +
            "vec2 y = mainSound( 0, t );" +
            "vec2 v  = floor((0.5+0.5*y)*65536.0);" +
            "vec2 vl =   mod(v,256.0)/255.0;" +
            "vec2 vh = floor(v/256.0)/255.0;" +
            "gl_FragColor = vec4(vl.x,vh.x,vl.y,vh.y);" +
            "}";
    }
    header += "\n";
    this.mHeader = header;
    this.mHeaderLength = 0;
}


EffectPass.prototype.MakeHeader_Common = function ()
{
    let header = "";
    let headerlength = 0;

    header += "uniform vec4      iDate;\n" +
              "uniform float     iSampleRate;\n";
    headerlength += 2;

    if (this.mIs20)
    {
        header += "out vec4 outColor;\n";
        headerlength += 1;
    }
    header += "void main( void )\n";
    headerlength += 1;

    if (this.mIs20)
        header += "{ outColor = vec4(0.0); }";
    else
        header += "{ gl_FragColor = vec4(0.0); }";
    headerlength += 1;
    header += "\n";
    headerlength += 1;

    this.mHeader = header;
    this.mHeaderLength = headerlength;
}

EffectPass.prototype.MakeHeader = function()
{
         if( this.mType==="image" ) this.MakeHeader_Image();
    else if( this.mType==="sound" ) this.MakeHeader_Sound();
    else if( this.mType==="buffer") this.MakeHeader_Buffer();
    else if( this.mType==="common") this.MakeHeader_Common();
    else if( this.mType==="cubemap") this.MakeHeader_Cubemap();
    else console.log("ERROR 4");
}

EffectPass.prototype.Create_Image = function( wa )
{
    this.MakeHeader();
    this.mSampleRate = 44100;
    this.mSupportsVR = false;
    this.mProgram = null;
    this.mError = false;
    this.mErrorStr = "";
    this.mTranslatedSource = null;
    //this.mProgramVR = null;
}
EffectPass.prototype.Destroy_Image = function( wa )
{
}

EffectPass.prototype.Create_Buffer = function( wa )
{
    this.MakeHeader();
    this.mSampleRate = 44100;
    this.mSupportsVR = false;
    this.mProgram = null;
    this.mError = false;
    this.mErrorStr = "";
    this.mTranslatedSource = null;
    //this.mProgramVR = null;
}

EffectPass.prototype.Destroy_Buffer = function( wa )
{
}

EffectPass.prototype.Create_Cubemap = function( wa )
{
    this.MakeHeader();
    this.mSampleRate = 44100;
    this.mProgram = null;
    this.mError = false;
    this.mErrorStr = "";
    this.mTranslatedSource = null;
}

EffectPass.prototype.Destroy_Cubemap = function( wa )
{
}

EffectPass.prototype.Create_Common = function( wa )
{
    this.mProgram = null;
    this.mError = false;
    this.mErrorStr = "";
    this.MakeHeader();
}
EffectPass.prototype.Destroy_Common = function( wa )
{
}

EffectPass.prototype.Create_Sound = function (wa)
{
    this.MakeHeader();


    this.mProgram = null;
    this.mError = false;
    this.mErrorStr = "";
    this.mTranslatedSource = null;
    this.mSampleRate = 44100;
    this.mPlayTime = 60*3;
    this.mPlaySamples = this.mPlayTime*this.mSampleRate;
    this.mBuffer = wa.createBuffer( 2, this.mPlaySamples, this.mSampleRate );

    //-------------------
    this.mTextureDimensions = 512;
    this.mRenderTexture = this.mRenderer.CreateTexture(this.mRenderer.TEXTYPE.T2D, 
                                                       this.mTextureDimensions, this.mTextureDimensions,
                                                       this.mRenderer.TEXFMT.C4I8,
                                                       this.mRenderer.FILTER.NONE,
                                                       this.mRenderer.TEXWRP.CLAMP, null);
    this.mRenderFBO = this.mRenderer.CreateRenderTarget(this.mRenderTexture, null, null, null, null, false);

    //-----------------------------

    // ArrayBufferView pixels;
    this.mTmpBufferSamples = this.mTextureDimensions*this.mTextureDimensions;
    this.mData = new Uint8Array( this.mTmpBufferSamples*4 );

    this.mPlaying = false;
}

EffectPass.prototype.Destroy_Sound = function( wa )
{
    if( this.mPlayNode!==null ) this.mPlayNode.stop();
    this.mPlayNode = null;
    this.mBuffer = null;
    this.mData = null;

    this.mRenderer.DestroyRenderTarget(this.mRenderFBO);
    this.mRenderer.DestroyTexture(this.mRenderTexture);
}

EffectPass.prototype.Create = function( passType, wa )
{
    this.mType = passType;
    this.mSource = null;

         if( passType==="image" ) this.Create_Image( wa );
    else if( passType==="sound" ) this.Create_Sound( wa );
    else if( passType==="buffer") this.Create_Buffer( wa );
    else if( passType==="common") this.Create_Common( wa );
    else if( passType==="cubemap") this.Create_Cubemap( wa );
    else alert("ERROR 1");
}

EffectPass.prototype.SetName = function (passName)
{
    this.mName = passName;
}

EffectPass.prototype.SetCode = function (src)
{
    this.mSource = src;
}

EffectPass.prototype.Destroy = function( wa )
{
    this.mSource = null;
         if( this.mType==="image" ) this.Destroy_Image( wa );
    else if( this.mType==="sound" ) this.Destroy_Sound( wa );
    else if( this.mType==="buffer") this.Destroy_Buffer( wa );
    else if( this.mType==="common") this.Destroy_Common( wa );
    else if( this.mType==="cubemap") this.Destroy_Cubemap( wa );
    else alert("ERROR 2");
}

EffectPass.prototype.NewShader_Sound = function( shaderCode, commonShaderCodes)
{
    let vsSource = null;

    if( this.mIs20 )
        vsSource = "layout(location = 0) in vec2 pos; void main() { gl_Position = vec4(pos.xy,0.0,1.0); }";
    else
        vsSource = "attribute vec2 pos; void main() { gl_Position = vec4(pos.xy,0.0,1.0); }";

    let fsSource = this.mHeader;
    for( let i=0; i<commonShaderCodes.length; i++ )
    {
        fsSource += commonShaderCodes[i]+'\n';
    }
    this.mHeaderLength = fsSource.split(/\r\n|\r|\n/).length;
    fsSource += shaderCode;

    this.mSoundShaderCompiled = false;

    return [vsSource, fsSource];
}

EffectPass.prototype.NewShader_Image = function ( shaderCode, commonShaderCodes )
{
    this.mSupportsVR = false;


    let vsSource = null;
    if( this.mIs20 )
        vsSource = "layout(location = 0) in vec2 pos; void main() { gl_Position = vec4(pos.xy,0.0,1.0); }";
    else
        vsSource = "attribute vec2 pos; void main() { gl_Position = vec4(pos.xy,0.0,1.0); }";

    let fsSource = this.mHeader;
    for (let i = 0; i < commonShaderCodes.length; i++)
    {
        fsSource += commonShaderCodes[i]+'\n';
    }
    this.mHeaderLength = fsSource.split(/\r\n|\r|\n/).length;
    fsSource += shaderCode;

    return [vsSource, fsSource];


    /*
    let n1 = shaderCode.indexOf("mainVR(");
    let n2 = shaderCode.indexOf("mainVR (");
    let n3 = shaderCode.indexOf("mainVR  (");
    if( n1>0 || n2>0 || n3>0 )
    {
        let vsSourceVR;
        if( this.mIs20 )
            vsSourceVR = "layout(location = 0) in vec2 pos; void main() { gl_Position = vec4(pos.xy,0.0,1.0); }";
        else
            vsSourceVR = "attribute in vec2 pos; void main() { gl_Position = vec4(pos.xy,0.0,1.0); }";

        let fsSourceVR = this.mHeader;
        for (let i = 0; i < commonShaderCodes.length; i++) {
            fsSourceVR += commonShaderCodes[i];
        }
        fsSourceVR += shaderCode;
        fsSourceVR += this.mImagePassFooterVR;

        let res = this.mRenderer.CreateShader(vsSource, fsSourceVR, preventCache);
        if( res.mResult == false )
        {
            return res.mInfo;
        }
        if( this.mProgramVR != null )
            this.mRenderer.DestroyShader( this.mProgramVR );

        this.mSupportsVR = true;
        this.mProgramVR = res;
    }
    */
}

EffectPass.prototype.NewShader_Cubemap = function( shaderCode, commonShaderCodes )
{
    let vsSource = null;
    if( this.mIs20 )
        vsSource = "layout(location = 0) in vec2 pos; void main() { gl_Position = vec4(pos.xy,0.0,1.0); }";
    else
        vsSource = "attribute vec2 pos; void main() { gl_Position = vec4(pos.xy,0.0,1.0); }";

    let fsSource = this.mHeader;
    for (let i = 0; i < commonShaderCodes.length; i++)
    {
        fsSource += commonShaderCodes[i]+'\n';
    }

    this.mHeaderLength = fsSource.split(/\r\n|\r|\n/).length;

    fsSource += shaderCode;

    return [vsSource, fsSource];
}


EffectPass.prototype.NewShader_Common = function (shaderCode )
{
    let vsSource = null;
    if (this.mIs20)
        vsSource = "layout(location = 0) in vec2 pos; void main() { gl_Position = vec4(pos.xy,0.0,1.0); }";
    else
        vsSource = "attribute vec2 pos; void main() { gl_Position = vec4(pos.xy,0.0,1.0); }";

    let fsSource = this.mHeader + shaderCode;

    return [vsSource, fsSource];
}

EffectPass.prototype.NewShader = function ( commonSourceCodes, preventCache, onResolve)
{
    if( this.mRenderer===null ) return;

    let vs_fs = null;

         if( this.mType==="sound"  ) vs_fs = this.NewShader_Sound(   this.mSource, commonSourceCodes );
    else if( this.mType==="image"  ) vs_fs = this.NewShader_Image(   this.mSource, commonSourceCodes );
    else if( this.mType==="buffer" ) vs_fs = this.NewShader_Image(   this.mSource, commonSourceCodes );
    else if( this.mType==="common" ) vs_fs = this.NewShader_Common(  this.mSource,                   );
    else if( this.mType==="cubemap") vs_fs = this.NewShader_Cubemap( this.mSource, commonSourceCodes );
    else { console.log("ERROR 3: \"" + this.mType + "\""); return; }

    let me = this;
    this.mRenderer.CreateShader(vs_fs[0], vs_fs[1], preventCache, false,
        function (worked, info)
        {
            if (worked === true)
            {
                if (me.mType === "sound")
                {
                    me.mSoundShaderCompiled = true;
                }

                me.mCompilationTime = info.mTime;
                me.mError = false;
                me.mErrorStr = "No Errors";
                if (me.mProgram !== null)
                    me.mRenderer.DestroyShader(me.mProgram);
                me.mTranslatedSource = me.mRenderer.GetTranslatedShaderSource(info);
                me.mProgram = info;
            }
            else
            {
                me.mError = true;
                me.mErrorStr = info.mErrorStr;
            }
            onResolve();
        });
}

EffectPass.prototype.DestroyInput = function( id )
{
    if( this.mInputs[id]===null ) return;

    if( this.mInputs[id].mInfo.mType==="texture" )
    {
        if( this.mInputs[id].globject !== null )
            this.mRenderer.DestroyTexture(this.mInputs[id].globject);
    }
    if( this.mInputs[id].mInfo.mType==="volume" )
    {
        if( this.mInputs[id].globject !== null )
            this.mRenderer.DestroyTexture(this.mInputs[id].globject);
    }
    else if( this.mInputs[id].mInfo.mType==="webcam" )
    {
        this.mInputs[id].video.pause();
        this.mInputs[id].video.src = "";

        if( this.mInputs[id].video.srcObject!==null )
        {
        let tracks = this.mInputs[id].video.srcObject.getVideoTracks();
        if( tracks ) tracks[0].stop();
        }
        this.mInputs[id].video = null;
        if( this.mInputs[id].globject !== null )
            this.mRenderer.DestroyTexture(this.mInputs[id].globject);
    }
    else if( this.mInputs[id].mInfo.mType==="video" )
    {
        this.mInputs[id].video.pause();
        this.mInputs[id].video = null;
        if( this.mInputs[id].globject !== null )
            this.mRenderer.DestroyTexture(this.mInputs[id].globject);
    }
    else if( this.mInputs[id].mInfo.mType==="music" || this.mInputs[id].mInfo.mType==="musicstream")
    {
        this.mInputs[id].audio.pause();
        this.mInputs[id].audio.mSound.mFreqData = null;
        this.mInputs[id].audio.mSound.mWaveData = null;
        this.mInputs[id].audio = null;
        if( this.mInputs[id].globject !== null )
            this.mRenderer.DestroyTexture(this.mInputs[id].globject);
    }
    else if( this.mInputs[id].mInfo.mType==="cubemap" )
    {
        if( this.mInputs[id].globject !== null )
            this.mRenderer.DestroyTexture(this.mInputs[id].globject);
    }
    else if( this.mInputs[id].mInfo.mType==="keyboard" )
    {
        //if( this.mInputs[id].globject != null )
          //  this.mRenderer.DestroyTexture(this.mInputs[id].globject);
    }
    else if( this.mInputs[id].mInfo.mType==="mic" )
    {
        this.mInputs[id].mic = null;
        if( this.mInputs[id].globject !== null )
            this.mRenderer.DestroyTexture(this.mInputs[id].globject);
    }

    this.mInputs[id] = null;
}

EffectPass.prototype.TooglePauseInput = function( wa, id )
{
    var me = this;
    let inp = this.mInputs[id];

    if( inp===null )
    {
    }
    else if( inp.mInfo.mType==="texture" )
    {
    }
    else if( inp.mInfo.mType==="volume" )
    {
    }
    else if( inp.mInfo.mType==="video" )
    {
        if( inp.video.mPaused )
        {
            inp.video.play();
            inp.video.mPaused = false;
        }
        else
        {
            inp.video.pause();
            inp.video.mPaused = true;
        }
        return inp.video.mPaused;
    }
    else if( inp.mInfo.mType==="music" || inp.mInfo.mType==="musicstream")
    {
        wa.resume()
        if( inp.audio.mPaused )
        {
            if( inp.loaded )
            {
                inp.audio.play();
            }
            inp.audio.mPaused = false;
        }
        else
        {
            inp.audio.pause();
            inp.audio.mPaused = true;
        }
        return inp.audio.mPaused;
    }

    return null;
}

EffectPass.prototype.StopInput = function( id )
{
    let inp = this.mInputs[id];

    if( inp===null )
    {
    }
    else if( inp.mInfo.mType==="texture" )
    {
    }
    else if( inp.mInfo.mType==="volume" )
    {
    }
    else if( inp.mInfo.mType==="video" )
    {
        if( inp.video.mPaused === false )
        {
            inp.video.pause();
            inp.video.mPaused = true;
        }
        return inp.video.mPaused;
    }
    else if( inp.mInfo.mType==="music" || inp.mInfo.mType==="musicstream" )
    {
        if( inp.audio.mPaused === false )
        {
            inp.audio.pause();
            inp.audio.mPaused = true;
        }
        return inp.audio.mPaused;
    }
    return null;
}

EffectPass.prototype.ResumeInput = function( id )
{
    let inp = this.mInputs[id];

    if( inp===null )
    {
    }
    else if( inp.mInfo.mType==="texture" )
    {
    }
    else if( inp.mInfo.mType==="volume" )
    {
    }
    else if( inp.mInfo.mType==="video" )
    {
        if( inp.video.mPaused )
        {
            inp.video.play();
            inp.video.mPaused = false;
        }
        return inp.video.mPaused;
    }
    else if( inp.mInfo.mType==="music" || inp.mInfo.mType==="musicstream" )
    {
        if( inp.audio.mPaused )
        {
            inp.audio.play();
            inp.audio.mPaused = false;
        }
        return inp.audio.mPaused;
    }
    return null;
}

EffectPass.prototype.RewindInput = function( wa, id )
{
    var me = this;
    let inp = this.mInputs[id];

    if( inp==null )
    {
    }
    else if( inp.mInfo.mType==="texture" )
    {
    }
    else if( inp.mInfo.mType==="volume" )
    {
    }
    else if( inp.mInfo.mType==="video" )
    {
        if( inp.loaded )
        {
            inp.video.currentTime = 0;
        }
    }
    else if( inp.mInfo.mType==="music" || inp.mInfo.mType==="musicstream")
    {
        wa.resume()
        if( inp.loaded )
        {
            inp.audio.currentTime = 0;
        }
    }
}

EffectPass.prototype.MuteInput = function( wa, id )
{
    let inp = this.mInputs[id];
    if( inp===null ) return;

    if( inp.mInfo.mType==="video" )
    {
        inp.video.muted = true;
        inp.video.mMuted = true;
    }
    else if( inp.mInfo.mType==="music" || inp.mInfo.mType==="musicstream")
    {
        if (wa !== null) inp.audio.mSound.mGain.gain.value = 0.0;
        inp.audio.mMuted = true;
    }
}

EffectPass.prototype.UnMuteInput = function( wa, id )
{
    let inp = this.mInputs[id];
    if( inp===null ) return;

    if( inp.mInfo.mType==="video" )
    {
        inp.video.muted = false;
        inp.video.mMuted = false;
    }
    else if( inp.mInfo.mType==="music" || inp.mInfo.mType==="musicstream")
    {
        if (wa !== null) inp.audio.mSound.mGain.gain.value = 1.0;
        inp.audio.mMuted = false;
    }
}

EffectPass.prototype.ToggleMuteInput = function( wa, id )
{
    var me = this;
    let inp = this.mInputs[id];
    if( inp===null ) return null;

    if( inp.mInfo.mType==="video" )
    {
        if( inp.video.mMuted ) this.UnMuteInput(wa,id);
        else                   this.MuteInput(wa,id);
        return inp.video.mMuted;
    }
    else if( inp.mInfo.mType==="music" || inp.mInfo.mType==="musicstream")
    {
        if( inp.audio.mMuted ) this.UnMuteInput(wa,id);
        else                   this.MuteInput(wa,id);
        return inp.audio.mMuted;
    }

    return null;
}

EffectPass.prototype.UpdateInputs = function( wa, forceUpdate, keyboard )
{
   for (let i=0; i<this.mInputs.length; i++ )
   {
        let inp = this.mInputs[i];

        if( inp===null )
        {
            if( forceUpdate )
            {
              if( this.mTextureCallbackFun!==null )
                  this.mTextureCallbackFun( this.mTextureCallbackObj, i, null, false, 0, 0, -1.0, this.mID );
            }
        }
        else if( inp.mInfo.mType==="texture" )
        {
            if( inp.loaded && forceUpdate )
            {
              if( this.mTextureCallbackFun!==null )
                  this.mTextureCallbackFun( this.mTextureCallbackObj, i, inp.image, true, 1, 1, -1.0, this.mID );
            }
        }
        else if( inp.mInfo.mType==="volume" )
        {
            if( inp.loaded && forceUpdate )
            {
              if( this.mTextureCallbackFun!==null )
                  this.mTextureCallbackFun( this.mTextureCallbackObj, i, inp.mPreview, true, 1, 1, -1.0, this.mID );
            }
        }
        else if( inp.mInfo.mType==="cubemap" )
        {
            if( inp.loaded && forceUpdate )
            {
                if( this.mTextureCallbackFun!==null )
                {
                    let img = (assetID_to_cubemapBuferID(inp.mInfo.mID)===-1) ? inp.image[0] : inp.mImage;
                    this.mTextureCallbackFun( this.mTextureCallbackObj, i, img, true, 2, 1, -1.0, this.mID );
                }
            }
        }
        else if( inp.mInfo.mType==="keyboard" )
        {
            if( this.mTextureCallbackFun!==null )
                this.mTextureCallbackFun( this.mTextureCallbackObj, i, {mImage:keyboard.mIcon,mData:keyboard.mData}, false, 6, 0, -1.0, this.mID );
        }
        else if( inp.mInfo.mType==="video" )
        {
            if( inp.video.readyState === inp.video.HAVE_ENOUGH_DATA )
            {
                if( this.mTextureCallbackFun!==null )
                    this.mTextureCallbackFun( this.mTextureCallbackObj, i, inp.video, false, 3, 1, -1, this.mID );
            }
        }
        else if( inp.mInfo.mType==="music" || inp.mInfo.mType==="musicstream" )
        {
              if( inp.loaded && inp.audio.mPaused === false && inp.audio.mForceMuted === false )
              {
                  if( wa !== null )
                  {
                      inp.audio.mSound.mAnalyser.getByteFrequencyData(  inp.audio.mSound.mFreqData );
                      inp.audio.mSound.mAnalyser.getByteTimeDomainData( inp.audio.mSound.mWaveData );
                  }

                  if (this.mTextureCallbackFun!==null)
                  {
                           if (inp.mInfo.mType === "music")       this.mTextureCallbackFun(this.mTextureCallbackObj, i, {wave:(wa==null)?null:inp.audio.mSound.mFreqData}, false, 4, 1, inp.audio.currentTime, this.mID);
                      else if (inp.mInfo.mType === "musicstream") this.mTextureCallbackFun(this.mTextureCallbackObj, i, {wave:(wa==null)?null:inp.audio.mSound.mFreqData, info: inp.audio.soundcloudInfo}, false, 8, 1, inp.audio.currentTime, this.mID);
                  }
              }
              else if( inp.loaded===false )
              {
                  if (this.mTextureCallbackFun!==null)
                      this.mTextureCallbackFun(this.mTextureCallbackObj, i, {wave:null}, false, 4, 0, -1.0, this.mID);
              }
        }
        else if( inp.mInfo.mType==="mic" )
        {
              if( inp.loaded && inp.mForceMuted === false )
              {
                  if( wa !== null )
                  {
                      inp.mAnalyser.getByteFrequencyData(  inp.mFreqData );
                      inp.mAnalyser.getByteTimeDomainData( inp.mWaveData );
                  }
                  if( this.mTextureCallbackFun!==null )
                      this.mTextureCallbackFun( this.mTextureCallbackObj, i, {wave: ((wa==null)?null:inp.mFreqData) }, false, 5, 1, 0, this.mID );
              }
        }
        else if( inp.mInfo.mType==="buffer" )
        {
            if( inp.loaded && forceUpdate )
            {
              if( this.mTextureCallbackFun!==null )
                  this.mTextureCallbackFun( this.mTextureCallbackObj, i, {texture:inp.image, data:null}, true, 9, 1, -1.0, this.mID );
            }
        }
    }
}

EffectPass.prototype.Sampler2Renderer = function (sampler)
{
    let filter = this.mRenderer.FILTER.NONE;
    if (sampler.filter === "linear") filter = this.mRenderer.FILTER.LINEAR;
    if (sampler.filter === "mipmap") filter = this.mRenderer.FILTER.MIPMAP;
    let wrap = this.mRenderer.TEXWRP.REPEAT;
    if (sampler.wrap === "clamp") wrap = this.mRenderer.TEXWRP.CLAMP;
    let vflip = false;
    if (sampler.vflip === "true") vflip = true;

    return { mFilter: filter, mWrap: wrap, mVFlip: vflip };
}

EffectPass.prototype.GetSamplerVFlip = function (id)
{
    let inp = this.mInputs[id];
    return inp.mInfo.mSampler.vflip;
}

EffectPass.prototype.GetTranslatedShaderSource = function ()
{
    return this.mTranslatedSource;
}


EffectPass.prototype.SetSamplerVFlip = function (id, str) 
{
    var me = this;
    var renderer = this.mRenderer;
    let inp = this.mInputs[id];

    let filter = false;
    if (str === "true") filter = true;

    if (inp === null)
    {
    }
    else if (inp.mInfo.mType === "texture")
    {
        if (inp.loaded)
        {
            renderer.SetSamplerVFlip(inp.globject, filter, inp.image);
            inp.mInfo.mSampler.vflip = str;
        }
    }
    else if (inp.mInfo.mType === "volume")
    {
    }
    else if (inp.mInfo.mType === "video")
    {
        if (inp.loaded) 
        {
            renderer.SetSamplerVFlip(inp.globject, filter, inp.image);
            inp.mInfo.mSampler.vflip = str;
        }
    }
    else if (inp.mInfo.mType === "cubemap")
    {
        if (inp.loaded) 
        {
            renderer.SetSamplerVFlip(inp.globject, filter, inp.image);
            inp.mInfo.mSampler.vflip = str;
        }
    }
    else if (inp.mInfo.mType === "webcam")
    {
        if (inp.loaded) 
        {
            renderer.SetSamplerVFlip(inp.globject, filter, null);
            inp.mInfo.mSampler.vflip = str;
        }
    }
}

EffectPass.prototype.GetAcceptsVFlip = function (id)
{
    let inp = this.mInputs[id];

    if (inp === null) return false;
    if (inp.mInfo.mType === "texture") return true;
    if (inp.mInfo.mType === "volume") return false;
    if (inp.mInfo.mType === "video")  return true;
    if (inp.mInfo.mType === "cubemap") return true;
    if (inp.mInfo.mType === "webcam")  return true;
    if (inp.mInfo.mType === "music")  return false;
    if (inp.mInfo.mType === "musicstream") return false;
    if (inp.mInfo.mType === "mic")  return false;
    if (inp.mInfo.mType === "keyboard")  return false;
    if (inp.mInfo.mType === "buffer") return false;
    return true;
}

EffectPass.prototype.GetSamplerFilter = function (id)
{
    let inp = this.mInputs[id];
    if( inp===null) return;
    return inp.mInfo.mSampler.filter;
}

EffectPass.prototype.SetSamplerFilter = function (id, str, buffers, cubeBuffers) 
{
    var me = this;
    var renderer = this.mRenderer;
    let inp = this.mInputs[id];

    let filter = renderer.FILTER.NONE;
    if (str === "linear") filter = renderer.FILTER.LINEAR;
    if (str === "mipmap") filter = renderer.FILTER.MIPMAP;

    if (inp === null)
    {
    }
    else if (inp.mInfo.mType === "texture")
    {
        if (inp.loaded)
        {
            renderer.SetSamplerFilter(inp.globject, filter, true);
            inp.mInfo.mSampler.filter = str;
        }
    }
    else if (inp.mInfo.mType === "volume")
    {
        if (inp.loaded)
        {
            renderer.SetSamplerFilter(inp.globject, filter, true);
            inp.mInfo.mSampler.filter = str;
        }
    }
    else if (inp.mInfo.mType === "video")
    {
        if (inp.loaded) 
        {
            renderer.SetSamplerFilter(inp.globject, filter, true);
            inp.mInfo.mSampler.filter = str;
        }
    }
    else if (inp.mInfo.mType === "cubemap")
    {
        if (inp.loaded) 
        {
            if( assetID_to_cubemapBuferID(inp.mInfo.mID)===0)
            {
                renderer.SetSamplerFilter(cubeBuffers[0].mTexture[0], filter, true);
                renderer.SetSamplerFilter(cubeBuffers[0].mTexture[1], filter, true);
                inp.mInfo.mSampler.filter = str;
            }
            else
            {
                renderer.SetSamplerFilter(inp.globject, filter, true);
                inp.mInfo.mSampler.filter = str;
            }
        }
    }
    else if (inp.mInfo.mType === "webcam")
    {
        if (inp.loaded) 
        {
            renderer.SetSamplerFilter(inp.globject, filter, true);
            inp.mInfo.mSampler.filter = str;
        }
    }
    else if (inp.mInfo.mType === "buffer")
    {
        renderer.SetSamplerFilter(buffers[inp.id].mTexture[0], filter, true);
        renderer.SetSamplerFilter(buffers[inp.id].mTexture[1], filter, true);
        inp.mInfo.mSampler.filter = str;
    }
    else if (inp.mInfo.mType === "keyboard")
    {
        inp.mInfo.mSampler.filter = str;
    }
}



EffectPass.prototype.GetAcceptsMipmapping = function (id)
{
    let inp = this.mInputs[id];

    if (inp === null) return false;
    if (inp.mInfo.mType === "texture") return true;
    if (inp.mInfo.mType === "volume") return true;
    if (inp.mInfo.mType === "video")  return this.mIs20;
    if (inp.mInfo.mType === "cubemap") return true;
    if (inp.mInfo.mType === "webcam")  return this.mIs20;
    if (inp.mInfo.mType === "music")  return false;
    if (inp.mInfo.mType === "musicstream") return false;
    if (inp.mInfo.mType === "mic")  return false;
    if (inp.mInfo.mType === "keyboard")  return false;
    if (inp.mInfo.mType === "buffer") return this.mIs20;
    return false;
}

EffectPass.prototype.GetAcceptsLinear = function (id)
{
    let inp = this.mInputs[id];

    if (inp === null) return false;
    if (inp.mInfo.mType === "texture") return true;
    if (inp.mInfo.mType === "volume") return true;
    if (inp.mInfo.mType === "video")  return true;
    if (inp.mInfo.mType === "cubemap") return true;
    if (inp.mInfo.mType === "webcam")  return true;
    if (inp.mInfo.mType === "music")  return true;
    if (inp.mInfo.mType === "musicstream") return true;
    if (inp.mInfo.mType === "mic")  return true;
    if (inp.mInfo.mType === "keyboard")  return false;
    if (inp.mInfo.mType === "buffer") return true;
    return false;
}


EffectPass.prototype.GetAcceptsWrapRepeat = function (id)
{
    let inp = this.mInputs[id];

    if (inp === null) return false;
    if (inp.mInfo.mType === "texture") return true;
    if (inp.mInfo.mType === "volume") return true;
    if (inp.mInfo.mType === "video")  return this.mIs20;
    if (inp.mInfo.mType === "cubemap") return false;
    if (inp.mInfo.mType === "webcam")  return this.mIs20;
    if (inp.mInfo.mType === "music")  return false;
    if (inp.mInfo.mType === "musicstream") return false;
    if (inp.mInfo.mType === "mic")  return false;
    if (inp.mInfo.mType === "keyboard")  return false;
    if (inp.mInfo.mType === "buffer") return this.mIs20;
    return false;
}

EffectPass.prototype.GetSamplerWrap = function (id)
{
    let inp = this.mInputs[id];
    return inp.mInfo.mSampler.wrap;
}
EffectPass.prototype.SetSamplerWrap = function (id, str, buffers)
{
    var me = this;
    var renderer = this.mRenderer;
    let inp = this.mInputs[id];

    let restr = renderer.TEXWRP.REPEAT;
    if (str === "clamp") restr = renderer.TEXWRP.CLAMP;

    if (inp === null) 
    {
    }
    else if (inp.mInfo.mType === "texture")
    {
        if (inp.loaded) 
        {
            renderer.SetSamplerWrap(inp.globject, restr);
            inp.mInfo.mSampler.wrap = str;
        }
    }
    else if (inp.mInfo.mType === "volume")
    {
        if (inp.loaded) 
        {
            renderer.SetSamplerWrap(inp.globject, restr);
            inp.mInfo.mSampler.wrap = str;
        }
    }
    else if (inp.mInfo.mType === "video") 
    {
        if (inp.loaded) 
        {
            renderer.SetSamplerWrap(inp.globject, restr);
            inp.mInfo.mSampler.wrap = str;
        }
    }
    else if (inp.mInfo.mType === "cubemap") 
    {
        if (inp.loaded)
        {
            renderer.SetSamplerWrap(inp.globject, restr);
            inp.mInfo.mSampler.wrap = str;
        }
    }
    else if (inp.mInfo.mType === "webcam") 
    {
        if (inp.loaded) 
        {
            renderer.SetSamplerWrap(inp.globject, restr);
            inp.mInfo.mSampler.wrap = str;
        }
    }
    else if (inp.mInfo.mType === "buffer")
    {
        renderer.SetSamplerWrap(buffers[inp.id].mTexture[0], restr);
        renderer.SetSamplerWrap(buffers[inp.id].mTexture[1], restr);
        inp.mInfo.mSampler.wrap = str;
    }
}


EffectPass.prototype.GetTexture = function( slot )
{
    let inp = this.mInputs[slot];
    if( inp===null ) return null;
    return inp.mInfo;

}

EffectPass.prototype.SetOutputs = function( slot, id )
{
    this.mOutputs[slot] = id;
}

EffectPass.prototype.SetOutputsByBufferID = function( slot, id )
{
    if( this.mType==="buffer" )
    {
        this.mOutputs[slot] = bufferID_to_assetID( id );

        this.mEffect.ResizeBuffer( id, this.mEffect.mXres, this.mEffect.mYres, false );
    }
    else if( this.mType==="cubemap" )
    {
        this.mOutputs[slot] = cubamepBufferID_to_assetID( id );
        this.mEffect.ResizeCubemapBuffer(id, 1024, 1024 );
    }
}

EffectPass.prototype.NewTexture = function( wa, slot, url, buffers, cubeBuffers, keyboard )
{
    var me = this;
    var renderer = this.mRenderer;

    if( renderer===null ) return;

    let texture = null;

    if( url===null || url.mType===null )
    {
        if( me.mTextureCallbackFun!==null )
            me.mTextureCallbackFun( this.mTextureCallbackObj, slot, null, true, 0, 0, -1.0, me.mID );
        me.DestroyInput( slot );
        me.mInputs[slot] = null;
        me.MakeHeader();
        return { mFailed:false, mNeedsShaderCompile:false };
    }
    else if( url.mType==="texture" )
    {
        texture = {};
        texture.mInfo = url;
        texture.globject = null;
        texture.loaded = false;
        texture.image = new Image();
        texture.image.crossOrigin = '';
        texture.image.onload = function()
        {
            let rti = me.Sampler2Renderer(url.mSampler);

            // O.M.G. FIX THIS
            let channels = renderer.TEXFMT.C4I8;
            if (url.mID === "Xdf3zn" || url.mID === "4sf3Rn" || url.mID === "4dXGzn" || url.mID === "4sf3Rr")
                channels = renderer.TEXFMT.C1I8;
            
            texture.globject = renderer.CreateTextureFromImage(renderer.TEXTYPE.T2D, texture.image, channels, rti.mFilter, rti.mWrap, rti.mVFlip);

            texture.loaded = true;
            if( me.mTextureCallbackFun!==null )
                me.mTextureCallbackFun( me.mTextureCallbackObj, slot, texture.image, true, 1, 1, -1.0, me.mID );
        }
        texture.image.src = url.mSrc;


        let returnValue = { mFailed:false, mNeedsShaderCompile: (this.mInputs[slot]===null ) || (
                                                                (this.mInputs[slot].mInfo.mType!=="texture") && 
                                                                (this.mInputs[slot].mInfo.mType!=="webcam") && 
                                                                (this.mInputs[slot].mInfo.mType!=="mic") && 
                                                                (this.mInputs[slot].mInfo.mType!=="music") && 
                                                                (this.mInputs[slot].mInfo.mType!=="musicstream") && 
                                                                (this.mInputs[slot].mInfo.mType!=="keyboard") && 
                                                                (this.mInputs[slot].mInfo.mType!=="video")) };
        this.DestroyInput( slot );
        this.mInputs[slot] = texture;
        this.MakeHeader();
        return returnValue;
    }
    else if( url.mType==="volume" )
    {
        texture = {};
        texture.mInfo = url;
        texture.globject = null;
        texture.loaded = false;
        texture.mImage = { mData:null, mXres:1, mYres:0, mZres:0 };
        texture.mPreview = new Image();
        texture.mPreview.crossOrigin = '';

	    var xmlHttp = new XMLHttpRequest();
        if( xmlHttp===null ) return { mFailed:true };

        xmlHttp.open('GET', url.mSrc, true);
        xmlHttp.responseType = "arraybuffer";
        xmlHttp.onerror = function()
        {
            console.log( "Error 1 loading Volume" );
        }
        xmlHttp.onload = function()
        {
            let data = xmlHttp.response;
            if (!data ) { console.log( "Error 2 loading Volume" ); return; }

            let file = piFile(data);

            let signature = file.ReadUInt32();
            texture.mImage.mXres = file.ReadUInt32();
            texture.mImage.mYres = file.ReadUInt32();
            texture.mImage.mZres = file.ReadUInt32();
            let binNumChannels = file.ReadUInt8();
            let binLayout = file.ReadUInt8();
            let binFormat = file.ReadUInt16();
            let format = renderer.TEXFMT.C1I8;
                 if( binNumChannels===1 && binFormat===0 )  format = renderer.TEXFMT.C1I8;
            else if( binNumChannels===2 && binFormat===0 )  format = renderer.TEXFMT.C2I8;
            else if( binNumChannels===3 && binFormat===0 )  format = renderer.TEXFMT.C3I8;
            else if( binNumChannels===4 && binFormat===0 )  format = renderer.TEXFMT.C4I8;
            else if( binNumChannels===1 && binFormat===10 ) format = renderer.TEXFMT.C1F32;
            else if( binNumChannels===2 && binFormat===10 ) format = renderer.TEXFMT.C2F32;
            else if( binNumChannels===3 && binFormat===10 ) format = renderer.TEXFMT.C3F32;
            else if( binNumChannels===4 && binFormat===10 ) format = renderer.TEXFMT.C4F32;
            else return;

            let buffer = new Uint8Array(data, 20); // skip 16 bytes (header of .bin)

            let rti = me.Sampler2Renderer(url.mSampler);

            texture.globject = renderer.CreateTexture(renderer.TEXTYPE.T3D, texture.mImage.mXres, texture.mImage.mYres, format, rti.mFilter, rti.mWrap, buffer);

            if( texture.globject===null )
            {
                console.log( "Error 4: loading Volume" ); 
                return { mFailed:true };
            }

            if (me.mTextureCallbackFun !== null)
            {
                me.mTextureCallbackFun( me.mTextureCallbackObj, slot, texture.mPreview, true, 1, 1, -1.0, me.mID );
            }

            texture.loaded = true;

            // load icon for it
            texture.mPreview.onload = function()
            {
                if( me.mTextureCallbackFun!==null )
                    me.mTextureCallbackFun( me.mTextureCallbackObj, slot, texture.mPreview, true, 1, 1, -1.0, me.mID );
            }
            texture.mPreview.src = url.mPreviewSrc;
        }
        xmlHttp.send("");


        let returnValue = { mFailed:false, mNeedsShaderCompile: (this.mInputs[slot]==null ) || (
                                                                (this.mInputs[slot].mInfo.mType!="volume")) };
        this.DestroyInput( slot );
        this.mInputs[slot] = texture;
        this.MakeHeader();
        return returnValue;
    }
    else if( url.mType==="cubemap" )
    {
        texture = {};
        texture.mInfo = url;
        texture.globject = null;
        texture.loaded = false;

        let rti = me.Sampler2Renderer(url.mSampler);

        if( assetID_to_cubemapBuferID(url.mID)!==-1 )
        {
            texture.mImage = new Image();
            texture.mImage.onload = function()
            {
                texture.loaded = true;
                if( me.mTextureCallbackFun!==null )
                    me.mTextureCallbackFun( me.mTextureCallbackObj, slot, texture.mImage, true, 2, 1, -1.0, me.mID );
            }
            texture.mImage.src = "/media/previz/cubemap00.png";

            this.mEffect.ResizeCubemapBuffer(0, 1024, 1024 );

        }
        else
        {
            texture.image = [ new Image(), new Image(), new Image(), new Image(), new Image(), new Image() ];

            let numLoaded = 0;
            for (var i=0; i<6; i++ )
            {
                texture.image[i].mId = i;
                texture.image[i].crossOrigin = '';
                texture.image[i].onload = function()
                {
                    var id = this.mId;
                    numLoaded++;
                    if( numLoaded===6 )
                    {
                        texture.globject = renderer.CreateTextureFromImage(renderer.TEXTYPE.CUBEMAP, texture.image, renderer.TEXFMT.C4I8, rti.mFilter, rti.mWrap, rti.mVFlip);
                        texture.loaded = true;
                        if (me.mTextureCallbackFun !== null)
                            me.mTextureCallbackFun(me.mTextureCallbackObj, slot, texture.image[0], true, 2, 1, -1.0, me.mID);
                    }
                }

                if( i === 0) 
                {
                    texture.image[i].src = url.mSrc;
                } 
                else 
                {
                    let n = url.mSrc.lastIndexOf(".");
                    texture.image[i].src = url.mSrc.substring(0, n) + "_" + i + url.mSrc.substring(n, url.mSrc.length);
                }
            }
        }

        let returnValue = { mFailed:false, mNeedsShaderCompile: (this.mInputs[slot]==null ) || (
                                                                (this.mInputs[slot].mInfo.mType!="cubemap")) };

        this.DestroyInput( slot );
        this.mInputs[slot] = texture;
        this.MakeHeader();
        return returnValue;
    }
    else if( url.mType==="webcam" )
    {
        texture = {};
        texture.mInfo = url;
        texture.globject = null;
        texture.loaded = false;

        texture.video = document.createElement('video');
    	texture.video.width = 320;
    	texture.video.height = 240;
    	texture.video.autoplay = true;
    	texture.video.loop = true;
        texture.mForceMuted = this.mForceMuted;
        texture.mImage = null;

        let rti = me.Sampler2Renderer(url.mSampler);

        var loadImageInsteadOfWebCam = function()
        {
            texture.mImage = new Image();
            texture.mImage.onload = function()
            {
                texture.loaded = true;
                texture.globject = renderer.CreateTextureFromImage(renderer.TEXTYPE.T2D, texture.mImage, renderer.TEXFMT.C4I8, rti.mFilter, rti.mWrap, rti.mVFlip);
                if( me.mTextureCallbackFun!==null )
                    me.mTextureCallbackFun( me.mTextureCallbackObj, slot, texture.mImage, true, 7, 1, -1.0, me.mID );
            }
            texture.mImage.src = "/media/previz/webcam.png";
        }
        
        loadImageInsteadOfWebCam();

        if( typeof navigator.getUserMedia !== "undefined"  && texture.mForceMuted===false )
        {
            texture.video.addEventListener("canplay", function (e)
            {
				try
				{
                    texture.mImage = null;
                    if( texture.globject != null )
                        renderer.DestroyTexture( texture.globject );
					texture.globject = renderer.CreateTextureFromImage(renderer.TEXTYPE.T2D, texture.video, renderer.TEXFMT.C4I8, rti.mFilter, rti.mWrap, rti.mVFlip);
					texture.loaded = true;
                }
                catch(e)
                {
                    loadImageInsteadOfWebCam();
	                alert( 'Your browser can not transfer webcam data to the GPU.');
                }
            } );

            navigator.mediaDevices.getUserMedia( 
                                { "video": { width: 1280, height: 720 }, "audio": false } )
                                .then( function(stream)
                                       {
                                            texture.video.srcObject = stream;
    	                               } )
                                .catch( function(error)
                                        {
                                            loadImageInsteadOfWebCam();
    		                                alert( 'Unable to capture WebCam. Please reload the page.' );
    	                                } );
        }
        let returnValue = { mFailed:false, mNeedsShaderCompile: (this.mInputs[slot]==null ) || (
                                                                (this.mInputs[slot].mInfo.mType!="texture") && 
                                                                (this.mInputs[slot].mInfo.mType!="webcam") && 
                                                                (this.mInputs[slot].mInfo.mType!="mic") && 
                                                                (this.mInputs[slot].mInfo.mType!="music") && 
                                                                (this.mInputs[slot].mInfo.mType!="musicstream") && 
                                                                (this.mInputs[slot].mInfo.mType!="keyboard") && 
                                                                (this.mInputs[slot].mInfo.mType!="video")) };
        this.DestroyInput( slot );
        this.mInputs[slot] = texture;
        this.MakeHeader();
        return returnValue;
    }
    else if( url.mType==="mic" )
    {
        texture = {};
        texture.mInfo = url;
        texture.globject = null;
        texture.loaded = false;
        texture.mForceMuted = this.mForceMuted;
        texture.mAnalyser = null;
        let num = 512;
        texture.mFreqData = new Uint8Array( num );
        texture.mWaveData = new Uint8Array( num );

        if( wa === null || typeof navigator.getUserMedia === "undefined" )
        {
            if( !texture.mForceMuted ) alert( "Shadertoy: Web Audio not implement in this browser" );
            texture.mForceMuted = true; 
        }

        if( texture.mForceMuted )
        {
            texture.globject = renderer.CreateTexture(renderer.TEXTYPE.T2D, num, 2, renderer.TEXFMT.C1I8, renderer.FILTER.LINEAR, renderer.TEXWRP.CLAMP, null)
            texture.loaded = true;
        }
        else
        {
        navigator.getUserMedia( { "audio": true },
                                function(stream)
                                {
                                  texture.globject = renderer.CreateTexture(renderer.TEXTYPE.T2D, 512, 2, renderer.TEXFMT.C1I8, renderer.FILTER.LINEAR, null)
                                  texture.mic = wa.createMediaStreamSource(stream);
                                  texture.mAnalyser = wa.createAnalyser();
                                  texture.mic.connect( texture.mAnalyser );
                                  texture.loaded = true;
    	                        },
                                function(error)
                                {
    		                        alert( 'Unable open Mic. Please reload the page.' );
    	                        } );
        }
        let returnValue = { mFailed:false, mNeedsShaderCompile: (this.mInputs[slot]===null ) || (
                                                                (this.mInputs[slot].mInfo.mType!=="texture") && 
                                                                (this.mInputs[slot].mInfo.mType!=="webcam") && 
                                                                (this.mInputs[slot].mInfo.mType!=="mic") && 
                                                                (this.mInputs[slot].mInfo.mType!=="music") && 
                                                                (this.mInputs[slot].mInfo.mType!=="musicstream") && 
                                                                (this.mInputs[slot].mInfo.mType!=="keyboard") && 
                                                                (this.mInputs[slot].mInfo.mType!=="video")) };
        this.DestroyInput( slot );
        this.mInputs[slot] = texture;
        this.MakeHeader();
        return returnValue;
    }
    else if( url.mType==="video" )
    {
    	texture = {};
        texture.mInfo = url;
        texture.globject = null;
        texture.loaded = false;
        texture.video = document.createElement('video');
    	texture.video.loop = true;
        texture.video.preload = "auto";
        texture.video.mPaused = this.mForcePaused;
        texture.video.mMuted = true;//this.mForceMuted;
    	texture.video.muted  = true;//this.mForceMuted;
        if( this.mForceMuted===true )
            texture.video.volume = 0;
    	texture.video.autoplay = false;
        texture.video.hasFalled = false;
        
        let rti = me.Sampler2Renderer(url.mSampler);

        texture.video.addEventListener("canplay", function (e)
        {
            texture.video.play().then( function()
                                       {
                                           texture.video.mPaused = false;

                                           texture.globject = renderer.CreateTextureFromImage(renderer.TEXTYPE.T2D, texture.video, renderer.TEXFMT.C4I8, rti.mFilter, rti.mWrap, rti.mVFlip);
                                           texture.loaded = true;
            
                                           if( me.mTextureCallbackFun!=null )
                                               me.mTextureCallbackFun( me.mTextureCallbackObj, slot, texture.video, true, 3, 1, -1.0, me.mID );
                                        } )
                               .catch( function(error)
                                       {
                                           console.log( error );
                                       }
                                );
        } );

        texture.video.addEventListener( "error", function(e)
        {
               if( texture.video.hasFalled===true ) { alert("Error: cannot load video" ); return; }
               let str = texture.video.src;
               str = str.substr(0,str.lastIndexOf('.') ) + ".mp4";
               texture.video.src = str;
               texture.video.hasFalled = true;
        } );

        texture.video.src = url.mSrc;

        let returnValue = { mFailed:false, mNeedsShaderCompile: (this.mInputs[slot]==null ) || (
                                                                (this.mInputs[slot].mInfo.mType!="texture") && 
                                                                (this.mInputs[slot].mInfo.mType!="webcam") && 
                                                                (this.mInputs[slot].mInfo.mType!="mic") && 
                                                                (this.mInputs[slot].mInfo.mType!="music") && 
                                                                (this.mInputs[slot].mInfo.mType!="musicstream") && 
                                                                (this.mInputs[slot].mInfo.mType!="keyboard") && 
                                                                (this.mInputs[slot].mInfo.mType!="video")) };
        this.DestroyInput( slot );
        this.mInputs[slot] = texture;
        this.MakeHeader();
        return returnValue;
    }
    else if( url.mType==="music" || url.mType==="musicstream" )
    {
    	texture = {};
        texture.mInfo = url;
        texture.globject = null;
        texture.loaded = false;
        texture.audio = document.createElement('audio');
    	texture.audio.loop = true;
        texture.audio.mMuted = this.mForceMuted;
        texture.audio.mForceMuted = this.mForceMuted;
        texture.audio.muted = this.mForceMuted;
        if( this.mForceMuted===true )
            texture.audio.volume = 0;
        texture.audio.autoplay = false;
        texture.audio.hasFalled = false;
        texture.audio.mPaused = false;
        texture.audio.mSound = {};

        if( this.mForceMuted===false )
        {
            if(url.mType==="musicstream" && SC === null)
            {
                alert( "Shadertoy: Soundcloud could not be reached" );
                texture.audio.mForceMuted = true;
            }
            }

        if( wa === null && this.mForceMuted===false )
        {
            alert( "Shadertoy: Web Audio not implement in this browser" );
            texture.audio.mForceMuted = true;
        }

        if( texture.audio.mForceMuted )
        {
            texture.globject = renderer.CreateTexture(renderer.TEXTYPE.T2D, 512, 2, renderer.TEXFMT.C1I8, renderer.FILTER.LINEAR, renderer.TEXWRP.CLAMP, null);
            let num = 512;
            texture.audio.mSound.mFreqData = new Uint8Array( num );
            texture.audio.mSound.mWaveData = new Uint8Array( num );
            texture.loaded = true;
        }

        texture.audio.addEventListener( "canplay", function()
        {
            if( texture===null || texture.audio===null ) return;
            if( this.mForceMuted  ) return;
            if( texture.loaded === true ) return;

            texture.globject = renderer.CreateTexture(renderer.TEXTYPE.T2D, 512, 2, renderer.TEXFMT.C1I8, renderer.FILTER.LINEAR, renderer.TEXWRP.CLAMP, null)

            texture.audio.mSound.mSource   = wa.createMediaElementSource( texture.audio );
            texture.audio.mSound.mAnalyser = wa.createAnalyser();
            texture.audio.mSound.mGain     = wa.createGain();

            texture.audio.mSound.mSource.connect(   texture.audio.mSound.mAnalyser );
            texture.audio.mSound.mAnalyser.connect( texture.audio.mSound.mGain );
            texture.audio.mSound.mGain.connect(me.mGainNode);

            texture.audio.mSound.mFreqData = new Uint8Array( texture.audio.mSound.mAnalyser.frequencyBinCount );
            texture.audio.mSound.mWaveData = new Uint8Array( texture.audio.mSound.mAnalyser.frequencyBinCount );

            if( texture.audio.mPaused )
            {
                texture.audio.pause();
            }
            else
            {
                texture.audio.play().then( function() {/*console.log("ok");*/} ).catch( function(e){console.log("error " + e);} );
            }
            texture.loaded = true;
        } );

        texture.audio.addEventListener( "error", function(e)
        {
               if( this.mForceMuted  ) return;

               if( texture.audio.hasFalled===true ) { return; }
               let str = texture.audio.src;
               str = str.substr(0,str.lastIndexOf('.') ) + ".ogg";
               texture.audio.src = str;
               texture.audio.hasFalled = true;
        } );

        if( !texture.audio.mForceMuted )
        {
            if(url.mType==="musicstream")
            {
                SC.resolve(url.mSrc, 
                    function(song) 
                    {
                        if( song.streamable===true )
                        {
                            texture.audio.crossOrigin = 'anonymous';
                            texture.audio.src = song.stream_url;
                            texture.audio.soundcloudInfo = song;
                        }
                        else
                        {
                            alert('Shadertoy: Soundcloud 3 - This track cannot be streamed' );
                        }
                    },
                    function(error)
                    {
                        if (me.mTextureCallbackFun!==null)
                        {
                            me.mTextureCallbackFun(me.mTextureCallbackObj, slot, {wave:null}, false, 4, 0, -1.0, me.mID);
                        }
                    } );
            } 
            else
            {
                texture.audio.src = url.mSrc;
            }
        }

        if (me.mTextureCallbackFun!==null)
        {
            if (url.mType === "music")            me.mTextureCallbackFun(me.mTextureCallbackObj, slot, {wave:null}, false, 4, 0, -1.0, me.mID);
            else if (url.mType === "musicstream") me.mTextureCallbackFun(me.mTextureCallbackObj, slot, {wave:null, info: texture.audio.soundcloudInfo}, false, 8, 0, -1.0, me.mID);
        }

        let returnValue = { mFailed:false, mNeedsShaderCompile: (this.mInputs[slot]===null ) || (
                                                                (this.mInputs[slot].mInfo.mType!=="texture") && 
                                                                (this.mInputs[slot].mInfo.mType!=="webcam") && 
                                                                (this.mInputs[slot].mInfo.mType!=="mic") && 
                                                                (this.mInputs[slot].mInfo.mType!=="music") && 
                                                                (this.mInputs[slot].mInfo.mType!=="musicstream") && 
                                                                (this.mInputs[slot].mInfo.mType!=="keyboard") && 
                                                                (this.mInputs[slot].mInfo.mType!=="video")) };
        this.DestroyInput( slot );
        this.mInputs[slot] = texture;
        this.MakeHeader();
        return returnValue;
    }
    else if( url.mType==="keyboard" )
    {
    	texture = {};
        texture.mInfo = url;
        texture.globject = null;
        texture.loaded = true;

        texture.keyboard = {};

        if( me.mTextureCallbackFun!==null )
            me.mTextureCallbackFun( me.mTextureCallbackObj, slot, {mImage: keyboard.mIcon, mData: keyboard.mData}, false, 6, 1, -1.0, me.mID );

        let returnValue = { mFailed:false, mNeedsShaderCompile: (this.mInputs[slot]===null ) || (
                                                                (this.mInputs[slot].mInfo.mType!="texture") && 
                                                                (this.mInputs[slot].mInfo.mType!="webcam") && 
                                                                (this.mInputs[slot].mInfo.mType!="mic") && 
                                                                (this.mInputs[slot].mInfo.mType!="music") && 
                                                                (this.mInputs[slot].mInfo.mType!="musicstream") && 
                                                                (this.mInputs[slot].mInfo.mType!="keyboard") && 
                                                                (this.mInputs[slot].mInfo.mType!="video")) };
        this.DestroyInput( slot );
        this.mInputs[slot] = texture;
        this.MakeHeader();
        return returnValue;
    }
    else if( url.mType==="buffer" )
    {
        texture = {};
        texture.mInfo = url;

        texture.image = new Image();
        texture.image.onload = function()
        {
            if( me.mTextureCallbackFun!=null )
                me.mTextureCallbackFun( me.mTextureCallbackObj, slot, {texture: texture.image, data:null}, true, 9, 1, -1.0, me.mID );
        }
        texture.image.src = url.mSrc;
        texture.id = assetID_to_bufferID( url.mID );
        texture.loaded = true;

        let returnValue = { mFailed:false, mNeedsShaderCompile: (this.mInputs[slot]===null ) || (
                                                                (this.mInputs[slot].mInfo.mType!="texture") && 
                                                                (this.mInputs[slot].mInfo.mType!="webcam") && 
                                                                (this.mInputs[slot].mInfo.mType!="mic") && 
                                                                (this.mInputs[slot].mInfo.mType!="music") && 
                                                                (this.mInputs[slot].mInfo.mType!="musicstream") && 
                                                                (this.mInputs[slot].mInfo.mType!="keyboard") && 
                                                                (this.mInputs[slot].mInfo.mType!="video")) };

        this.DestroyInput( slot );
        this.mInputs[slot] = texture;

        this.mEffect.ResizeBuffer(texture.id, this.mEffect.mXres, this.mEffect.mYres, false );

        this.SetSamplerFilter(slot, url.mSampler.filter, buffers, cubeBuffers, true);
        this.SetSamplerVFlip(slot, url.mSampler.vflip);
        this.SetSamplerWrap(slot, url.mSampler.wrap, buffers);

        this.MakeHeader();
        return returnValue;
    }
    else
    {
        alert( "input type error" );
        return { mFailed: true };
    }

    return { mFailed: true };
}

EffectPass.prototype.Paint_Image = function( vrData, wa, d, time, dtime, fps, mouseOriX, mouseOriY, mousePosX, mousePosY, xres, yres, buffers, cubeBuffers, keyboard )
{
    let times = [ 0.0, 0.0, 0.0, 0.0 ];

    let dates = [ d.getFullYear(), // the year (four digits)
                  d.getMonth(),	   // the month (from 0-11)
                  d.getDate(),     // the day of the month (from 1-31)
                  d.getHours()*60.0*60 + d.getMinutes()*60 + d.getSeconds()  + d.getMilliseconds()/1000.0 ];

    let mouse = [  mousePosX, mousePosY, mouseOriX, mouseOriY ];


    //------------------------
    
    let resos = [ 0.0,0.0,0.0, 0.0,0.0,0.0, 0.0,0.0,0.0, 0.0,0.0,0.0 ];
    let texIsLoaded = [0, 0, 0, 0 ];
    let texID = [ null, null, null, null];

    for (let i=0; i<this.mInputs.length; i++ )
    {
        let inp = this.mInputs[i];

        if( inp===null )
        {
        }
        else if( inp.mInfo.mType==="texture" )
        {
            if( inp.loaded===true  )
            {
                texID[i] = inp.globject;
                texIsLoaded[i] = 1;
                resos[3*i+0] = inp.image.width;
                resos[3*i+1] = inp.image.height;
                resos[3*i+2] = 1;
            }
        }
        else if( inp.mInfo.mType==="volume" )
        {
            if( inp.loaded===true  )
            {
                texID[i] = inp.globject;
                texIsLoaded[i] = 1;
                resos[3*i+0] = inp.mImage.mXres;
                resos[3*i+1] = inp.mImage.mYres;
                resos[3*i+2] = inp.mImage.mZres;
            }
        }
        else if( inp.mInfo.mType==="keyboard" )
        {
            texID[i] = keyboard.mTexture;
            texIsLoaded[i] = 1;
            resos[3*i+0] = 256;
            resos[3*i+1] = 3;
            resos[3*i+2] = 1;
        }
        else if( inp.mInfo.mType==="cubemap" )
        {
            if (inp.loaded === true)
            {
                let id = assetID_to_cubemapBuferID(inp.mInfo.mID);
                if( id!==-1 )
                {
                    texID[i] = cubeBuffers[id].mTexture[ cubeBuffers[id].mLastRenderDone ];
                    resos[3*i+0] = cubeBuffers[id].mResolution[0];
                    resos[3*i+1] = cubeBuffers[id].mResolution[1];
                    resos[3*i+2] = 1;
                    texIsLoaded[i] = 1;

                    // hack. in webgl2.0 we have samplers, so we don't need this crap here
                    let filter = this.mRenderer.FILTER.NONE;
                         if (inp.mInfo.mSampler.filter === "linear") filter = this.mRenderer.FILTER.LINEAR;
                    else if (inp.mInfo.mSampler.filter === "mipmap") filter = this.mRenderer.FILTER.MIPMAP;
                    this.mRenderer.SetSamplerFilter( texID[i], filter, false);
                }
                else
                {
                    texID[i] = inp.globject;
                    texIsLoaded[i] = 1;
                }
            }
        }
        else if( inp.mInfo.mType==="webcam" )
        {
            if( inp.loaded===true )
            {
                if( inp.mImage !== null )
                {
                    if( this.mTextureCallbackFun!==null )
                        this.mTextureCallbackFun( this.mTextureCallbackObj, i, inp.mImage, false, 7, 1, -1, this.mID );

                    texID[i] = inp.globject;
                    texIsLoaded[i] = 1;
                    resos[3*i+0] = inp.mImage.width;
                    resos[3*i+1] = inp.mImage.height;
                    resos[3*i+2] = 1;
                }
                else  if( inp.video.readyState === inp.video.HAVE_ENOUGH_DATA )
                {

                    if( this.mTextureCallbackFun!==null )
                        this.mTextureCallbackFun( this.mTextureCallbackObj, i, inp.video, false, 7, 1, -1, this.mID );

                    texID[i] = inp.globject;
                    this.mRenderer.UpdateTextureFromImage(inp.globject, inp.video);
                    if( inp.mInfo.mSampler.filter === "mipmap" )
                        this.mRenderer.CreateMipmaps(inp.globject);
                    resos[3*i+0] = inp.video.videoWidth;
                    resos[3*i+1] = inp.video.videoHeight;
                    resos[3*i+2] = 1;
                    texIsLoaded[i] = 1;
                }
            }
            else 
            {
                texID[i] = null;
                texIsLoaded[i] = 0;
                resos[3*i+0] = inp.video.width;
                resos[3*i+1] = inp.video.height;
                resos[3*i+2] = 1;
            }
        }
        else if( inp.mInfo.mType==="video" )
        {
            if( inp.video.mPaused === false )
            {
                if( this.mTextureCallbackFun!==null )
                    this.mTextureCallbackFun( this.mTextureCallbackObj, i, inp.video, false, 3, 1, inp.video.currentTime, this.mID );
            }

            if( inp.loaded===true )
            { 
                times[i] = inp.video.currentTime;
                texID[i] = inp.globject;
                texIsLoaded[i] = 1;

      	        if( inp.video.mPaused === false )
      	        {
      	            this.mRenderer.UpdateTextureFromImage(inp.globject, inp.video);
                    if( inp.mInfo.mSampler.filter === "mipmap" )
                        this.mRenderer.CreateMipmaps(inp.globject);
                }
                resos[3*i+0] = inp.video.videoWidth;
                resos[3*i+1] = inp.video.videoHeight;
                resos[3*i+2] = 1;
            }
        }
        else if( inp.mInfo.mType==="music" || inp.mInfo.mType==="musicstream" )
        {
            if( inp.audio.mPaused === false && inp.audio.mForceMuted === false && inp.loaded===true )
            {
                if( wa !== null )
                {
                    inp.audio.mSound.mAnalyser.getByteFrequencyData(  inp.audio.mSound.mFreqData );
                    inp.audio.mSound.mAnalyser.getByteTimeDomainData( inp.audio.mSound.mWaveData );
                }

                if( this.mTextureCallbackFun!==null )
                {
                         if( inp.mInfo.mType==="music")       this.mTextureCallbackFun(this.mTextureCallbackObj, i, (wa === null) ? null : { wave : inp.audio.mSound.mFreqData }, false, 4, 1, inp.audio.currentTime, this.mID);
                    else if( inp.mInfo.mType==="musicstream") this.mTextureCallbackFun(this.mTextureCallbackObj, i, (wa === null) ? null : { wave : inp.audio.mSound.mFreqData, info : inp.audio.soundcloudInfo}, false, 8, 1, inp.audio.currentTime, this.mID);
                }
            }

            if( inp.loaded===true )
            {
                times[i] = inp.audio.currentTime;
                texID[i] = inp.globject;
                texIsLoaded[i] = 1;

                if( inp.audio.mForceMuted === true )
                {
                    times[i] = 10.0 + time;
                    let num = inp.audio.mSound.mFreqData.length;
                    for (let j=0; j<num; j++ )
                    {
                        let x = j / num;
                        let f =  (0.75 + 0.25*Math.sin( 10.0*j + 13.0*time )) * Math.exp( -3.0*x );

                        if( j<3 )
                            f =  Math.pow( 0.50 + 0.5*Math.sin( 6.2831*time ), 4.0 ) * (1.0-j/3.0);

                        inp.audio.mSound.mFreqData[j] = Math.floor(255.0*f) | 0;
                    }

                  //let num = inp.audio.mSound.mFreqData.length;
                    for (let j=0; j<num; j++ )
                    {
                        let f = 0.5 + 0.15*Math.sin( 17.0*time + 10.0*6.2831*j/num ) * Math.sin( 23.0*time + 1.9*j/num );
                        inp.audio.mSound.mWaveData[j] = Math.floor(255.0*f) | 0;
                    }

                }

      	        if( inp.audio.mPaused === false )
                {
      	            let waveLen = Math.min(inp.audio.mSound.mWaveData.length, 512);
      	            this.mRenderer.UpdateTexture(inp.globject, 0, 0, 512, 1, inp.audio.mSound.mFreqData);
      	            this.mRenderer.UpdateTexture(inp.globject, 0, 1, 512, 1, inp.audio.mSound.mWaveData);
                }

                resos[3*i+0] = 512;
                resos[3*i+1] = 2;
                resos[3*i+2] = 1;
            }
        }
        else if( inp.mInfo.mType==="mic" )
        {
            if( inp.loaded===false || inp.mForceMuted || wa === null || inp.mAnalyser == null )
            {
                    times[i] = 10.0 + time;
                    let num = inp.mFreqData.length;
                    for( let j=0; j<num; j++ )
                    {
                        let x = j / num;
                        let f =  (0.75 + 0.25*Math.sin( 10.0*j + 13.0*time )) * Math.exp( -3.0*x );

                        if( j<3 )
                            f =  Math.pow( 0.50 + 0.5*Math.sin( 6.2831*time ), 4.0 ) * (1.0-j/3.0);

                        inp.mFreqData[j] = Math.floor(255.0*f) | 0;
                    }

                    //var num = inp.mFreqData.length;
                    for( let j=0; j<num; j++ )
                    {
                        let f = 0.5 + 0.15*Math.sin( 17.0*time + 10.0*6.2831*j/num ) * Math.sin( 23.0*time + 1.9*j/num );
                        inp.mWaveData[j] = Math.floor(255.0*f) | 0;
                    }
            }
            else
            {
                inp.mAnalyser.getByteFrequencyData(  inp.mFreqData );
                inp.mAnalyser.getByteTimeDomainData( inp.mWaveData );
            }

            if( this.mTextureCallbackFun!==null )
                this.mTextureCallbackFun( this.mTextureCallbackObj, i, {wave:inp.mFreqData}, false, 5, 1, -1, this.mID );

            if( inp.loaded===true )
            {
                texID[i] = inp.globject;
                texIsLoaded[i] = 1;
                let waveLen = Math.min( inp.mWaveData.length, 512 );
                this.mRenderer.UpdateTexture(inp.globject, 0, 0, 512,     1, inp.mFreqData);
                this.mRenderer.UpdateTexture(inp.globject, 0, 1, waveLen, 1, inp.mWaveData);
                resos[3*i+0] = 512;
                resos[3*i+1] = 2;
                resos[3*i+2] = 1;
            }
        }
        else if( inp.mInfo.mType==="buffer" )
        {
            let id = inp.id;
            if( inp.loaded===true  )
            {
                texID[i] = buffers[id].mTexture[ buffers[id].mLastRenderDone ];
                texIsLoaded[i] = 1;
                resos[3*i+0] = xres;
                resos[3*i+1] = yres;
                resos[3*i+2] = 1;
                // hack. in webgl2.0 we have samplers, so we don't need this crap here
                let filter = this.mRenderer.FILTER.NONE;
                     if (inp.mInfo.mSampler.filter === "linear") filter = this.mRenderer.FILTER.LINEAR;
                else if (inp.mInfo.mSampler.filter === "mipmap") filter = this.mRenderer.FILTER.MIPMAP;
                this.mRenderer.SetSamplerFilter( texID[i], filter, false);
            }

            if( this.mTextureCallbackFun!==null )
            {
                this.mTextureCallbackFun( this.mTextureCallbackObj, i, {texture:inp.image, data:buffers[id].mThumbnailBuffer}, false, 9, 1, -1, this.mID );
            }
        }
    }

    this.mRenderer.AttachTextures( 4, texID[0], texID[1], texID[2], texID[3] );

    //-----------------------------------

    let prog = this.mProgram;

    //if( vrData!=null && this.mSupportsVR ) prog = this.mProgramVR;



    this.mRenderer.AttachShader(prog);

    this.mRenderer.SetShaderConstant1F(  "iTime", time);
    this.mRenderer.SetShaderConstant3F(  "iResolution", xres, yres, 1.0);
    this.mRenderer.SetShaderConstant4FV( "iMouse", mouse);
    this.mRenderer.SetShaderConstant1FV( "iChannelTime", times );              // OBSOLETE
    this.mRenderer.SetShaderConstant4FV( "iDate", dates );
    this.mRenderer.SetShaderConstant3FV( "iChannelResolution", resos );        // OBSOLETE
    this.mRenderer.SetShaderConstant1F(  "iSampleRate", this.mSampleRate);
    this.mRenderer.SetShaderTextureUnit( "iChannel0", 0 );
    this.mRenderer.SetShaderTextureUnit( "iChannel1", 1 );
    this.mRenderer.SetShaderTextureUnit( "iChannel2", 2 );
    this.mRenderer.SetShaderTextureUnit( "iChannel3", 3 );
    this.mRenderer.SetShaderConstant1I(  "iFrame", this.mFrame );
    this.mRenderer.SetShaderConstant1F(  "iTimeDelta", dtime);
    this.mRenderer.SetShaderConstant1F(  "iFrameRate", fps );

    this.mRenderer.SetShaderConstant1F(  "iCh0.time", times[0] );
    this.mRenderer.SetShaderConstant1F(  "iCh1.time", times[1] );
    this.mRenderer.SetShaderConstant1F(  "iCh2.time", times[2] );
    this.mRenderer.SetShaderConstant1F(  "iCh3.time", times[3] );
    this.mRenderer.SetShaderConstant3F(  "iCh0.size", resos[0], resos[ 1], resos[ 2] );
    this.mRenderer.SetShaderConstant3F(  "iCh1.size", resos[3], resos[ 4], resos[ 5] );
    this.mRenderer.SetShaderConstant3F(  "iCh2.size", resos[6], resos[ 7], resos[ 8] );
    this.mRenderer.SetShaderConstant3F(  "iCh3.size", resos[9], resos[10], resos[11] );
    this.mRenderer.SetShaderConstant1I(  "iCh0.loaded",       texIsLoaded[0] );
    this.mRenderer.SetShaderConstant1I(  "iCh1.loaded",       texIsLoaded[1] );
    this.mRenderer.SetShaderConstant1I(  "iCh2.loaded",       texIsLoaded[2] );
    this.mRenderer.SetShaderConstant1I(  "iCh3.loaded",       texIsLoaded[3] );

    let l1 = this.mRenderer.GetAttribLocation(this.mProgram, "pos");


    if( (vrData !== null) && this.mSupportsVR )
    {
        for (let i=0; i<2; i++ )
        {
            let ei = (i===0) ? vrData.mLeftEye : vrData.mRightEye;

            let vp = [i * xres / 2, 0, xres / 2, yres];

            this.mRenderer.SetViewport(vp);

            let fov = ei.mProjection;
            let corA = [ -fov[2], -fov[1], -1.0 ];
            let corB = [  fov[3], -fov[1], -1.0 ];
            let corC = [  fov[3],  fov[0], -1.0 ];
            let corD = [ -fov[2],  fov[0], -1.0 ];
            let apex = [ 0.0, 0.0, 0.0 ];

            let ma = invertFast( ei.mCamera );
            corA = matMulpoint( ma, corA ); 
            corB = matMulpoint( ma, corB ); 
            corC = matMulpoint( ma, corC ); 
            corD = matMulpoint( ma, corD ); 
            apex = matMulpoint( ma, apex ); 

            let corners = [ corA[0], corA[1], corA[2], 
                            corB[0], corB[1], corB[2], 
                            corC[0], corC[1], corC[2], 
                            corD[0], corD[1], corD[2],
                            apex[0], apex[1], apex[2]];

            this.mRenderer.SetShaderConstant3FV("unCorners", corners);
            this.mRenderer.SetShaderConstant4FV("unViewport", vp);

            this.mRenderer.DrawUnitQuad_XY(l1);
        }
    }
    else 
    {
        this.mRenderer.SetViewport([0, 0, xres, yres]);
        this.mRenderer.DrawFullScreenTriangle_XY( l1 );
    }

    this.mRenderer.DettachTextures();
}

EffectPass.prototype.iRenderSound = function(d, callback )
{
    let dates = [ d.getFullYear(), // the year (four digits)
                  d.getMonth(),	   // the month (from 0-11)
                  d.getDate(),     // the day of the month (from 1-31)
                  d.getHours()*60.0*60 + d.getMinutes()*60 + d.getSeconds() ];

    let resos = [ 0.0,0.0,0.0, 0.0,0.0,0.0, 0.0,0.0,0.0, 0.0,0.0,0.0 ];

    this.mRenderer.SetRenderTarget(this.mRenderFBO);

    this.mRenderer.SetViewport([0, 0, this.mTextureDimensions, this.mTextureDimensions]);
    this.mRenderer.AttachShader(this.mProgram);
    this.mRenderer.SetBlend( false );

    let texID = [null, null, null, null];
    for (let i = 0; i < this.mInputs.length; i++)
    {
        let inp = this.mInputs[i];

        if( inp===null )
        {
        }
        else if( inp.mInfo.mType==="texture" )
        {
            if( inp.loaded===true  )
            {
                texID[i] = inp.globject;
                resos[3*i+0] = inp.image.width;
                resos[3*i+1] = inp.image.height;
                resos[3*i+2] = 1;
            }
        }
        else if( inp.mInfo.mType==="volume" )
        {
            if( inp.loaded===true  )
            {
                texID[i] = inp.globject;
                resos[3*i+0] = inp.mImage.mXres;
                resos[3*i+1] = inp.mImage.mYres;
                resos[3*i+2] = inp.mImage.mZres;
            }
        }
    }

    this.mRenderer.AttachTextures(4, texID[0], texID[1], texID[2], texID[3]);

    let l2 = this.mRenderer.SetShaderConstantLocation(this.mProgram, "iTimeOffset");
    let l3 = this.mRenderer.SetShaderConstantLocation(this.mProgram, "iSampleOffset");
    this.mRenderer.SetShaderConstant4FV("iDate", dates);
    this.mRenderer.SetShaderConstant3FV("iChannelResolution", resos);
    this.mRenderer.SetShaderConstant1F("iSampleRate", this.mSampleRate);
    this.mRenderer.SetShaderTextureUnit("iChannel0", 0);
    this.mRenderer.SetShaderTextureUnit("iChannel1", 1);
    this.mRenderer.SetShaderTextureUnit("iChannel2", 2);
    this.mRenderer.SetShaderTextureUnit("iChannel3", 3);

    let l1 = this.mRenderer.GetAttribLocation(this.mProgram, "pos");

    //--------------------------------
    let numSamples = this.mTmpBufferSamples;
    let numBlocks = this.mPlaySamples / numSamples;
    for (let j=0; j<numBlocks; j++ )
    {
        let off = j*numSamples;
        
        this.mRenderer.SetShaderConstant1F_Pos(l2, off / this.mSampleRate);
        this.mRenderer.SetShaderConstant1I_Pos(l3, off );
        this.mRenderer.DrawUnitQuad_XY(l1);

        this.mRenderer.GetPixelData(this.mData, 0, this.mTextureDimensions, this.mTextureDimensions);

        callback( off, this.mData, numSamples );
    }

    this.mRenderer.DetachShader();
    this.mRenderer.DettachTextures();
    this.mRenderer.SetRenderTarget(null);
}

EffectPass.prototype.Paint_Sound = function( wa, d )
{
    let bufL = this.mBuffer.getChannelData(0); // Float32Array
    let bufR = this.mBuffer.getChannelData(1); // Float32Array

    this.iRenderSound( d, function(off, data, numSamples)
                         {
                            for( let i=0; i<numSamples; i++ )
                            {
                                bufL[off+i] = -1.0 + 2.0*(data[4*i+0]+256.0*data[4*i+1])/65535.0;
                                bufR[off+i] = -1.0 + 2.0*(data[4*i+2]+256.0*data[4*i+3])/65535.0;
                            }
                         }
                     );
}

EffectPass.prototype.SetUniforms = function(vrData, wa, d, time, dtime, fps, mouseOriX, mouseOriY, mousePosX, mousePosY, xres, yres, buffers, cubeBuffers, keyboard )
{
    let times = [ 0.0, 0.0, 0.0, 0.0 ];

    let dates = [ d.getFullYear(), // the year (four digits)
                  d.getMonth(),	   // the month (from 0-11)
                  d.getDate(),     // the day of the month (from 1-31)
                  d.getHours()*60.0*60 + d.getMinutes()*60 + d.getSeconds()  + d.getMilliseconds()/1000.0 ];

    let mouse = [  mousePosX, mousePosY, mouseOriX, mouseOriY ];

    let resos = [ 0.0,0.0,0.0, 0.0,0.0,0.0, 0.0,0.0,0.0, 0.0,0.0,0.0 ];

    //------------------------
    
    let texID = [ null, null, null, null];

    for( let i=0; i<this.mInputs.length; i++ )
    {
        let inp = this.mInputs[i];

        if( inp===null )
        {
        }
        else if( inp.mInfo.mType==="texture" )
        {
            if( inp.loaded===true  )
            {
                texID[i] = inp.globject;
                resos[3*i+0] = inp.image.width;
                resos[3*i+1] = inp.image.height;
                resos[3*i+2] = 1;
            }
        }
        else if( inp.mInfo.mType==="volume" )
        {
            if( inp.loaded===true  )
            {
                texID[i] = inp.globject;
                resos[3*i+0] = inp.mImage.mXres;
                resos[3*i+1] = inp.mImage.mYres;
                resos[3*i+2] = inp.mImage.mZres;
            }
        }
        else if( inp.mInfo.mType==="keyboard" )
        {
            texID[i] = keyboard.mTexture;
        }
        else if( inp.mInfo.mType=="cubemap" )
        {
            if (inp.loaded === true)
            {
                let id = assetID_to_cubemapBuferID(inp.mInfo.mID);
                if( id!==-1 )
                {
                    texID[i] = cubeBuffers[id].mTexture[ cubeBuffers[id].mLastRenderDone ];
                    resos[3*i+0] = cubeBuffers[id].mResolution[0];
                    resos[3*i+1] = cubeBuffers[id].mResolution[1];
                    resos[3*i+2] = 1;
    
                    // hack. in webgl2.0 we have samplers, so we don't need this crap here
                    let filter = this.mRenderer.FILTER.NONE;
                         if (inp.mInfo.mSampler.filter === "linear") filter = this.mRenderer.FILTER.LINEAR;
                    else if (inp.mInfo.mSampler.filter === "mipmap") filter = this.mRenderer.FILTER.MIPMAP;
                    this.mRenderer.SetSamplerFilter( texID[i], filter, false);
                }
                else
                {
                    texID[i] = inp.globject;
                }
            }

        }
        else if( inp.mInfo.mType==="webcam" )
        {
            if( inp.loaded===true )
            {
                if( inp.mImage !== null )
                {
                    texID[i] = inp.globject;
                    resos[3*i+0] = inp.mImage.width;
                    resos[3*i+1] = inp.mImage.height;
                    resos[3*i+2] = 1;
                }
                else  if( inp.video.readyState === inp.video.HAVE_ENOUGH_DATA )
                {
                    texID[i] = inp.globject;
                    resos[3*i+0] = inp.video.videoWidth;
                    resos[3*i+1] = inp.video.videoHeight;
                    resos[3*i+2] = 1;
                }
            }
            else 
            {
                texID[i] = null;
                resos[3*i+0] = inp.video.width;
                resos[3*i+1] = inp.video.height;
                resos[3*i+2] = 1;
            }
        }
        else if( inp.mInfo.mType==="video" )
        {
           if( inp.loaded===true )
           { 
                times[i] = inp.video.currentTime;
                texID[i] = inp.globject;
                resos[3*i+0] = inp.video.videoWidth;
                resos[3*i+1] = inp.video.videoHeight;
                resos[3*i+2] = 1;
            }
        }
        else if( inp.mInfo.mType==="music" || inp.mInfo.mType==="musicstream" )
        {
            if( inp.loaded===true )
            {
                times[i] = inp.audio.currentTime;
                texID[i] = inp.globject;

                if( inp.audio.mForceMuted === true )
                {
                    times[i] = 10.0 + time;
                }

                resos[3*i+0] = 512;
                resos[3*i+1] = 2;
                resos[3*i+2] = 1;
            }
        }
        else if( inp.mInfo.mType==="mic" )
        {
            if( inp.loaded===false || inp.mForceMuted || wa === null || inp.mAnalyser == null )
            {
                times[i] = 10.0 + time;
            }

            if( inp.loaded===true )
            {
                texID[i] = inp.globject;
                resos[3*i+0] = 512;
                resos[3*i+1] = 2;
                resos[3*i+2] = 1;
            }
        }
        else if( inp.mInfo.mType==="buffer" )
        {
            if( inp.loaded===true  )
            {
                texID[i] = buffers[inp.id].mTexture[ buffers[inp.id].mLastRenderDone ];
                resos[3*i+0] = buffers[inp.id].mResolution[0];
                resos[3*i+1] = buffers[inp.id].mResolution[1];
                resos[3*i+2] = 1;
            }
        }
    }

    this.mRenderer.AttachTextures( 4, texID[0], texID[1], texID[2], texID[3] );

    //-----------------------------------

    this.mRenderer.AttachShader(this.mProgram);

    this.mRenderer.SetShaderConstant1F(  "iTime", time);
    this.mRenderer.SetShaderConstant3F(  "iResolution", xres, yres, 1.0);
    this.mRenderer.SetShaderConstant4FV( "iMouse", mouse);
    this.mRenderer.SetShaderConstant1FV( "iChannelTime", times );              // OBSOLETE
    this.mRenderer.SetShaderConstant4FV( "iDate", dates );
    this.mRenderer.SetShaderConstant3FV( "iChannelResolution", resos );        // OBSOLETE
    this.mRenderer.SetShaderConstant1F(  "iSampleRate", this.mSampleRate);
    this.mRenderer.SetShaderTextureUnit( "iChannel0", 0 );
    this.mRenderer.SetShaderTextureUnit( "iChannel1", 1 );
    this.mRenderer.SetShaderTextureUnit( "iChannel2", 2 );
    this.mRenderer.SetShaderTextureUnit( "iChannel3", 3 );
    this.mRenderer.SetShaderConstant1I(  "iFrame", this.mFrame );
    this.mRenderer.SetShaderConstant1F(  "iTimeDelta", dtime);
    this.mRenderer.SetShaderConstant1F(  "iFrameRate", fps );

    this.mRenderer.SetShaderConstant1F(  "iChannel[0].time",       times[0] );
    this.mRenderer.SetShaderConstant1F(  "iChannel[1].time",       times[1] );
    this.mRenderer.SetShaderConstant1F(  "iChannel[2].time",       times[2] );
    this.mRenderer.SetShaderConstant1F(  "iChannel[3].time",       times[3] );
    this.mRenderer.SetShaderConstant3F(  "iChannel[0].resolution", resos[0], resos[ 1], resos[ 2] );
    this.mRenderer.SetShaderConstant3F(  "iChannel[1].resolution", resos[3], resos[ 4], resos[ 5] );
    this.mRenderer.SetShaderConstant3F(  "iChannel[2].resolution", resos[6], resos[ 7], resos[ 8] );
    this.mRenderer.SetShaderConstant3F(  "iChannel[3].resolution", resos[9], resos[10], resos[11] );
}

EffectPass.prototype.ProcessInputs = function(vrData, wa, d, time, dtime, fps, mouseOriX, mouseOriY, mousePosX, mousePosY, xres, yres, buffers, cubeBuffers, keyboard )
{
    for (let i=0; i<this.mInputs.length; i++ )
    {
        let inp = this.mInputs[i];

        if( inp===null )
        {
        }
        else if( inp.mInfo.mType==="texture" )
        {
        }
        else if( inp.mInfo.mType==="volume" )
        {
        }
        else if( inp.mInfo.mType==="keyboard" )
        {
        }
        else if( inp.mInfo.mType==="cubemap" )
        {
        }
        else if( inp.mInfo.mType==="webcam" )
        {
            if( inp.loaded===true )
            {
                if( inp.mImage !== null )
                {
                    if( this.mTextureCallbackFun!==null )
                        this.mTextureCallbackFun( this.mTextureCallbackObj, i, inp.mImage, false, 7, 1, -1, this.mID );
                }
                else if( inp.video.readyState === inp.video.HAVE_ENOUGH_DATA )
                {
                    if( this.mTextureCallbackFun!==null )
                        this.mTextureCallbackFun( this.mTextureCallbackObj, i, inp.video, false, 7, 1, -1, this.mID );

                    this.mRenderer.UpdateTextureFromImage(inp.globject, inp.video);
                    if( inp.mInfo.mSampler.filter === "mipmap" )
                        this.mRenderer.CreateMipmaps(inp.globject);
                }
            }
        }
        else if( inp.mInfo.mType==="video" )
        {
            if( inp.video.mPaused === false )
            {
                if( this.mTextureCallbackFun!==null )
                    this.mTextureCallbackFun( this.mTextureCallbackObj, i, inp.video, false, 3, 1, inp.video.currentTime, this.mID );
            }

            if( inp.loaded===true )
            { 
      	        if( inp.video.mPaused === false )
      	        {
      	            this.mRenderer.UpdateTextureFromImage(inp.globject, inp.video);
                    if( inp.mInfo.mSampler.filter === "mipmap" )
                        this.mRenderer.CreateMipmaps(inp.globject);
                }
            }
        }
        else if( inp.mInfo.mType==="music" || inp.mInfo.mType==="musicstream" )
        {
            if( inp.audio.mPaused === false && inp.audio.mForceMuted === false && inp.loaded===true )
            {
                if( wa !== null )
                {
                    inp.audio.mSound.mAnalyser.getByteFrequencyData(  inp.audio.mSound.mFreqData );
                    inp.audio.mSound.mAnalyser.getByteTimeDomainData( inp.audio.mSound.mWaveData );
                }

                if( this.mTextureCallbackFun!==null )
                {
                         if( inp.mInfo.mType==="music")       this.mTextureCallbackFun(this.mTextureCallbackObj, i, (wa == null) ? null : { wave : inp.audio.mSound.mFreqData }, false, 4, 1, inp.audio.currentTime, this.mID);
                    else if( inp.mInfo.mType==="musicstream") this.mTextureCallbackFun(this.mTextureCallbackObj, i, (wa == null) ? null : { wave : inp.audio.mSound.mFreqData, info : inp.audio.soundcloudInfo}, false, 8, 1, inp.audio.currentTime, this.mID);
                }
            }

            if( inp.loaded===true )
            {
                if( inp.audio.mForceMuted === true )
                {
                    let num = inp.audio.mSound.mFreqData.length;
                    for (let j=0; j<num; j++ )
                    {
                        let x = j / num;
                        let f =  (0.75 + 0.25*Math.sin( 10.0*j + 13.0*time )) * Math.exp( -3.0*x );

                        if( j<3 )
                            f =  Math.pow( 0.50 + 0.5*Math.sin( 6.2831*time ), 4.0 ) * (1.0-j/3.0);

                        inp.audio.mSound.mFreqData[j] = Math.floor(255.0*f) | 0;
                    }

                  //let num = inp.audio.mSound.mFreqData.length;
                    for (let j=0; j<num; j++ )
                    {
                        let f = 0.5 + 0.15*Math.sin( 17.0*time + 10.0*6.2831*j/num ) * Math.sin( 23.0*time + 1.9*j/num );
                        inp.audio.mSound.mWaveData[j] = Math.floor(255.0*f) | 0;
                    }

                }

      	        if( inp.audio.mPaused === false )
                {
      	            let waveLen = Math.min(inp.audio.mSound.mWaveData.length, 512);
      	            this.mRenderer.UpdateTexture(inp.globject, 0, 0, 512, 1, inp.audio.mSound.mFreqData);
      	            this.mRenderer.UpdateTexture(inp.globject, 0, 1, 512, 1, inp.audio.mSound.mWaveData);
                }
            }
        }
        else if( inp.mInfo.mType==="mic" )
        {
            if( inp.loaded===false || inp.mForceMuted || wa === null || inp.mAnalyser == null )
            {
                    let num = inp.mFreqData.length;
                    for( let j=0; j<num; j++ )
                    {
                        let x = j / num;
                        let f =  (0.75 + 0.25*Math.sin( 10.0*j + 13.0*time )) * Math.exp( -3.0*x );

                        if( j<3 )
                            f =  Math.pow( 0.50 + 0.5*Math.sin( 6.2831*time ), 4.0 ) * (1.0-j/3.0);

                        inp.mFreqData[j] = Math.floor(255.0*f) | 0;
                    }

                    for( let j=0; j<num; j++ )
                    {
                        let f = 0.5 + 0.15*Math.sin( 17.0*time + 10.0*6.2831*j/num ) * Math.sin( 23.0*time + 1.9*j/num );
                        inp.mWaveData[j] = Math.floor(255.0*f) | 0;
                    }
            }
            else
            {
                inp.mAnalyser.getByteFrequencyData(  inp.mFreqData );
                inp.mAnalyser.getByteTimeDomainData( inp.mWaveData );
            }

            if( this.mTextureCallbackFun!==null )
                this.mTextureCallbackFun( this.mTextureCallbackObj, i, {wave:inp.mFreqData}, false, 5, 1, -1, this.mID );

            if( inp.loaded===true )
            {
                let waveLen = Math.min( inp.mWaveData.length, 512 );
                this.mRenderer.UpdateTexture(inp.globject, 0, 0, 512,     1, inp.mFreqData);
                this.mRenderer.UpdateTexture(inp.globject, 0, 1, waveLen, 1, inp.mWaveData);
            }
        }
        else if( inp.mInfo.mType==="buffer" )
        {
            if( inp.loaded===true  )
            {
                let id = inp.id;
                let texID = buffers[id].mTexture[ buffers[id].mLastRenderDone ];

                // hack. in webgl2.0 we have samplers, so we don't need this crap here
                let filter = this.mRenderer.FILTER.NONE;
                     if (inp.mInfo.mSampler.filter === "linear") filter = this.mRenderer.FILTER.LINEAR;
                else if (inp.mInfo.mSampler.filter === "mipmap") filter = this.mRenderer.FILTER.MIPMAP;
                this.mRenderer.SetSamplerFilter( texID, filter, false);
            }

            if( this.mTextureCallbackFun!==null )
            {
				let id = inp.id;
                this.mTextureCallbackFun( this.mTextureCallbackObj, i, {texture:inp.image, data:buffers[id].mThumbnailBuffer}, false, 9, 1, -1, this.mID );
            }
        }
    }
}

EffectPass.prototype.Paint_Cubemap = function( vrData, wa, d, time, dtime, fps, mouseOriX, mouseOriY, mousePosX, mousePosY, xres, yres, buffers, cubeBuffers, keyboard, face )
{
    this.ProcessInputs(vrData, wa, d, time, dtime, fps, mouseOriX, mouseOriY, mousePosX, mousePosY, xres, yres, buffers, cubeBuffers, keyboard, face );
    this.SetUniforms(vrData, wa, d, time, dtime, fps, mouseOriX, mouseOriY, mousePosX, mousePosY, xres, yres, buffers, cubeBuffers, keyboard );

    let l1 = this.mRenderer.GetAttribLocation(this.mProgram, "pos");

    let vp = [0, 0, xres, yres];

    this.mRenderer.SetViewport(vp);

    let corA = [ -1.0, -1.0, -1.0 ];
    let corB = [  1.0, -1.0, -1.0 ];
    let corC = [  1.0,  1.0, -1.0 ];
    let corD = [ -1.0,  1.0, -1.0 ];
    let apex = [  0.0,  0.0,  0.0 ];

    if( face===0 )
    {
        corA = [  1.0,  1.0,  1.0 ];
        corB = [  1.0,  1.0, -1.0 ];
        corC = [  1.0, -1.0, -1.0 ];
        corD = [  1.0, -1.0,  1.0 ];
    }
    else if( face===1 ) // -X
    {
        corA = [ -1.0,  1.0, -1.0 ];
        corB = [ -1.0,  1.0,  1.0 ];
        corC = [ -1.0, -1.0,  1.0 ];
        corD = [ -1.0, -1.0, -1.0 ];
    }
    else if( face===2 ) // +Y
    {
        corA = [ -1.0,  1.0, -1.0 ];
        corB = [  1.0,  1.0, -1.0 ];
        corC = [  1.0,  1.0,  1.0 ];
        corD = [ -1.0,  1.0,  1.0 ];
    }
    else if( face===3 ) // -Y
    {
        corA = [ -1.0, -1.0,  1.0 ];
        corB = [  1.0, -1.0,  1.0 ];
        corC = [  1.0, -1.0, -1.0 ];
        corD = [ -1.0, -1.0, -1.0 ];
    }
    else if( face===4 ) // +Z
    {
        corA = [ -1.0,  1.0,  1.0 ];
        corB = [  1.0,  1.0,  1.0 ];
        corC = [  1.0, -1.0,  1.0 ];
        corD = [ -1.0, -1.0,  1.0 ];
    }
    else //if( face===5 ) // -Z
    {
        corA = [  1.0,  1.0, -1.0 ];
        corB = [ -1.0,  1.0, -1.0 ];
        corC = [ -1.0, -1.0, -1.0 ];
        corD = [  1.0, -1.0, -1.0 ];
    }

    let corners = [ corA[0], corA[1], corA[2], 
                    corB[0], corB[1], corB[2], 
                    corC[0], corC[1], corC[2], 
                    corD[0], corD[1], corD[2],
                    apex[0], apex[1], apex[2]];

    this.mRenderer.SetShaderConstant3FV("unCorners", corners);
    this.mRenderer.SetShaderConstant4FV("unViewport", vp);

    this.mRenderer.DrawUnitQuad_XY(l1);

    this.mRenderer.DettachTextures();
}


EffectPass.prototype.Paint = function( vrData, wa, da, time, dtime, fps, mouseOriX, mouseOriY, mousePosX, mousePosY, xres, yres, isPaused, bufferID, bufferNeedsMimaps, buffers, cubeBuffers, keyboard, effect )
{
    if( this.mType==="sound" )
    {
        if (this.mSoundShaderCompiled === true)
        {
            // make sure all textures are loaded
            for (let i=0; i<this.mInputs.length; i++ )
            {
                let inp = this.mInputs[i];
                if (inp === null) continue;

                if (inp.mInfo.mType === "texture" && !inp.loaded) return;
                if (inp.mInfo.mType === "cubemap" && !inp.loaded) return;
            }

            this.Paint_Sound(wa, da);
            this.mSoundShaderCompiled = false;
        }
        if (this.mFrame === 0)
        {
            if (this.mPlaying===true)
            {
                this.mPlayNode.disconnect();
                this.mPlayNode.stop();
                this.mPlayNode = null;
            }
            this.mPlaying = true;

            this.mPlayNode = wa.createBufferSource();
            this.mPlayNode.buffer = this.mBuffer;
            this.mPlayNode.connect(this.mGainNode);
            this.mPlayNode.start(0);
        }
        this.mFrame++;
    }
    else if( this.mType==="image" )
    {
        this.mRenderer.SetRenderTarget( null );
        this.Paint_Image( vrData, wa, da, time, dtime, fps, mouseOriX, mouseOriY, mousePosX, mousePosY, xres, yres, buffers, cubeBuffers, keyboard );
        this.mFrame++;
    }
    else if( this.mType==="common" )
    {
        //console.log("rendering common");
    }
    else if( this.mType==="buffer" )
    {
        this.mEffect.ResizeBuffer(bufferID, this.mEffect.mXres, this.mEffect.mYres, false );

        let buffer = buffers[bufferID];

        let dstID = 1 - buffer.mLastRenderDone;

        this.mRenderer.SetRenderTarget( buffer.mTarget[dstID] );
        this.Paint_Image( vrData, wa, da, time, dtime, fps, mouseOriX, mouseOriY, mousePosX, mousePosY, xres, yres, buffers, cubeBuffers, keyboard );

        // compute mipmaps if needd
        if( bufferNeedsMimaps )
        {
            this.mRenderer.CreateMipmaps( buffer.mTexture[dstID]);
        }

        // make thumbnail
        //if( this.mTextureCallbackFun != null )
        /*
        {
            this.mRenderer.SetRenderTarget( buffer.mThumbnailRenderTarget );
            let v = [0, 0, buffer.mThumbnailRes[0], buffer.mThumbnailRes[1]];
            this.mRenderer.SetBlend(false);
            this.mRenderer.SetViewport(v);
            this.mRenderer.AttachShader(this.mProgramCopy);
            let l1 = this.mRenderer.GetAttribLocation(this.mProgramCopy, "pos");
            this.mRenderer.SetShaderConstant4FV("v", v);
            this.mRenderer.AttachTextures(1, buffer.mTexture[dstID], null, null, null);
            this.mRenderer.DrawUnitQuad_XY(l1);
            this.mRenderer.DettachTextures();
            this.mRenderer.DetachShader();
            this.mRenderer.GetPixelData( new Uint8Array(buffer.mThumbnailBuffer.data.buffer), buffer.mThumbnailRes[0], buffer.mThumbnailRes[1] );
            this.mRenderer.SetRenderTarget(null);
        }
        */
        buffers[bufferID].mLastRenderDone = 1 - buffers[bufferID].mLastRenderDone;
        this.mFrame++;
    }
    else if( this.mType==="cubemap" )
    {
        this.mEffect.ResizeCubemapBuffer(bufferID, 1024, 1024, false );

        let buffer = cubeBuffers[bufferID];

        xres = buffer.mResolution[0];
        yres = buffer.mResolution[1];
        let dstID = 1 - buffer.mLastRenderDone;
        for( let face=0; face<6; face++ )
        {
            this.mRenderer.SetRenderTargetCubeMap( buffer.mTarget[dstID], face );
            this.Paint_Cubemap( vrData, wa, da, time, dtime, fps, mouseOriX, mouseOriY, mousePosX, mousePosY, xres, yres, buffers, cubeBuffers, keyboard, face );
        }
        this.mRenderer.SetRenderTargetCubeMap( null, 0 );

        // compute mipmaps if needd
        if( bufferNeedsMimaps )
        {
            this.mRenderer.CreateMipmaps( buffer.mTexture[dstID]);
        }
        cubeBuffers[bufferID].mLastRenderDone = 1 - cubeBuffers[bufferID].mLastRenderDone;

        this.mFrame++;
    }

}

EffectPass.prototype.StopOutput_Sound = function( wa )
{
    if( this.mPlayNode===null ) return;
    this.mPlayNode.disconnect();

};

EffectPass.prototype.ResumeOutput_Sound = function( wa )
{
    if( this.mPlayNode===null ) return;

    wa.resume()
    this.mPlayNode.connect( this.mGainNode );
};

EffectPass.prototype.StopOutput_Image = function( wa )
{
};

EffectPass.prototype.ResumeOutput_Image = function( wa )
{
};

EffectPass.prototype.StopOutput = function( wa )
{
    for (let j=0; j<this.mInputs.length; j++ )
        this.StopInput(j);

    if( this.mType==="sound" )
         this.StopOutput_Sound( wa );
    else
         this.StopOutput_Image( wa );
}

EffectPass.prototype.ResumeOutput = function( wa )
{
    for (let j=0; j<this.mInputs.length; j++ )
        this.ResumeInput(j);

    if( this.mType==="sound" )
         this.ResumeOutput_Sound( wa );
    else
         this.ResumeOutput_Image( wa );
}

EffectPass.prototype.GetCompilationTime = function()
{
    return this.mCompilationTime;
}

//============================================================================================================
function Screenshots()
{
    // private
    let mTexture = null;
    let mTarget = null;
    let mXres = 0;
    let mYres = 0;
    let mCubemapToEquirectProgram;
    let mRenderer = null;

    // public
    var me = {};

    me.Initialize = function(renderer)
    {
        mRenderer = renderer;
        let caps = mRenderer.GetCaps();
        let is20 = caps.mIsGL20;


        let vsSourceC, fsSourceC;
        if( is20 )
        {
            vsSourceC = "layout(location = 0) in vec2 pos; void main() { gl_Position = vec4(pos.xy,0.0,1.0); }";
            fsSourceC = "uniform samplerCube t; out vec4 outColor; void main() { vec2 px = gl_FragCoord.xy/vec2(4096.0,2048.0); vec2 an = 3.1415926535898 * (px*vec2(2.0, 1.0) - vec2(0.0,0.5)); vec3 rd = vec3(-cos(an.y) * sin(an.x), sin(an.y), cos(an.y) * cos(an.x)); outColor = texture(t, rd); }";
        }
        else
        {
            vsSourceC = "attribute vec2 pos; void main() { gl_Position = vec4(pos.xy,0.0,1.0); }";
            fsSourceC = "uniform samplerCube t; void main() { vec2 px = gl_FragCoord.xy/vec2(4096.0,2048.0); vec2 an = 3.1415926535898 * (px*vec2(2.0, 1.0) - vec2(0.0,0.5)); vec3 rd = vec3(-cos(an.y) * sin(an.x), sin(an.y), cos(an.y) * cos(an.x)); gl_FragColor = texture(t, rd); }";
        }

        let compileShader = function (worked, info)
        {
            if (worked === false)
            {
                console.log("Failed to compile cubemap resample shader (" + errorType + "): " + log);
            }
            else
            {
                mCubemapToEquirectProgram = info;
            }
        }
        mRenderer.CreateShader(vsSourceC, fsSourceC, false, true, compileShader);

        return true;
    };

    me.Allocate = function( xres, yres )
    {
        if( xres>mXres || yres>mYres )
        {
            let texture = mRenderer.CreateTexture(mRenderer.TEXTYPE.T2D, xres, yres, mRenderer.TEXFMT.C4F32, mRenderer.FILTER.NONE, mRenderer.TEXWRP.CLAMP, null);
            let target = mRenderer.CreateRenderTarget( texture, null, null, null, null, false);

            if( mXres!==0 )
            {
                mRenderer.DestroyTexture(mTexture);
                mRenderer.DestroyRenderTarget(mTarget);
            }

            mTexture = texture;
            mTarget = target;
            mXres = xres;
            mYres = yres;
        }
    };

    me.GetProgram = function()
    {
        return mCubemapToEquirectProgram;
    };
    me.GetTarget = function()
    {
        return mTarget;
    };

    return me;
};

//============================================================================================================

function Effect(vr, ac, canvas, callback, obj, forceMuted, forcePaused, resizeCallback, crashCallback )
{
    let xres = canvas.width;
    let yres = canvas.height;

    let me = this;
    this.mCanvas = canvas;
    this.mCreated = false;
    this.mRenderer = null;
    this.mAudioContext = ac;
    this.mGLContext = null;
    this.mWebVR = vr;
    this.mRenderingStereo = false;
    this.mXres = xres;
    this.mYres = yres;
    this.mForceMuted = forceMuted;
    if( ac===null ) this.mForceMuted = true;
    this.mForcePaused = forcePaused;
    this.mGainNode = null;
    this.mPasses = [];
    this.mFrame = 0;
    this.mTextureCallbackFun = callback;
    this.mTextureCallbackObj = obj;
    this.mMaxBuffers = 4;
    this.mMaxCubeBuffers = 1;
    this.mMaxPasses = this.mMaxBuffers + 1 + 1 + 1 + 1; // some day decouple passes from buffers (4 buffers + common + Imagen + sound + cubemap)
    this.mBuffers = [];
    this.mCubeBuffers = [];
    this.mScreenshotSytem = null;
    this.mCompilationTime = 0;
    this.mIsLowEnd = piIsMobile();

    this.mGLContext = piCreateGlContext(canvas, false, false, true, false); // need preserve-buffe to true in order to capture screenshots
    if (this.mGLContext === null)
    {
        return;
    }

    canvas.addEventListener("webglcontextlost", function (event)
        {
            event.preventDefault();
            crashCallback();
        }, false);

    this.mRenderer = piRenderer();
    if (!this.mRenderer.Initialize(this.mGLContext))
        return;

    this.mScreenshotSytem = Screenshots();
    if (!this.mScreenshotSytem.Initialize(this.mRenderer))
        return;

    var caps = this.mRenderer.GetCaps();
    this.mIs20 = caps.mIsGL20;
    this.mShaderTextureLOD = caps.mShaderTextureLOD;
    //-------------
    if( ac!==null )
    {   
        this.mGainNode = ac.createGain();
        if( !forceMuted )
        {
            this.mGainNode.connect( ac.destination);
        }
        if (this.mForceMuted )
            this.mGainNode.gain.value = 0.0;
        else
            this.mGainNode.gain.value = 1.0;
    }

    //-------------
    let vsSourceC, fsSourceC;
    if( this.mIs20 )
    {
        vsSourceC = "layout(location = 0) in vec2 pos; void main() { gl_Position = vec4(pos.xy,0.0,1.0); }";
        fsSourceC = "uniform vec4 v; uniform sampler2D t; out vec4 outColor; void main() { outColor = textureLod(t, gl_FragCoord.xy / v.zw, 0.0); }";
    }
    else
    {
        vsSourceC = "attribute vec2 pos; void main() { gl_Position = vec4(pos.xy,0.0,1.0); }";
        fsSourceC = "uniform vec4 v; uniform sampler2D t; void main() { gl_FragColor = texture2D(t, gl_FragCoord.xy / v.zw, -100.0); }";
    }

    this.mRenderer.CreateShader(vsSourceC, fsSourceC, false, true, function(worked, info)
        {
            if (worked === false) console.log("Failed to compile shader to copy buffers : " + info.mErrorStr);
            else me.mProgramCopy = info;
        });

    let vsSourceD, fsSourceD;
    if( this.mIs20 )
    {
        vsSourceD = "layout(location = 0) in vec2 pos; void main() { gl_Position = vec4(pos.xy,0.0,1.0); }";
        fsSourceD = "uniform vec4 v; uniform sampler2D t; out vec4 outColor; void main() { vec2 uv = gl_FragCoord.xy / v.zw; outColor = texture(t, vec2(uv.x,1.0-uv.y)); }";
    }
    else
    {
        vsSourceD = "attribute vec2 pos; void main() { gl_Position = vec4(pos.xy,0.0,1.0); }";
        fsSourceD = "uniform vec4 v; uniform sampler2D t; void main() { vec2 uv = gl_FragCoord.xy / v.zw; gl_FragColor = texture2D(t, vec2(uv.x,1.0-uv.y)); }";
    }

    this.mRenderer.CreateShader(vsSourceD, fsSourceD, false, true, function (worked, info)
        {
            if (worked === false) console.log("Failed to compile shader to downscale buffers : " + info.mErrorStr);
            else me.mProgramDownscale = info;
        });


    // set all buffers and cubemaps to null
    for( let i=0; i<this.mMaxBuffers; i++ )
    {
        this.mBuffers[i] = { mTexture: [null, null], 
                             mTarget:  [null, null], 
                             mResolution: [0, 0],
                             mLastRenderDone: 0,
                             mThumbnailRenderTarget: null,
                             mThumbnailTexture: null,
                             mThumbnailBuffer:  null,
                             mThumbnailRes: [0, 0] };
    }

    for( let i=0; i<this.mMaxCubeBuffers; i++ )
    {
        this.mCubeBuffers[i] = { mTexture: [null, null], 
                                mTarget:  [null, null], 
                                mResolution: [0, 0],
                                mLastRenderDone: 0,
                                mThumbnailRenderTarget: null,
                                mThumbnailTexture: null,
                                mThumbnailBuffer:  null,
                                mThumbnailRes: [0, 0] };
    }

    //-------

    let keyboardData = new Uint8Array( 256*3 );
    for (let j=0; j<(256*3); j++ ) { keyboardData[j] = 0; }
    let kayboardTexture = this.mRenderer.CreateTexture( this.mRenderer.TEXTYPE.T2D, 256, 3, this.mRenderer.TEXFMT.C1I8, this.mRenderer.FILTER.NONE, this.mRenderer.TEXWRP.CLAMP, null);
    let keyboardImage = new Image();
    if( callback!==null )
        keyboardImage.src = "/img/keyboard.png"; // don't load PNG if no UI 
    this.mKeyboard = { mData: keyboardData, mTexture: kayboardTexture, mIcon: keyboardImage };

    let iResize = function( xres, yres )
    {
        me.mCanvas.width = xres;
        me.mCanvas.height = yres;
        me.mXres = xres;
        me.mYres = yres;
        me.ResizeBuffers(xres, yres);
        resizeCallback(xres, yres);
    };

    let bestAttemptFallback = function()
    {
        let devicePixelRatio = window.devicePixelRatio || 1;
        let xres = Math.round(me.mCanvas.offsetWidth  * devicePixelRatio) | 0;
        let yres = Math.round(me.mCanvas.offsetHeight * devicePixelRatio) | 0;
        iResize(xres, yres);
    };

    if(!window.ResizeObserver)
    {
        console.log("WARNING: This browser doesn't support ResizeObserver.");
        bestAttemptFallback();
        window.addEventListener("resize", bestAttemptFallback);
    }
    else
    {
        this.mRO = new ResizeObserver( function(entries, observer)
        {
            var entry = entries[0];
            if (!entry['devicePixelContentBoxSize'])
            {
                observer.unobserve(me.mCanvas);
                console.log("WARNING: This browser doesn't support ResizeObserver + device-pixel-content-box (2)");
                bestAttemptFallback();
                window.addEventListener("resize", bestAttemptFallback);
            }
            else
            {
                let box = entry.devicePixelContentBoxSize[0];
                let xres = box.inlineSize;
                let yres = box.blockSize;
                iResize(xres, yres);
            }
        });
        try
        {
            this.mRO.observe(this.mCanvas, { box: ["device-pixel-content-box"] });
            //this.mRO.observe(this.mCanvas);
        }
        catch (e)
        {
            console.log("WARNING: This browser doesn't support ResizeObserver + device-pixel-content-box (1)");
            bestAttemptFallback();
            window.addEventListener("resize", bestAttemptFallback);
        }
    }

    this.mCreated = true;
}


Effect.prototype.ResizeCubemapBuffer = function(i, xres, yres )
{
    let oldXres = this.mCubeBuffers[i].mResolution[0];
    let oldYres = this.mCubeBuffers[i].mResolution[1];

    if( this.mCubeBuffers[i].mTexture[0]===null || oldXres !== xres || oldYres !== yres )
    {
        let texture1 = this.mRenderer.CreateTexture(this.mRenderer.TEXTYPE.CUBEMAP,
            xres, yres,
            this.mRenderer.TEXFMT.C4F16,
            this.mRenderer.FILTER.LINEAR,
            this.mRenderer.TEXWRP.CLAMP, 
            null);
        let target1 = this.mRenderer.CreateRenderTargetCubeMap( texture1, null, false);

        let texture2 = this.mRenderer.CreateTexture(this.mRenderer.TEXTYPE.CUBEMAP,
            xres, yres,
            this.mRenderer.TEXFMT.C4F16,
            this.mRenderer.FILTER.LINEAR,
            this.mRenderer.TEXWRP.CLAMP, 
            null);

        let target2 = this.mRenderer.CreateRenderTargetCubeMap( texture2, null, false);

        // Store new buffers
        this.mCubeBuffers[i].mTexture = [texture1,texture2], 
        this.mCubeBuffers[i].mTarget =  [target1, target2 ], 
        this.mCubeBuffers[i].mLastRenderDone = 0;
        this.mCubeBuffers[i].mResolution[0] = xres;
        this.mCubeBuffers[i].mResolution[1] = yres;
    }
}


Effect.prototype.ResizeBuffer = function( i, xres, yres, skipIfNotExists )
{
    if( skipIfNotExists && this.mBuffers[i].mTexture[0]===null ) return;

    let oldXres = this.mBuffers[i].mResolution[0];
    let oldYres = this.mBuffers[i].mResolution[1];

    if( oldXres !== xres || oldYres !== yres )
    {
        let needCopy = (this.mBuffers[i].mTexture[0]!==null);

        let texture1 = this.mRenderer.CreateTexture(this.mRenderer.TEXTYPE.T2D,
            xres, yres,
            this.mRenderer.TEXFMT.C4F32,
            (needCopy) ? this.mBuffers[i].mTexture[0].mFilter : this.mRenderer.FILTER.NONE,
            (needCopy) ? this.mBuffers[i].mTexture[0].mWrap   : this.mRenderer.TEXWRP.CLAMP, 
            null);

        let texture2 = this.mRenderer.CreateTexture(this.mRenderer.TEXTYPE.T2D,
            xres, yres,
            this.mRenderer.TEXFMT.C4F32,
            (needCopy) ? this.mBuffers[i].mTexture[1].mFilter : this.mRenderer.FILTER.NONE,
            (needCopy) ? this.mBuffers[i].mTexture[1].mWrap   : this.mRenderer.TEXWRP.CLAMP, 
            null);

        let target1 = this.mRenderer.CreateRenderTarget( texture1, null, null, null, null, false);
        let target2 = this.mRenderer.CreateRenderTarget( texture2, null, null, null, null, false);

        if( needCopy )
        {
            let v = [0, 0, Math.min(xres, oldXres), Math.min(yres, oldYres)];
            this.mRenderer.SetBlend(false);
            this.mRenderer.SetViewport(v);
            this.mRenderer.AttachShader(this.mProgramCopy);
            let l1 = this.mRenderer.GetAttribLocation(this.mProgramCopy, "pos");
            let vOld = [0, 0, oldXres, oldYres];
            this.mRenderer.SetShaderConstant4FV("v", vOld);

            // Copy old buffers 1 to new buffer
            this.mRenderer.SetRenderTarget(target1);
            this.mRenderer.AttachTextures(1, this.mBuffers[i].mTexture[0], null, null, null);
            this.mRenderer.DrawUnitQuad_XY(l1);

            // Copy old buffers 2 to new buffer
            this.mRenderer.SetRenderTarget(target2);
            this.mRenderer.AttachTextures(1, this.mBuffers[i].mTexture[1], null, null, null);
            this.mRenderer.DrawUnitQuad_XY(l1);

            // Deallocate old memory
            this.mRenderer.DestroyTexture(this.mBuffers[i].mTexture[0]);
            this.mRenderer.DestroyRenderTarget(this.mBuffers[i].mTarget[0]);
            this.mRenderer.DestroyTexture(this.mBuffers[i].mTexture[1]);
            this.mRenderer.DestroyRenderTarget(this.mBuffers[i].mTarget[1]);
            //this.mRenderer.DestroyTexture(this.mBuffers[i].thumbnailTexture);
        }

        // Store new buffers
        this.mBuffers[i].mTexture = [texture1,texture2], 
        this.mBuffers[i].mTarget =  [target1, target2 ], 
        this.mBuffers[i].mLastRenderDone = 0;
        this.mBuffers[i].mResolution[0] = xres;
        this.mBuffers[i].mResolution[1] = yres;
    }
}

Effect.prototype.saveScreenshot = function(passid)
{
    let pass = this.mPasses[passid];

    if( pass.mType === "buffer" )
    {
        let bufferID = assetID_to_bufferID( this.mPasses[passid].mOutputs[0] );

        let texture = this.mBuffers[bufferID].mTarget[ this.mBuffers[bufferID].mLastRenderDone ];

        let numComponents = 3;
        let width = texture.mTex0.mXres;
        let height = texture.mTex0.mYres;
        let type = "Float"; // Other options Float, Half, Uint
        let bytes = new Float32Array(width * height * 4 );//numComponents);
        this.mRenderer.GetPixelDataRenderTarget( texture, bytes, width, height );
        let blob = piExportToEXR(width, height, numComponents, type, bytes);

        // Offer download automatically to the user
        piTriggerDownload("image.exr", blob);
    }
    else if( pass.mType === "cubemap" )
    {
        let xres = 4096;
        let yres = 2048;
        this.mScreenshotSytem.Allocate( xres, yres );

        let cubeBuffer = this.mCubeBuffers[0];

        let target = this.mScreenshotSytem.GetTarget();
        this.mRenderer.SetRenderTarget( target );

        let program = this.mScreenshotSytem.GetProgram();

        this.mRenderer.AttachShader(program);
        let l1 = this.mRenderer.GetAttribLocation(program, "pos");
        this.mRenderer.SetViewport( [0, 0, xres, yres] );
        this.mRenderer.AttachTextures(1, cubeBuffer.mTexture[ cubeBuffer.mLastRenderDone ], null, null, null);
        this.mRenderer.DrawUnitQuad_XY(l1);
        this.mRenderer.DettachTextures();
        this.mRenderer.SetRenderTarget( null );

        let data = new Float32Array(xres*yres*4);
        this.mRenderer.GetPixelDataRenderTarget( target, data, xres, yres );

        let blob = piExportToEXR(xres, yres, 3, "Float", data );
        piTriggerDownload("image.exr", blob);
    }
    else if( pass.mType === "sound" )
    {
        let offset = 0;
        const bits = 16;
        const numChannels = 2;
        let words = new Int16Array(60*pass.mSampleRate*numChannels );

        pass.iRenderSound( new Date(), function(off, data, numSamples)
                                         {
                                            for( let i=0; i<numSamples; i++ )
                                            {
                                                words[offset++] = (data[4*i+0]+256.0*data[4*i+1]) - 32767;
                                                words[offset++] = (data[4*i+2]+256.0*data[4*i+3]) - 32767;
                                            }
                                         }
                                     );

        let blob = piExportToWAV( 60*pass.mSampleRate, pass.mSampleRate, bits, numChannels, words);

        piTriggerDownload("sound.wav", blob);
    }    
}

Effect.prototype.ResizeBuffers = function(xres, yres)
{
    for (let i=0; i<this.mMaxBuffers; i++ )
    {
        this.ResizeBuffer(i, xres, yres, true);
    }
}

Effect.prototype.IsEnabledVR = function ()
{
    if (this.mRenderingStereo) return true;
    return false;
}

Effect.prototype.EnableVR = function()
{
    if( !this.mWebVR.IsSupported() ) return;
    if( this.mRenderingStereo ) return;

    this.mRenderingStereo = true;
    this.mWebVR.Enable();
}

Effect.prototype.DisableVR = function()
{
    if( !this.mWebVR.IsSupported() ) return;
    if( !this.mRenderingStereo ) return;

    this.mRenderingStereo = false;
    this.mWebVR.Disable();
}

Effect.prototype.GetTexture = function( passid, slot )
{
    return this.mPasses[passid].GetTexture( slot );
}

Effect.prototype.NewTexture = function( passid, slot, url )
{
    return this.mPasses[passid].NewTexture( this.mAudioContext, slot, url, this.mBuffers, this.mCubeBuffers, this.mKeyboard );
}

Effect.prototype.SetOutputs = function( passid, slot, url )
{
    this.mPasses[passid].SetOutputs( slot, url );
}

Effect.prototype.SetOutputsByBufferID = function( passid, slot, id )
{
    this.mPasses[passid].SetOutputsByBufferID( slot, id );
}

Effect.prototype.GetAcceptsLinear = function (passid, slot) 
{
    return this.mPasses[passid].GetAcceptsLinear(slot);
}

Effect.prototype.GetAcceptsMipmapping = function (passid, slot) 
{
    return this.mPasses[passid].GetAcceptsMipmapping(slot);
}

Effect.prototype.GetAcceptsWrapRepeat = function (passid, slot) 
{
    return this.mPasses[passid].GetAcceptsWrapRepeat(slot);
}

Effect.prototype.GetAcceptsVFlip = function (passid, slot)
{
    return this.mPasses[passid].GetAcceptsVFlip(slot);
}

Effect.prototype.SetSamplerFilter = function (passid, slot, str) 
{
    this.mPasses[passid].SetSamplerFilter(slot, str, this.mBuffers, this.mCubeBuffers);
}

Effect.prototype.GetTranslatedShaderSource = function (passid)
{
    return this.mPasses[passid].GetTranslatedShaderSource();
}

Effect.prototype.GetSamplerFilter = function (passid, slot) {
    return this.mPasses[passid].GetSamplerFilter(slot);
}

Effect.prototype.SetSamplerWrap = function (passid, slot, str) {
    this.mPasses[passid].SetSamplerWrap(slot, str, this.mBuffers);
}

Effect.prototype.GetSamplerWrap = function (passid, slot) {
    return this.mPasses[passid].GetSamplerWrap(slot);
}

Effect.prototype.SetSamplerVFlip = function (passid, slot, str) {
    this.mPasses[passid].SetSamplerVFlip(slot, str);
}

Effect.prototype.GetSamplerVFlip = function (passid, slot) {
    return this.mPasses[passid].GetSamplerVFlip(slot);
}

Effect.prototype.GetHeaderSize = function (passid)
{
    return this.mPasses[passid].mHeaderLength + 
           this.mRenderer.GetShaderHeaderLines(1);
 
}

Effect.prototype.ToggleVolume = function()
{
    this.mForceMuted = !this.mForceMuted;

    // outp
    if (this.mForceMuted)
        this.mGainNode.gain.value = 0.0;
    else
        this.mGainNode.gain.value = 1.0;

    // inp
    let num = this.mPasses.length;
    for( let j=0; j<num; j++ )
    {
        for( let i=0; i<this.mPasses[j].mInputs.length; i++ )
        {
            if( this.mForceMuted )
                this.mPasses[j].MuteInput( this.mAudioContext, i );
            else
                this.mPasses[j].UnMuteInput( this.mAudioContext, i );
        }
    }

    return this.mForceMuted;
}

Effect.prototype.SetKeyDown = function( passid, k )
{
    if( this.mKeyboard.mData[ k + 0*256 ] == 255 ) return;

    this.mKeyboard.mData[ k + 0*256 ] = 255;
    this.mKeyboard.mData[ k + 1*256 ] = 255;
    this.mKeyboard.mData[ k + 2*256 ] = 255 - this.mKeyboard.mData[ k + 2*256 ];
    this.mRenderer.UpdateTexture( this.mKeyboard.mTexture, 0, 0, 256, 3, this.mKeyboard.mData );

    let num = this.mPasses.length;
    for (let j=0; j<num; j++ )
    {
        for (let i=0; i<this.mPasses[j].mInputs.length; i++ )
        {
            let inp = this.mPasses[j].mInputs[i];
            if( inp!==null && inp.mInfo.mType==="keyboard" )
            {
                if( this.mTextureCallbackFun!==null )
                    this.mTextureCallbackFun( this.mTextureCallbackObj, i, {mImage:this.mKeyboard.mIcon, mData: this.mKeyboard.mData}, false, 6, 1, -1.0, this.mPasses[j].mID );
            }
        }
    }
}

Effect.prototype.SetKeyUp = function( passid, k )
{
    this.mKeyboard.mData[ k + 0*256 ] = 0;
    this.mKeyboard.mData[ k + 1*256 ] = 0;
    this.mRenderer.UpdateTexture( this.mKeyboard.mTexture, 0, 0, 256, 3, this.mKeyboard.mData );

    let num = this.mPasses.length;
    for (let j=0; j<num; j++ )
    {
        for (let i=0; i<this.mPasses[j].mInputs.length; i++ )
        {
            let inp = this.mPasses[j].mInputs[i];
            if( inp!==null && inp.mInfo.mType==="keyboard" )
            {
                if( this.mTextureCallbackFun!==null )
                    this.mTextureCallbackFun( this.mTextureCallbackObj, i, {mImage:this.mKeyboard.mIcon, mData: this.mKeyboard.mData}, false, 6, 1, -1.0, this.mPasses[j].mID );
            }
        }
    }

}

Effect.prototype.StopOutputs = function()
{
    let wa = this.mAudioContext;

    let num = this.mPasses.length;
    for (let i=0; i<num; i++ )
    {
        this.mPasses[i].StopOutput( wa );
    }
}

Effect.prototype.ResumeOutputs = function()
{
    let wa = this.mAudioContext;

    let num = this.mPasses.length;
    for (let i=0; i<num; i++ )
    {
        this.mPasses[i].ResumeOutput( wa );
    }
}

Effect.prototype.PauseInput = function( passid, id )
{
    return this.mPasses[passid].TooglePauseInput( this.mAudioContext, id );
}

Effect.prototype.ToggleMuteInput = function( passid, id )
{
    return this.mPasses[passid].ToggleMuteInput( this.mAudioContext, id );
}

Effect.prototype.RewindInput = function( passid, id )
{
    this.mPasses[passid].RewindInput( this.mAudioContext, id );
}

Effect.prototype.UpdateInputs = function( passid, forceUpdate )
{
   this.mPasses[passid].UpdateInputs( this.mAudioContext, forceUpdate, this.mKeyboard );
}

Effect.prototype.ResetTime = function()
{
    this.mFrame = 0;
    this.mAudioContext.resume()

    let num = this.mPasses.length;
    for( let i=0; i<num; i++ )
    {
        this.mPasses[i].mFrame = 0;
        for( let j=0; j<this.mPasses[i].mInputs.length; j++ )
            this.mPasses[i].RewindInput(this.mAudioContext, j)
    }
}

Effect.prototype.RequestAnimationFrame = function (id)
{
    if (this.mRenderingStereo && this.mWebVR.IsPresenting())
    {
        this.mWebVR.RequestAnimationFrame(id);
    }
    else
    {
        requestAnimFrame(id);
    }
}

Effect.prototype.Paint = function(time, dtime, fps, mouseOriX, mouseOriY, mousePosX, mousePosY, isPaused)
{
    let wa = this.mAudioContext;
    let da = new Date();
    let vrData = null; if (this.mRenderingStereo) vrData = this.mWebVR.GetData();
    let xres = this.mXres / 1;
    let yres = this.mYres / 1;

    if( this.mFrame===0 )
    {
        for( let i=0; i<this.mMaxBuffers; i++ )
        {
            if( this.mBuffers[i].mTexture[0]!==null )
            {
                this.mRenderer.SetRenderTarget( this.mBuffers[i].mTarget[0] );
                this.mRenderer.Clear( this.mRenderer.CLEAR.Color, [0.0,0.0,0.0,0.0], 1.0, 0   );
                this.mRenderer.SetRenderTarget( this.mBuffers[i].mTarget[1] );
                this.mRenderer.Clear( this.mRenderer.CLEAR.Color, [0.0,0.0,0.0,0.0], 1.0, 0   );
				
				this.mRenderer.CreateMipmaps( this.mBuffers[i].mTexture[0] );
				this.mRenderer.CreateMipmaps( this.mBuffers[i].mTexture[1] );
            }
        }
        for( let i=0; i<this.mMaxCubeBuffers; i++ )
        {
            if( this.mCubeBuffers[i].mTexture[0]!==null )
            {
                for( let face=0; face<6; face++ )
                {
                    this.mRenderer.SetRenderTargetCubeMap( this.mCubeBuffers[i].mTarget[0], face );
                    this.mRenderer.Clear( this.mRenderer.CLEAR.Color, [0.0,0.0,0.0,0.0], 1.0, 0   );
                    this.mRenderer.SetRenderTargetCubeMap( this.mCubeBuffers[i].mTarget[1], face );
                    this.mRenderer.Clear( this.mRenderer.CLEAR.Color, [0.0,0.0,0.0,0.0], 1.0, 0   );
					this.mRenderer.CreateMipmaps( this.mCubeBuffers[i].mTexture[0] );
				    this.mRenderer.CreateMipmaps( this.mCubeBuffers[i].mTexture[1] );
                }
            }
        }
    }

    let num = this.mPasses.length;

    // render sound first
    for( let i=0; i<num; i++ )
    {
        if( this.mPasses[i].mType !== "sound" ) continue;
        if( this.mPasses[i].mProgram===null ) continue;
        this.mPasses[i].Paint( vrData, wa, da, time, dtime, fps, mouseOriX, mouseOriY, mousePosX, mousePosY, xres, yres, isPaused, null, false, this.mBuffers, this.mCubeBuffers, this.mKeyboard, this );
    }

    // render buffers second
    for( let i=0; i<num; i++ )
    {
        if( this.mPasses[i].mType !== "buffer" ) continue;
        if( this.mPasses[i].mProgram===null ) continue;
        let bufferID = assetID_to_bufferID( this.mPasses[i].mOutputs[0] );

        // check if any downstream pass needs mipmaps when reading from this buffer
        let needMipMaps = false;
        for (let j=0; j<num; j++ )
        {
            for (let k=0; k<this.mPasses[j].mInputs.length; k++ )
            {
                let inp = this.mPasses[j].mInputs[k];
                if( inp!==null && inp.mInfo.mType==="buffer" && inp.id === bufferID && inp.mInfo.mSampler.filter === "mipmap")
                {
                    needMipMaps = true;
                    break;
                }
            }
        }

        this.mPasses[i].Paint( vrData, wa, da, time, dtime, fps, mouseOriX, mouseOriY, mousePosX, mousePosY, xres, yres, isPaused, bufferID, needMipMaps, this.mBuffers, this.mCubeBuffers, this.mKeyboard, this );
    }


    // render cubemap buffers second
    for( let i=0; i<num; i++ )
    {
        if( this.mPasses[i].mType !== "cubemap" ) continue;
        if( this.mPasses[i].mProgram===null ) continue;
        let bufferID = 0;//assetID_to_bufferID( this.mPasses[i].mOutputs[0] );

        // check if any downstream pass needs mipmaps when reading from this buffer
        let needMipMaps = false;

        for (let j=0; j<num; j++ )
        {
            for (let k=0; k<this.mPasses[j].mInputs.length; k++ )
            {
                let inp = this.mPasses[j].mInputs[k];
                if( inp!==null && inp.mInfo.mType==="cubemap" )
                {
                    if( assetID_to_cubemapBuferID(inp.mInfo.mID)===0 && inp.mInfo.mSampler.filter === "mipmap" )
                    {
                        needMipMaps = true;
                        break;
                    }
                }
            }
        }

        this.mPasses[i].Paint( vrData, wa, da, time, dtime, fps, mouseOriX, mouseOriY, mousePosX, mousePosY, xres, yres, isPaused, bufferID, needMipMaps, this.mBuffers, this.mCubeBuffers, this.mKeyboard, this );
    }

    // render image last
    for( let i=0; i<num; i++ )
    {
        if( this.mPasses[i].mType !== "image" ) continue;
        if( this.mPasses[i].mProgram===null ) continue;
        this.mPasses[i].Paint( vrData, wa, da, time, dtime, fps, mouseOriX, mouseOriY, mousePosX, mousePosY, xres, yres, isPaused, null, false, this.mBuffers, this.mCubeBuffers, this.mKeyboard, this );
    }   

    // erase keypresses
    for (let k=0; k<256; k++ )
    {
       this.mKeyboard.mData[ k + 1*256 ] = 0;
    }
    this.mRenderer.UpdateTexture( this.mKeyboard.mTexture, 0, 0, 256, 3, this.mKeyboard.mData );

    if( this.mRenderingStereo ) this.mWebVR.Finish();

    this.mFrame++;
}

Effect.prototype.NewShader = function( passid, preventCache, onResolve )
{
    let commonSourceCodes = [];
    for (let i=0; i<this.mPasses.length; i++ )
    {
        if( this.mPasses[i].mType==="common")
        {
            commonSourceCodes.push(this.mPasses[i].mSource);
        }
    }

    this.mPasses[passid].NewShader(commonSourceCodes, preventCache, onResolve );
}

Effect.prototype.GetNumPasses = function()
{
    return this.mPasses.length;
}

Effect.prototype.GetNumOfType = function(passtype)
{
    let id = 0;
    for (let j=0; j<this.mPasses.length; j++ )
    {
        if( this.mPasses[j].mType===passtype )
        {
            id++;
        }
    }
    return id;
}

Effect.prototype.GetPassType = function( id )
{
    return this.mPasses[id].mType;
}
Effect.prototype.GetPassName = function( id )
{
    return this.mPasses[id].mName;
}
Effect.prototype.GetCode = function( id )
{
    return this.mPasses[id].mSource;
}
Effect.prototype.SetCode = function( id, source )
{
    this.mPasses[id].SetCode(source);
}
Effect.prototype.GetError = function (id)
{
    return this.mPasses[id].mError;
}
Effect.prototype.GetErrorStr = function (id)
{
    return this.mPasses[id].mErrorStr;
}
Effect.prototype.GetErrorGlobal = function()
{
    for (let i = 0; i < this.mPasses.length; i++)
    {
        if (this.mPasses[i].mError)
        {
            return true;
        }
    }
    return false;
}

Effect.prototype.Load = function (jobj )
{
    if (jobj.ver !== "0.1")
    {
        console.log("Wrong Format");
        return false;
    }

    let numPasses = jobj.renderpass.length;

    if( numPasses<1 || numPasses>this.mMaxPasses )
    {
        console.log("Corrupted Shader - " + numPasses);
        return false;
    }

    this.mPasses = [];
    for (let j = 0; j < numPasses; j++)
    {
        let rpass = jobj.renderpass[j];

        // skip sound passes if in thumbnail mode
        if( this.mForceMuted && rpass.type === "sound" ) continue;

        let wpass = new EffectPass(this.mRenderer, this.mIs20, this.mIsLowEnd, this.mShaderTextureLOD,
                                   this.mTextureCallbackFun, this.mTextureCallbackObj, this.mForceMuted, this.mForcePaused, this.mGainNode,
                                   this.mProgramDownscale, j, this);

        wpass.Create(rpass.type, this.mAudioContext);

        let numInputs = rpass.inputs.length;

        for (let i = 0; i < 4; i++)
        {
            wpass.NewTexture(this.mAudioContext, i, null, null, null);
        }
        for (let i = 0; i < numInputs; i++)
        {
            let lid  = rpass.inputs[i].channel;
            let styp = rpass.inputs[i].type;
            let sid  = rpass.inputs[i].id;
            let ssrc = rpass.inputs[i].filepath;
            let psrc = rpass.inputs[i].previewfilepath;
            let samp = rpass.inputs[i].sampler;

            wpass.NewTexture(this.mAudioContext, lid, { mType: styp, mID: sid, mSrc: ssrc, mSampler: samp, mPreviewSrc: psrc }, this.mBuffers, this.mCubeBuffers, this.mKeyboard);
        }

        for (let i = 0; i < 4; i++)
        {
            wpass.SetOutputs(i, null);
        }

        let numOutputs = rpass.outputs.length;
        for (let i = 0; i < numOutputs; i++)
        {
            let outputID = rpass.outputs[i].id;
            let outputCH = rpass.outputs[i].channel;
            wpass.SetOutputs(outputCH, outputID);
        }

        // create some hardcoded names. This should come from the DB
        let rpassName = "";
        if (rpass.type === "common" ) rpassName = "Common";
        if (rpass.type === "sound"  ) rpassName = "Sound";
        if (rpass.type === "image"  ) rpassName = "Image";
        if (rpass.type === "buffer") rpassName = "Buffer " + String.fromCharCode(65 + assetID_to_bufferID(wpass.mOutputs[0]));
        if (rpass.type === "cubemap") rpassName = "Cube A";// " + String.fromCharCode(65 + assetID_to_bufferID(this.mPasses[j].mOutputs[0]));
        wpass.SetName(rpassName);
        wpass.SetCode(rpass.code);

        this.mPasses.push(wpass);
    }
    return true;
}

Effect.prototype.CompileSome = function ( passes, preventCache, onResolve )
{
    let me = this;

    let to = getRealTime();
    let allPromisses = [];
    for (let j = 0; j < passes.length; j++)
    {
        allPromisses.push(new Promise(function (resolve, reject)
        {
            me.NewShader(passes[j], preventCache, function () { resolve(1); });
        }));
    }

    // aggregated callback when all passes have been compiled
    Promise.all(allPromisses).then(function (values)
    {
        let totalError = false;
        for (let j = 0; j < me.mPasses.length; j++)
        {
            if (me.mPasses[j].mError)
            {
                totalError = true;
                break;
            }
        }
        me.mCompilationTime = getRealTime() - to;
        onResolve(!totalError);
    }).catch(console.log);
}

Effect.prototype.Compile = function (preventCache, onResolve )
{
    let me = this;

    let to = getRealTime();
    let allPromisses = [];
    let numPasses = this.mPasses.length;
    for (let j = 0; j < numPasses; j++)
    {
        allPromisses.push(new Promise(function (resolve, reject)
        {
            me.NewShader(j, preventCache, function () { resolve(1); });
        }));
    }

    // aggregated callback when all passes have been compiled
    Promise.all(allPromisses).then(function (values)
    {
        let totalError = false;
        for (let j = 0; j < numPasses; j++)
        {
            if (me.mPasses[j].mError)
            {
                totalError = true;
                break;
            }
        }
        me.mCompilationTime = getRealTime() - to;
        onResolve(!totalError);
    }).catch(console.log);
}

Effect.prototype.GetCompilationTime = function( id )
{
    return this.mPasses[id].GetCompilationTime()/1000.0;
}
Effect.prototype.GetTotalCompilationTime = function()
{
    return this.mCompilationTime/1000.0;
}

Effect.prototype.DestroyPass = function( id )
{
   this.mPasses[id].Destroy( this.mAudioContext );
   this.mPasses.splice(id, 1);
}

Effect.prototype.AddPass = function( passType, passName, onResolve )
{
    let shaderStr = null;

    if( passType==="sound"   ) shaderStr = "vec2 mainSound( int samp, float time )\n{\n    // A 440 Hz wave that attenuates quickly overt time\n    return vec2( sin(6.2831*440.0*time)*exp(-3.0*time) );\n}";
    if( passType==="buffer"  ) shaderStr = "void mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    fragColor = vec4(0.0,0.0,1.0,1.0);\n}";
    if( passType==="common"  ) shaderStr = "vec4 someFunction( vec4 a, float b )\n{\n    return a+b;\n}";
    if( passType==="cubemap" ) shaderStr = "void mainCubemap( out vec4 fragColor, in vec2 fragCoord, in vec3 rayOri, in vec3 rayDir )\n{\n    // Ray direction as color\n    vec3 col = 0.5 + 0.5*rayDir;\n\n    // Output to cubemap\n    fragColor = vec4(col,1.0);\n}";

    let id = this.GetNumPasses();
    this.mPasses[id] = new EffectPass( this.mRenderer, this.mIs20, this.mIsLowEnd, this.mShaderTextureLOD,
                                       this.mTextureCallbackFun, this.mTextureCallbackObj, this.mForceMuted, this.mForcePaused, this.mGainNode, 
                                       this.mProgramDownscale, id, this );

    this.mPasses[id].Create( passType, this.mAudioContext );
    this.mPasses[id].SetName( passName );
    this.mPasses[id].SetCode( shaderStr );
    this.NewShader(id, false, function ()
    {
        onResolve();
    });

    return { mId : id, mShader : shaderStr };
}

// this should be removed once we have MultiPass 2.0 and passes render to arbitrary buffers
Effect.prototype.IsBufferPassUsed = function( bufferID )
{
    for (let j=0; j<this.mPasses.length; j++ )
    {
        if( this.mPasses[j].mType !== "buffer" ) continue;
        if( this.mPasses[j].mOutputs[0] === bufferID_to_assetID(bufferID) ) return true;
    }
    return false;
}

Effect.prototype.Save = function()
{
    var result = {};

    result.ver = "0.1";

    result.renderpass = [];

    let numPasses = this.mPasses.length;
    for (let j=0; j<numPasses; j++ )
    {
        result.renderpass[j] = {};

        result.renderpass[j].outputs = new Array();
        for (let i = 0; i<4; i++ )
        {
            let outputID = this.mPasses[j].mOutputs[i];
            if( outputID===null ) continue;
            result.renderpass[j].outputs.push( { channel: i, id: outputID } );
        }
        result.renderpass[j].inputs = new Array();
        for (let i = 0; i<4; i++ )
        {
            if( this.mPasses[j].mInputs[i]===null ) continue;
            result.renderpass[j].inputs.push( {channel: i,
                                               type    : this.mPasses[j].mInputs[i].mInfo.mType,
                                               id      : this.mPasses[j].mInputs[i].mInfo.mID,
                                               filepath: this.mPasses[j].mInputs[i].mInfo.mSrc,
                                               sampler : this.mPasses[j].mInputs[i].mInfo.mSampler });
        }

        result.renderpass[j].code = this.mPasses[j].mSource;
        result.renderpass[j].name = this.mPasses[j].mName
        result.renderpass[j].description = "";
        result.renderpass[j].type = this.mPasses[j].mType;
    }

    result.flags = this.calcFlags();

    return result;
}

Effect.prototype.calcFlags = function ()
{
    let flagVR = false;
    let flagWebcam = false;
    let flagSoundInput = false;
    let flagSoundOutput = false;
    let flagKeyboard = false;
    let flagMultipass = false;
    let flagMusicStream = false;

    let numPasses = this.mPasses.length;
    for (let j = 0; j < numPasses; j++)
    {
        let pass = this.mPasses[j];

        if (pass.mType === "sound") flagSoundOutput = true;
        if (pass.mType === "buffer") flagMultipass = true;

        for (let i = 0; i < 4; i++)
        {
            if (pass.mInputs[i] === null) continue;

            if (pass.mInputs[i].mInfo.mType === "webcam") flagWebcam = true;
            else if (pass.mInputs[i].mInfo.mType === "keyboard") flagKeyboard = true;
            else if (pass.mInputs[i].mInfo.mType === "mic") flagSoundInput = true;
            else if (pass.mInputs[i].mInfo.mType === "musicstream") flagMusicStream = true;
        }

        let n1 = pass.mSource.indexOf("mainVR(");
        let n2 = pass.mSource.indexOf("mainVR (");
        if (n1 > 0 || n2 > 0) flagVR = true;
    }

    return {
        mFlagVR: flagVR,
        mFlagWebcam: flagWebcam,
        mFlagSoundInput: flagSoundInput,
        mFlagSoundOutput: flagSoundOutput,
        mFlagKeyboard: flagKeyboard,
        mFlagMultipass: flagMultipass,
        mFlagMusicStream: flagMusicStream
    };
}</script>
    <script>"use strict"

const kMaxCompileTime = 10.0;

function iReportCrash(shaderID)
{
    let req = new XMLHttpRequest();
    req.onload = function ()
    {
        let jsn = req.response;
        if (jsn === null) return;
        if (jsn.result === 0)
        {
            // yep
        }
    };
    req.open("POST", "/shadertoy", true);
    req.responseType = "json";
    req.setRequestHeader('Content-Type', 'application/x-www-form-urlencoded');
    req.send( "s=" + shaderID + "&r=2" );
}
</script>
    <script>"use strict"

var gActive = -1;
var mShaders = [];
var gNumCanvases = 0;

function myrefresh( id, slot, img, forceFrame, gui, guiID, renderID, time )
{
    if( mShaders[id].mReady===false ) return;
    if( forceFrame )
    {
        if (mShaders[id].mScreenshot === false)
        {
            mShaders[id].gEffect.Paint(mShaders[id].mTime / 1000.0, 1.0 / 60.0, 60.0, 0, 0, 0, 0, false);
        }
    }
}

function startRendering()
{
    if( gActive<0 ) return;
    if( mShaders[gActive].mReady===false ) return;
    if( mShaders[gActive].mScreenshot===true ) return;

    let time = getRealTime();

    mShaders[gActive].mFPS.Count( time );
    mShaders[gActive].mTime = mShaders[gActive].mTime0 + (time - mShaders[gActive].mTo);
    let dtime = 1000.0/60.0;
    mShaders[gActive].gEffect.Paint( mShaders[gActive].mTime/1000.0, dtime/1000.0, mShaders[gActive].mFPS.GetFPS(), 0,0,0,0, false);

    requestAnimFrame( startRendering );
}

function iLoadAndCompile(jsn, i )
{
    var shaderObj = jsn[i];
    if (shaderObj === null) return;

    var resizeCB = function (xres, yres) { myrefresh(i, 0, null, true, false, 0, -1.0) };
    var crashCB = function () { alert('crash');/*iReportCrash(gShaderIDs[i])*/ };
    mShaders[i].gEffect = new Effect(null, null, mShaders[i].mPreview.mCanvas, myrefresh, i, true, true, resizeCB, crashCB);

    if (!mShaders[i].gEffect.Load(shaderObj)) return;

    mShaders[i].gEffect.Compile(false, function (worked)
    {
        if (worked === true)
        {
            previewShowRender(mShaders[i].mPreview);

            mShaders[i].mScreenshot = false;
            mShaders[i].mReady = true;
            mShaders[i].mTime = 10.0 * 1000.0;
            mShaders[i].mTime0 = 0.0;
            mShaders[i].mTo = 0.0;
            mShaders[i].mFPS = piCreateFPSCounter();
            mShaders[i].mPreview.mCanvas.addEventListener("mouseout", function (ev) { gActive = -1; }, true);
            mShaders[i].mPreview.mBase.addEventListener("mouseover", function (ev) { if (mShaders[i].mPreview.mUI !== null) mShaders[i].mPreview.mUI.classList.add('isVisible'); }, true);
            mShaders[i].mPreview.mBase.addEventListener("mouseout", function (ev) { if (mShaders[i].mPreview.mUI !== null) mShaders[i].mPreview.mUI.classList.remove('isVisible'); }, true);
            mShaders[i].mPreview.mCanvas.addEventListener("mouseover", function (ev)
            {
                let ele = piGetSourceElement(ev);
                if (ele.mId === undefined) return;

                gActive = ele.mId;
                if (!mShaders[gActive].mReady) return;
                let time = getRealTime();
                mShaders[gActive].mTo = time;
                mShaders[gActive].mTime0 = mShaders[gActive].mTime;
                mShaders[gActive].mFPS.Reset(time);

                startRendering();
            }, true);


            /*
            let compilationTime = mShaders[i].gEffect.GetTotalCompilationTime();
            if (compilationTime > kMaxCompileTime)
            {
                iReportCrash(mShaders[i].mShaderID);
            }*/

            myrefresh(i, null, null, true, false, 0, -1.0);
        }
        else
        {
            mShaders[i].mReady = false;
            previewShowError(mShaders[i].mPreview);
        }
    });
};


function iProcessShader( jsn, i )
{
    var shaderObj = jsn[i];
    if( shaderObj===null ) return;

    if ((shaderObj.info.usePreview === 0 && !gUseScreenshots) || (mShaders[i].mPreviewReady !== 1))
    {
        iLoadAndCompile(jsn, i);
    }
    else
    {
        mShaders[i].mScreenshot = true;
        if( shaderObj.info.usePreview === 1 )
            previewShowScreenshot(mShaders[i].mPreview, 1); // comp
        else if (gUseScreenshots)
            previewShowScreenshot(mShaders[i].mPreview, 2); // sett
    }

    if( i<(jsn.length-1) ) setTimeout( function(){iProcessShader(jsn,i+1);}, 10 );
}

function iInitUI(numCanvases, uiCallback, windowTitle)
{
    gNumCanvases = numCanvases;
    document.getElementById("mySearch").focus();

    //-----------------------------------------------------------------
    // window
    //-----------------------------------------------------------------
    if (windowTitle !== null) {
        document.title = windowTitle;
    }

    //-----------------------------------------------------------------
    // ui
    //-----------------------------------------------------------------
    var num = Math.min(gShaders.length, gNumCanvases);

    //var base = document.getElementsByClassName( "searchResult" );

    for (let i = 0; i < gNumCanvases; i++)
    {
        let pv = createPreview(i);

        if (i >= num) {
            previewHide(pv);
            continue;
        }

        let shaderID = gShaders[i].info.id;
        
        if (pv.mUI !== null && uiCallback !== null) {
            pv.mUI.addEventListener('click', function (ev) {
                uiCallback(shaderID);
                ev.preventDefault();
            }, false);
        }
        
        previewShowLoading(pv);
        
        mShaders[i] = {};
        mShaders[i].mShaderID = shaderID;
        mShaders[i].mPreview = pv;
        mShaders[i].mScreenshot = false;
        mShaders[i].mPreview.mLink.href = "/view/" + shaderID;
        mShaders[i].mPreviewReady = 0;
        mShaders[i].mReady = false;
        mShaders[i].gEffect = null;

        previewLoadScreenshot(mShaders[i].mPreview,
            function () { mShaders[i].mPreviewReady = 1; if (mShaders[i].mReady === false) previewShowScreenshot(mShaders[i].mPreview, 0); },
            function () { mShaders[i].mPreviewReady = 2; },
            shaderID);
    }

    if (num <= 0) {
        return;
    }
}

function iInitShaders(jsn)
{
    for (let i = 0; i < jsn.length; i++)
    {
        let shaderObj = jsn[i];
        if (shaderObj === null) continue;
        let inf = shaderObj.info;
        mShaders[i].mPreview.mTextA.textContent = inf.name;
        mShaders[i].mPreview.mTextB.innerHTML = "<a class='user' href='/user/" + htmlEntities(inf.username) + "'>" + htmlEntities(inf.username) + "</a>";
        mShaders[i].mPreview.mTextC.innerHTML = "<img src='/img/themes/" + gThemeName + "/views.png' class='viewsIcon'></img>" + inf.viewed + "    &nbsp;&nbsp;  <img src='/img/themes/" + gThemeName + "/likes.png' class='likesIcon'></img>" + inf.likes;
    }

    setTimeout(function () { iProcessShader(jsn, 0); }, 10);
}

function resultsInitStatic(numCanvases, uiCallback, windowTitle)
{
    iInitUI(numCanvases, uiCallback, windowTitle);

    iInitShaders(gShaders);
}

function resultsInit(numCanvases, uiCallback, windowTitle)
{	
    iInitUI(numCanvases, uiCallback, windowTitle);

    var num = Math.min(gShaderIDs.length, gNumCanvases);

    var mHttpReq = new XMLHttpRequest();

    mHttpReq.abort();

    var str = "{ \"shaders\" : [";
    for( let i=0; i<num; i++ )
    {
         str += "\"" + gShaderIDs[i] + "\"";
         if( i!==(num-1) ) str += ", ";
    }
    str += "] }";

    str = "s=" + encodeURIComponent( str ) + "&nt=0&nl=0&np=0";

    mHttpReq.open( "POST", "/shadertoy", true );
    mHttpReq.responseType = "json";
    mHttpReq.setRequestHeader('Content-Type', 'application/x-www-form-urlencoded');
    mHttpReq.onload = function ()
    {
        let jsn = this.response;
        if( jsn===null )
        {
            console.log( "Could not load shaders" );
            return;
        }

        iInitShaders(jsn);
    }
    mHttpReq.send( str );
}</script>
    <style>
    .shaderPreview
    {
    display: block;
    background-color: #000000;
    background-image: url("/img/loading.gif");
    background-repeat: no-repeat;
    background-position: center;
    padding: 0px;
    margin: 0px;
    border: 0px solid #000000;
    border-radius: 8px;
    width:100%;
    height:100%;
    position: absolute;
    overflow:hidden;
    }

    .previewInfo
    {
    width: 100%;
    left: 0px;
    top: 2px;
    position: relative;
    visibility: hidden;
    }

    .previewCanvas
    {
    left: 0px;
    top: 0px;
    padding: 0px;
    margin: 0px;
    position: absolute;
    cursor: pointer;
    width:100%;
    height:100%;
    border-radius: 8px;
    border: 0px solid #000000;
    backgroundColor: transparent;
visibility: hidden;
opacity:0;
transition: opacity 1.0s ease;
    }

    .previewText
    {
        text-overflow: ellipsis;
    white-space: nowrap;
    padding-right: 1px;
    }

    .previewTextUser
    {
    text-overflow: ellipsis;
    white-space: nowrap;
    padding-left: 3px;
    }

    .previewStats
    {
    padding-right: 1px;
    right: 0px;
    top: 0px;
    position: absolute;
    }

    .previewErrorContainer
    {
    left:0px;
    top:0px;
    width:100%;
    height:100%;
    padding:0px;
    margin:0px;
    background-color:#000000;
    border-radius:8px;
    cursor:pointer;
    visibility:hidden;
    }

    .previewErrorMessage
    {
    top:50%;
    position:absolute;
    width:100%;
    text-align:center;
    padding:0;
    margin:auto;
    color:#ff0000;
    font-size:2em;
    font-style:italic;
    }

    .previewNoGLContainter
    {
    left:0px;
    top:0px;
    width:100%;
    height:100%;
    padding:0px;
    margin:0px;
    position:absolute;
    background-color:#000000;
    border-radius:8px;
    cursor:pointer;
    pointer-events:none;
    visibility:hidden;
    font-size:2em;
    }

    .previewNoGLMessage
    {
    width:86%;
    height:90%;
    padding-left:7%;
    padding-right:7%;
    padding-top:10%;
    padding-bottom:0px;
    color:#ff0000;
    position:absolute;
    visibility:hidden;
    }

    .previewThumbnailContainer
    {
    width:100%;
    height:100%;
    left:0px;
    top:0px;
    padding:0px;
    margin:0px;
    position:absolute;
    cursor:pointer;
    visibility:hidden;
    border-radius:8px;
    border:0px solid #000000;
    }

    .previewThumbnailImage
    {
    width:100%;
    height:100%;
    left:0px;
    top:0px;
    padding:0px;
    margin:0px;
    position:absolute;
    cursor:pointer;
    border-radius:8px;
    border:0px solid #000000;
opacity: 0.0;
transition: opacity 1.0s ease;
    }

    .previewThumbnailIcon
    {
    width:64px;
    height:32px;
    left:0px;
    top:0px;
    padding:0px;
    padding-top:12px;
    margin:0px;
    position:absolute;
    color:#ffffff;
    background-color:#ff8020;
    font-weight:bold;
    border-radius:0px 0px 8px 0px;
    text-align:center;
    //visibility:hidden;
    }


    .previewUIContainter
    {
    display: block;
    right:0px;
    top:0px;
    padding:0px;
    margin:0px;
    position:absolute;
    //cursor:pointer;
    //pointer-events:none;
    //visibility:hidden;
    }
</style>

<script>
    function previewHide(me)
    {
    me.mBase.style.visibility = "hidden";
    me.mCanvas.style.visibility = "hidden";
    me.mCanvas2D.style.visibility = "hidden";
    me.mNoWebGL.style.visibility = "hidden";
    me.mError.style.visibility = "hidden";
    me.mCont.style.visibility = "hidden";
    }

    function previewShowRender(me)
    {
    me.mBase.style.visibility = "visible";
    me.mCanvas.style.visibility = "visible";
me.mCanvas.style.opacity = 1.0;
    me.mCanvas.style.borderRadius ="8px;";
//  me.mCanvas2D.style.visibility = "hidden";
    me.mNoWebGL.style.visibility = "hidden";
    me.mError.style.visibility = "hidden";
    me.mCont.style.visibility = "visible";
    }

    function previewShowScreenshot(me, message)
    {
    me.mBase.style.visibility = "visible";
    me.mCanvas.style.visibility = "hidden";
    me.mCanvas2D.style.visibility = "visible";
me.mThumbnailImg.style.opacity = 1.0;
    me.mNoWebGL.style.visibility = "hidden";
    me.mError.style.visibility = "hidden";
    me.mCont.style.visibility = "visible";
    me.mThumbnailWar1.style.visibility = (message===1)?"visible":"hidden";
    me.mThumbnailWar2.style.visibility = (message===2)?"visible":"hidden";
    }

    function previewShowLoading(me)
    {
    me.mBase.style.visibility = "visible";
    me.mCanvas.style.visibility = "hidden";
    me.mCanvas2D.style.visibility = "hidden";
    me.mNoWebGL.style.visibility = "hidden";
    me.mError.style.visibility = "hidden";
    me.mCont.style.visibility = "hidden";

    me.mLink.style.visibility = "visible";
    me.mBase.style.backgroundColor = "#ff0000;"
    me.mCont.style.visibility = "visible";
    }

    function previewShowNoWebGL(me, shaderID)
    {
    me.mBase.style.visibility = "visible";
    me.mCanvas.style.visibility = "hidden";
    me.mCanvas2D.style.visibility = "hidden";
    me.mNoWebGL.style.visibility = "visible";
    me.mError.style.visibility = "visible";
    me.mThumbnailImgNoWebGL.onerror = function(ev) 
                                      { 
                                            me.mThumbnailImgNoWebGL.style.visibility="hidden"; 
                                            me.mMessageNoWebGL.style.visibility="visible"; 
                                      };
    me.mThumbnailImgNoWebGL.src = "/media/shaders/" + shaderID + ".jpg";
    }

    function previewShowError(me)
    {
    me.mBase.style.visibility = "visible";
    me.mCanvas.style.visibility = "hidden";
    me.mCanvas2D.style.visibility = "hidden";
    me.mNoWebGL.style.visibility = "hidden";
    me.mError.style.visibility = "visible";
    me.mCont.style.visibility = "visible";
    }

    function previewLoadScreenshot( me, cbSuccess, cbError, shaderID )
    {
    var url = "/media/shaders/" + shaderID + ".jpg";
    me.mThumbnailImg.onload = cbSuccess;
    me.mThumbnailImg.onerror = function(ev) { cbError(); };
    me.mThumbnailImg.src = url;
    }
        
    function createPreview(id)
    {
        var bar = document.getElementById( "Preview_"+id+"_Canvas" );
        bar.width = bar.offsetWidth;
        bar.height = bar.offsetHeight;
        bar.mId = id;

        return { mBase: document.getElementById( "Preview_"+id+"_Container" ),
        mLink: document.getElementById( "Preview_"+id+"_Link" ),
        mCanvas: bar,
        mCont: document.getElementById( "Preview_"+id+"_Info" ),
        mTextA: document.getElementById( "Preview_"+id+"_Text" ),
        mTextB: document.getElementById( "Preview_"+id+"_TextUser" ),
        mTextC: document.getElementById( "Preview_"+id+"_Stats" ),
        mNoWebGL: document.getElementById( "Preview_"+id+"_NoWebGL" ),
        mError: document.getElementById( "Preview_"+id+"_Error" ),
        mCanvas2D: document.getElementById( "Preview_"+id+"_Thumnail" ),
        mThumbnailImg: document.getElementById( "Preview_"+id+"_ThumnailImage" ),
        mThumbnailWar1: document.getElementById( "Preview_"+id+"_ThumnailWarning1" ),
        mThumbnailWar2: document.getElementById( "Preview_"+id+"_ThumnailWarning2" ),
        mThumbnailImgNoWebGL: document.getElementById( "Preview_"+id+"_ThumnailImageNoWebGL" ),
        mMessageNoWebGL: document.getElementById( "Preview_"+id+"_MessageNoWebGL"),
        mUI: document.getElementById( "Preview_"+id+"_UI" )
        };
    }
</script>

    <style>

    #content
    {
        user-select: text;
        -moz-user-select: -moz-text;
        -webkit-user-select: text;
        padding:0px;
        margin:0px;
        position:relative;
    }

    #divUser
    {
        padding:0px;
        padding-top:24px;
        padding-bottom:16px;
        width:100%;
    }

    div#controls
    {
        width:100%;
        padding-top:16px;
        padding-bottom:16px;
        display:flex;
        justify-content:space-between; 
        flex-wrap:wrap;
    }

    div#controls > div
    {
        display:inline-flex;
    }

    .controlOptions
    {
        display:inline-block;
    }

    div#shaderGrid
    {
        width:100%;
        padding:0px;
        margin:0px;
        display: grid;
        grid-template-columns: repeat(4, 1fr);
        grid-template-rows: repeat(2, 1fr);
        grid-column-gap: 64px;
        grid-row-gap: 16px;
    }

    .searchResult
    {
        margin: 0px;
        padding: 0px;
        width: 100%;
    }
    .searchResultContainer
    {
        width: 100%;
        padding-bottom:56.25%;
        height: 0;
        position: relative;
    }

    div#navigation
    {
        text-align: center;
        width: 100%;
    }


    #userPicture
    {
        background-color:#808080;
        border: 1px solid #000000;
        padding:0px;
        left:0px;
        top:0px;
        width:128px;
        height:128px;
    }

    a.pageButtons, .pageButtonsCurrent
    {
        
        //background-color: #303030;
        border-style: solid;
        border-width: 1px;
        border-color: #808080;
        text-align: center;
        vertical-align: middle;
        margin-left: 12px;
        display: inline-block;
        border-radius: 4px;
		font-weight:bold;
        cursor: pointer;
        padding-bottom:5px;
        padding-top:4px;
        padding-left: 8px;
        padding-right: 8px;
        margin:8px;
    }

    a.pageButtons
    {
        text-decoration: none;
        -moz-transition:    background-color 0.15s linear, color 0.15s linear;
        -webkit-transition: background-color 0.15s linear, color 0.15s linear;
        transition:         background-color 0.15s linear, color 0.15s linear;
    }

    a.pageButtons:hover
    {
      background-color:#808080;
      color : #ff8020;
    }

    .pageButtonsCurrent
    {
        background-color: #808080;
        color:#000000;
    }

    /* ----------------------- media resolutions ------------------------ */

    @media screen and (max-width:799px) 
    {
        div#shaderGrid  { grid-template-columns: 1fr; grid-template-rows: repeat(8, 1fr); grid-column-gap: 0px; grid-row-gap: 16px; padding-bottom:16px; }

        div#controls
        {
            width:100%;
            display:flex;
            justify-content:flex-start; 
            flex-wrap:wrap;
        }

        div#controls > div
        {
            display:inline-flex;
            width:100%;
            margin-left: 0px;
            margin-right: 0px;
            padding-bottom:16px;
        }
    }
    </style>

    <script>

    var gShaders=[{"ver":"0.1","info":{"id":"MscXzn","date":"1457308502","viewed":25602,"name":"IcePrimitives","username":"Bers","description":"Practice at playing with ray-marched refraction through arbitrary geometry.","likes":219,"published":3,"flags":32,"usePreview":0,"tags":[]},"renderpass":[{"inputs":[{"id":"4dX3Rn","filepath":"\/media\/a\/bd6464771e47eed832c5eb2cd85cdc0bfc697786b903bfd30f890f9d4fc36657.jpg","previewfilepath":"\/media\/ap\/bd6464771e47eed832c5eb2cd85cdc0bfc697786b903bfd30f890f9d4fc36657.jpg","type":"texture","channel":1,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sf3Rn","filepath":"\/media\/a\/0a40562379b63dfb89227e6d172f39fdce9022cba76623f1054a2c83d6c0ba5d.png","previewfilepath":"\/media\/ap\/0a40562379b63dfb89227e6d172f39fdce9022cba76623f1054a2c83d6c0ba5d.png","type":"texture","channel":0,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"\/media\/previz\/buffer00.png","previewfilepath":"\/media\/previz\/buffer00.png","type":"buffer","channel":2,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"\/\/ Author : S\u00c3\u00a9bastien B\u00c3\u00a9rub\u00c3\u00a9\n\/\/ Created : Dec 2014\n\/\/ Modified : Feb 2016\n\/\/\n\/\/ Ice raymarching experiment, built on top of primitives shader from Inigo Quilez : \n\/\/ https:\/\/www.shadertoy.com\/view\/Xds3zN\n\/\/\n\/\/ You can play with the sliders : 1-Normal map scale\n\/\/                                 2-Isosurface thickness\n\/\/                                 3-Color \/ refraction normal \/ other debug stuff\n\/\/                                 4-Refraction index\n\/\/\n\/\/ Notes:\n\/\/ \n\/\/ - distance function map() works as usual, as all boolean operations and signed distance functions do.\n\/\/ - sphereTracing() function was modified for volume raymarching (sign added, simple as that).\n\/\/ - triplanar noise projection used for surface normal noise.\n\/\/ - smooth subtraction was implemented to smooth out boolean shape.\n\/\/ - \"in scattering\" is simply approximated with positive inner ice colors (the default color)\n\/\/ - extinction coefficient is also roughly approximated both by negative inner ice color\n\/\/   and with traversal distance (WIP, I'll return to improve this once I better\n\/\/   understand scattering equations).\n\/\/ - RAYMARCH_DFSS is slightly different from inigo's softshadow.\n\/\/   A \"light cone width\" value [0-1] is passed to the function in order to control softness.\n\/\/   I don't know how well it would perform in other scenarios, but it seems to do the trick\n\/\/   with limited samples in this case. I guess the principle is the same.\n\/\/\n\/\/ License : Creative Commons Non-commercial (NC) license\n\/\/\n\n\/\/----------------------\n\/\/ Constants \nconst float GEO_MAX_DIST  = 1000.0;\nconst int MATERIALID_NONE      = 0;\nconst int MATERIALID_FLOOR     = 1;\nconst int MATERIALID_ICE_OUTER = 2;\nconst int MATERIALID_ICE_INNER = 3;\nconst int MATERIALID_SKY       = 4;\n\n\/\/----------------------\n\/\/ Slider bound globals.\nfloat ROUGHNESS      = 0.25; \/\/sliderVal[0]\nfloat ISOVALUE       = 0.03; \/\/sliderVal[1]\nfloat ICE_COLOR      = 0.00; \/\/sliderVal[2]\nfloat REFRACTION_IDX = 1.31; \/\/sliderVal[3]\n\nstruct TraceData\n{\n    float rayLen;\n    vec3  rayDir;\n    vec3  normal;\n    int   matID;\n    vec3  matUVW;\n    float alpha;\n};\n\n#define saturate(x) clamp(x,0.0,1.0)\nvec3 normalMap(vec3 p, vec3 n);\nTraceData TRACE_geometry(vec3 o, vec3 d);\nTraceData TRACE_reflexion(vec3 o, vec3 d);\nTraceData TRACE_translucentDensity(vec3 o, vec3 d);\nTraceData TRACE_cheap(vec3 o, vec3 d);\n\nfloat RAYMARCH_DFSS(vec3 ro, vec3 rd, float coneWidth);\n\nvec4 MAT_apply(vec3 pos, TraceData traceData)\n{\n    vec3 L = normalize(vec3(-0.6,0.7,-0.5));\n    vec4 col = vec4(traceData.alpha);\n    \n    if(traceData.matID==MATERIALID_NONE)\n    {\n        return vec4(0,0,0,1);\n    }\n    else if(traceData.matID==MATERIALID_ICE_INNER)\n    {\n        \/\/NOTE : Coloring is not physically accurate.\n        \/\/       For this to be more accurate, \n        \/\/       it should probably be computed like fog.\n        \/\/       (in scattering, out scattering \/ extinction coefficient?).\n        vec3 cRed   = vec3( 0.70,-0.5,-0.60);\n        vec3 cGreen = vec3(-0.50, 0.0,-0.5);\n        vec3 cBlue  = vec3(-0.50,-0.5, 0.30);\n        vec3 cGrey = vec3(-0.3); \/\/Glass (~extinction coefficient, more or less)\n        vec3 cWhite = vec3(1.0); \/\/Ice (pseudo \"in scattering\")\n        \n        col.rgb = mix(cWhite ,cGrey, smoothstep(0.00,0.20,ICE_COLOR));\n\t\tcol.rgb = mix(col.rgb,cBlue, smoothstep(0.20,0.40,ICE_COLOR));\n        col.rgb = mix(col.rgb,cGreen,smoothstep(0.40,0.60,ICE_COLOR));\n\t\tcol.rgb = mix(col.rgb,cRed , smoothstep(0.60,0.80,ICE_COLOR));    \n    }\n    else if(traceData.matID==MATERIALID_SKY)\n    {\n        col.rgb = vec3(0.6,0.7,0.85);\n    }\n    else if(traceData.matID==MATERIALID_FLOOR)\n    {\n        vec3 cDiff = pow(texture(iChannel1,traceData.matUVW.xz).rgb,vec3(1.2));\n        float dfss = RAYMARCH_DFSS(pos, L, 0.07);\n    \tcol.rgb = cDiff*(0.45+1.2*(dfss));\n    }\n    return col;\n}\n\nstruct IceTracingData\n{\n    TraceData reflectTraceData;\n\tTraceData translucentTraceData;\n    TraceData exitTraceData;\n};\n    \nIceTracingData renderIce(TraceData iceSurface, vec3 ptIce, vec3 dir)\n{\n    IceTracingData iceData;\n    \n    vec3 normalDelta = normalMap(ptIce*ROUGHNESS,iceSurface.normal)*ROUGHNESS\/10.;\n    \n    vec3 iceSurfaceNormal = normalize(iceSurface.normal+normalDelta); \n    vec3 refract_dir = refract(dir,iceSurfaceNormal,1.0\/REFRACTION_IDX); \/\/Ice refraction index = 1.31\n    vec3 reflect_dir = reflect(dir,iceSurfaceNormal);\n\n    \/\/Trace reflection\n    iceData.reflectTraceData = TRACE_reflexion(ptIce,reflect_dir);\n    \n    \/\/Balance between refraction and reflection (not entirely physically accurate, Fresnel could be used here).\n    float fReflectAlpha = 0.5*(1.0-abs(dot(normalize(dir),iceSurfaceNormal)));\n    iceData.reflectTraceData.alpha = fReflectAlpha;\n    vec3 ptReflect = ptIce+iceData.reflectTraceData.rayLen*reflect_dir;\n\n    \/\/Trace refraction\n    iceData.translucentTraceData = TRACE_translucentDensity(ptIce,refract_dir);\n    \n    vec3 ptRefract = ptIce+iceData.translucentTraceData.rayLen*refract_dir;\n    vec3 exitRefract_dir = refract(refract_dir,-iceData.translucentTraceData.normal,REFRACTION_IDX);\n\n    \/\/This value fades around total internal refraction angle threshold.\n    if(length(exitRefract_dir)<=0.95)\n    {\n        \/\/Total internal reflection (either refraction or reflexion, to keep things cheap).\n        exitRefract_dir = reflect(refract_dir,-iceData.translucentTraceData.normal);\n    }\n    \n    \/\/Trace environment upon exit.\n    iceData.exitTraceData = TRACE_cheap(ptRefract,exitRefract_dir);\n    iceData.exitTraceData.matID = MATERIALID_FLOOR;\n    \n    return iceData;\n}\n\nvec3 main_render( vec3 o, vec3 dir, vec2 uv)\n{ \n    vec3 pt = o;\n    \n    vec3 ptGeometry = vec3(0);\n    vec3 ptReflect = vec3(0);\n    \n    TraceData geometryTraceData = TRACE_geometry(pt, dir);\n    ptGeometry = o+geometryTraceData.rayLen*dir;\n    \n    IceTracingData iceData;\n    iceData.translucentTraceData.rayLen = 0.0;\n    if(geometryTraceData.matID == MATERIALID_ICE_OUTER && geometryTraceData.rayLen < GEO_MAX_DIST)\n    {\n        vec3 ptIce = ptGeometry;\n        iceData = renderIce(geometryTraceData, ptIce, dir);\n        geometryTraceData = iceData.exitTraceData;\n        \n        vec3 ptRefract = ptIce+iceData.translucentTraceData.rayLen*iceData.translucentTraceData.rayDir;\n        ptReflect = ptIce+iceData.reflectTraceData.rayLen*iceData.reflectTraceData.rayDir;\n        ptGeometry = ptRefract+geometryTraceData.rayLen*dir;\n        \n        \/\/<Debug section, not mandatory>\n        \/\/[0.80-1.00] = Debug color range.\n        if(ICE_COLOR>0.95) return iceData.exitTraceData.rayDir;\n        if(ICE_COLOR>0.90) return max(iceData.exitTraceData.matUVW,vec3(0));\n        if(ICE_COLOR>0.85) return iceData.translucentTraceData.rayLen*vec3(1);\n        if(ICE_COLOR>0.80) return iceData.reflectTraceData.alpha*vec3(1);\n        \/\/<\/Debug section, not mandatory>\n    }\n    \n    \/\/cTerrain is either direct ray or refract ray.\n    vec4 cTerrain  = MAT_apply(ptGeometry,geometryTraceData);\n    vec4 cIceInner = MAT_apply(ptGeometry,iceData.translucentTraceData);\n    vec4 cReflect  = MAT_apply(ptReflect,iceData.reflectTraceData);\n    \n    if(iceData.translucentTraceData.rayLen > 0.0 )\n    {\n        float fTrav = iceData.translucentTraceData.rayLen;\n        vec3 cRefract = cTerrain.rgb;\n        cRefract.rgb = mix(cRefract,cIceInner.rgb,0.3*fTrav+0.2*sqrt(fTrav*3.0));\n        cRefract.rgb += fTrav*0.3;\n        vec3 cIce = mix(cRefract,cReflect.rgb,iceData.reflectTraceData.alpha);\n        return cIce;\n\t}\n    return cTerrain.rgb;\n}\n\n\n\n\nstruct DF_out\n{\n    float d;  \/\/Distance to geometry\n    int matID;\/\/Geometry material ID\n};\n    \n\nfloat sdPlane( vec3 p )\n{\n\treturn p.y;\n}\n\nfloat sdSphere( vec3 p, float s )\n{\n    return length(p)-s;\n}\n\nfloat sdBox( vec3 p, vec3 b )\n{\n  vec3 d = abs(p) - b;\n  return min(max(d.x,max(d.y,d.z)),0.0) + length(max(d,0.0));\n}\n\nfloat udRoundBox( vec3 p, vec3 b, float r )\n{\n  return length(max(abs(p)-b,0.0))-r;\n}\n\nfloat sdTorus( vec3 p, vec2 t )\n{\n  return length( vec2(length(p.xz)-t.x,p.y) )-t.y;\n}\n\nfloat sdTriPrism( vec3 p, vec2 h )\n{\n    vec3 q = abs(p);\n#if 0\n    return max(q.z-h.y,max(q.x*0.866025+p.y*0.5,-p.y)-h.x*0.5);\n#else\n    float d1 = q.z-h.y;\n    float d2 = max(q.x*0.866025+p.y*0.5,-p.y)-h.x*0.5;\n    return length(max(vec2(d1,d2),0.0)) + min(max(d1,d2), 0.);\n#endif\n}\n\nfloat sdCylinder( vec3 p, vec2 h )\n{\n  vec2 d = abs(vec2(length(p.xz),p.y)) - h;\n  return min(max(d.x,d.y),0.0) + length(max(d,0.0));\n}\n\nfloat length2( vec2 p )\n{\n\treturn sqrt( p.x*p.x + p.y*p.y );\n}\n\nfloat length8( vec2 p )\n{\n\tp = p*p; p = p*p; p = p*p;\n\treturn pow( p.x + p.y, 1.0\/8.0 );\n}\n\nfloat sdTorus88( vec3 p, vec2 t )\n{\n  vec2 q = vec2(length8(p.xz)-t.x,p.y);\n  return length8(q)-t.y;\n}\n\n\n\/\/----------------------------------------------------------------------\n\nfloat opSmoothSubtract( float d1, float d2 )\n{\n    return length(vec2(max(d1,0.),min(d2,0.0)));\n}\n\nfloat opU( float d1, float d2 )\n{\n\treturn (d1<d2) ? d1 : d2;\n}\n\nvec3 opTwist( vec3 p )\n{\n    float  c = cos(10.0*p.y+10.0);\n    float  s = sin(10.0*p.y+10.0);\n    mat2   m = mat2(c,-s,s,c);\n    return vec3(m*p.xz,p.y);\n}\n\nDF_out map( in vec3 pos )\n{\n    float dist = opU( sdPlane(     pos-vec3( -1.4) ),\n\t                sdSphere(    pos-vec3( 0.0,0.25, 0.0), 0.25 ) );\n    dist = opU( dist, udRoundBox(  pos-vec3( 1.0,0.25, 1.0), vec3(0.15), 0.1 ) );\n\tdist = opU( dist, sdTorus(     pos-vec3( 0.0,0.25, 1.0), vec2(0.20,0.05) ) );\n\tdist = opU( dist, sdTriPrism(  pos-vec3(-1.0,0.25,-1.0), vec2(0.25,0.05) ) );\n\tdist = opU( dist, sdCylinder(  pos-vec3( 1.0,0.30,-1.0), vec2(0.10,0.20) ) );\n\tdist = opU( dist, sdTorus88(   pos-vec3(-1.0,0.25, 1.0), vec2(0.20,0.05) ) );\n    dist = opU( dist, opSmoothSubtract(\n\t                      udRoundBox(  pos-vec3(-1.0,0.2, 0.0), vec3(0.15),0.05),\n\t                      sdSphere(    pos-vec3(-1.0,0.2, 0.0), 0.25)) );\n    dist = opU( dist, sdBox(       pos-vec3( 0.0,0.20,-1.0), vec3(0.25)) );\n\tdist = opU( dist, 0.5*sdTorus( opTwist(pos-vec3( 1.0,0.25, 0.0)),vec2(0.15,0.02)) );\n\n    DF_out outData;\n    outData.d = dist-ISOVALUE;\n    outData.matID = MATERIALID_ICE_OUTER;\n    return outData;\n}\n\nvec3 gradient( in vec3 p )\n{\n\tconst float d = 0.001;\n\tvec3 grad = vec3(map(p+vec3(d,0,0)).d-map(p-vec3(d,0,0)).d,\n                     map(p+vec3(0,d,0)).d-map(p-vec3(0,d,0)).d,\n                     map(p+vec3(0,0,d)).d-map(p-vec3(0,0,d)).d);\n\treturn grad;\n}\n\nvec2 sphereTracing( const vec3 o, const vec3 d, const float tmin, const float eps, const bool bInternal)\n{\n    \/\/https:\/\/iquilezles.org\/articles\/raymarchingdf\n    \/\/http:\/\/mathinfo.univ-reims.fr\/IMG\/pdf\/hart94sphere.pdf p.5-89\n    \/\/[modified for internal marching]\n    float tmax = 10.0;\n    float t = tmin;\n    float dist = GEO_MAX_DIST;\n    for( int i=0; i<50; i++ )\n    {\n        vec3 p = o+d*t;\n\t    dist = (bInternal?-1.:1.)*map(p).d;\n        if( abs(dist)<eps || t>tmax )\n            break;\n        t += dist;\n    }\n    \n    dist = (dist<tmax)?dist:GEO_MAX_DIST;\n    return vec2( t, dist );\n}\n\nTraceData TRACE_getFront(const in TraceData tDataA, const in TraceData tDataB)\n{\n    if(tDataA.rayLen<tDataB.rayLen)\n    {\n        return tDataA;\n    }\n    else\n    {\n        return tDataB;\n    }\n}\n\nfloat RAYCAST_floor(vec3 o, vec3 d)\n{\n    vec3 n = vec3(0,1,0);\n    vec3 p = vec3(-0.1);\n    float t = dot(p-o,n)\/dot(d,n);\n    return (t<0.0)?GEO_MAX_DIST:t;\n}\n\n\/\/o=origin, d = direction\nTraceData TRACE_cheap(vec3 o, vec3 d)\n{\n    TraceData floorData;\n\tfloorData.rayLen  = RAYCAST_floor(o, d);\n\tfloorData.rayDir  = d;\n\tfloorData.normal  = vec3(0,1,0);\n\tfloorData.matUVW  = o+d*floorData.rayLen;\n\tfloorData.matID   = MATERIALID_FLOOR;\n    floorData.alpha   = 1.0;\n    \n    TraceData skyData;\n    skyData.rayLen  = 50.0;\n    skyData.rayDir  = d;\n\tskyData.normal  = -d;\n\tskyData.matUVW  = d;\n\tskyData.matID   = MATERIALID_SKY;\n    skyData.alpha   = 1.0;\n    return TRACE_getFront(floorData,skyData);\n}\n\nTraceData TRACE_reflexion(vec3 o, vec3 d)\n{\n    return TRACE_cheap(o,d);\n}\n\n\/\/o=origin, d = direction\nTraceData TRACE_geometry(vec3 o, vec3 d)\n{\n    TraceData cheapTrace = TRACE_cheap(o,d);\n    \n    TraceData iceTrace;\n    vec2 rayLen_geoDist = sphereTracing(o,d,0.1,0.0001,false);\n    vec3 iceHitPosition = o+rayLen_geoDist.x*d;\n    iceTrace.rayDir     = d;\n    iceTrace.rayLen     = rayLen_geoDist.x;\n    iceTrace.normal     = normalize(gradient(iceHitPosition));\n    iceTrace.matUVW     = iceHitPosition;\n    iceTrace.matID      = MATERIALID_ICE_OUTER;\n    iceTrace.alpha      = 0.0;\n    \n    return TRACE_getFront(cheapTrace,iceTrace);\n}\n\n\/\/o=origin, d = direction\nTraceData TRACE_translucentDensity(vec3 o, vec3 d)\n{\n    TraceData innerIceTrace;\n    \n    vec2 rayLen_geoDist   = sphereTracing(o,d,0.01,0.001,true).xy;\n    vec3 iceExitPosition  = o+rayLen_geoDist.x*d;\n    innerIceTrace.rayDir  = d;\n    innerIceTrace.rayLen  = rayLen_geoDist.x;\n    innerIceTrace.normal  = normalize(gradient(iceExitPosition));\n    innerIceTrace.matUVW  = iceExitPosition;\n    innerIceTrace.matID   = MATERIALID_ICE_INNER;\n    innerIceTrace.alpha   = rayLen_geoDist.x;\n    return innerIceTrace;\n}\n\n#define saturate(x) clamp(x,0.0,1.0)\n\/\/o=origin, L = light direction\nfloat RAYMARCH_DFSS( vec3 o, vec3 L, float coneWidth )\n{\n    \/\/Variation of the Distance Field Soft Shadow from : https:\/\/www.shadertoy.com\/view\/Xds3zN\n    \/\/Initialize the minimum aperture (angle tan) allowable with this distance-field technique\n    \/\/(45deg: sin\/cos = 1:1)\n    float minAperture = 1.0; \n    float t = 0.0;\n    float dist = GEO_MAX_DIST;\n    for( int i=0; i<6; i++ )\n    {\n        vec3 p = o+L*t; \/\/Sample position = ray origin + ray direction * travel distance\n        float dist = map( p ).d;\n        float curAperture = dist\/t; \/\/Aperture ~= cone angle tangent (sin=dist\/cos=travelDist)\n        minAperture = min(minAperture,curAperture);\n        t += 0.03+dist; \/\/0.03 : min step size.\n    }\n    \n    \/\/The cone width controls shadow transition. The narrower, the sharper the shadow.\n    return saturate(minAperture\/coneWidth); \/\/Should never exceed [0-1]. 0 = shadow, 1 = fully lit.\n}\n\nvec3 smoothSampling(vec2 uv)\n{\n    const float T_RES = 64.0;\n    vec2 x = fract(uv*T_RES+0.5);\n    vec2 pc1 = uv-(x)\/T_RES;\n    \/\/vec2 t = x * x * (3.0 - 2.0 * x);\n    vec2 t = (6.*x*x-15.0*x+10.)*x*x*x; \/\/ease function\n    return textureLod(iChannel0,pc1+t\/T_RES,0.0).xyz;\n}\n\nfloat triplanarSampling(vec3 p, vec3 n)\n{\n\tfloat fTotal = abs(n.x)+abs(n.y)+abs(n.z);\n\treturn  (abs(n.x)*smoothSampling(p.yz).x\n            +abs(n.y)*smoothSampling(p.xz).x\n            +abs(n.z)*smoothSampling(p.xy).x)\/fTotal;\n}\n\nconst mat2 m2 = mat2(0.90,0.44,-0.44,0.90);\nfloat triplanarNoise(vec3 p, vec3 n)\n{\n    const float BUMP_MAP_UV_SCALE = 0.2;\n    float fTotal = abs(n.x)+abs(n.y)+abs(n.z);\n    float f1 = triplanarSampling(p*BUMP_MAP_UV_SCALE,n);\n    p.xy = m2*p.xy;\n    p.xz = m2*p.xz;\n    p *= 2.1;\n    float f2 = triplanarSampling(p*BUMP_MAP_UV_SCALE,n);\n    p.yx = m2*p.yx;\n    p.yz = m2*p.yz;\n    p *= 2.3;\n    float f3 = triplanarSampling(p*BUMP_MAP_UV_SCALE,n);\n    return f1+0.5*f2+0.25*f3;\n}\n\nvec3 normalMap(vec3 p, vec3 n)\n{\n    float d = 0.005;\n    float po = triplanarNoise(p,n);\n\tfloat px = triplanarNoise(p+vec3(d,0,0),n);\n    float py = triplanarNoise(p+vec3(0,d,0),n);\n\tfloat pz = triplanarNoise(p+vec3(0,0,d),n);\n    return normalize(vec3((px-po)\/d,\n                          (py-po)\/d,\n                          (pz-po)\/d));\n}\n\nstruct Cam\n{\n    vec3 R;\/\/Right, \n    vec3 U;\/\/Up,\n    vec3 D;\/\/Direction,\n    vec3 o;\/\/origin (pos)\n};\nCam CAM_animate(vec2 uv)\n{\n    float PI = 3.14159;\n\tfloat rotX = 2.0*PI*(iMouse.x\/iResolution.x+iTime*0.05);\n    Cam cam;\n    cam.o = vec3(cos(rotX),0.475,sin(rotX))*2.3;\n    cam.D = normalize(vec3(0,-0.25,0)-cam.o);\n    cam.R = normalize(cross(cam.D,vec3(0,1,0)));\n    cam.U = cross(cam.R,cam.D);\n    return cam;\n}\nvec3 CAM_getRay(Cam cam,vec2 uv)\n{\n    uv *= 2.0*iResolution.x\/iResolution.y;;\n    return normalize(uv.x*cam.R+uv.y*cam.U+cam.D*2.5);\n}\n\nvec4 processSliders(in vec2 fragCoord)\n{\n    vec4 sliderVal = texture(iChannel2,vec2(0,0));\n\tROUGHNESS       = sliderVal[0]*4.0;\n\tISOVALUE        = 0.005+sliderVal[1]*0.1;\n\tICE_COLOR       = sliderVal[2];\n\tREFRACTION_IDX  = 1.0+sliderVal[3];\n    \n    if(length(fragCoord.xy-vec2(0,0))>1.)\n    {\n    \treturn texture(iChannel2,fragCoord.xy\/iResolution.xy);\n    }\n    return vec4(0);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec4 cSlider = processSliders(fragCoord);\n\tvec2 uv = (fragCoord.xy-0.5*iResolution.xy) \/ iResolution.xx;\n    \n    Cam cam = CAM_animate(uv);\n    vec3 d = CAM_getRay(cam,uv);\n    vec3 c = main_render(cam.o, d, uv);\n    \n    \/\/Vignetting\n    float lensRadius = 0.65;\n    uv \/= lensRadius;\n    float sin2 = uv.x*uv.x+uv.y*uv.y;\n    float cos2 = 1.0-min(sin2*sin2,1.0);\n    float cos4 = cos2*cos2;\n    c *= cos4;\n    \n    \/\/Gamma\n    c = pow(c,vec3(0.4545)); \/\/2.2 Gamma compensation\n    \n    \/\/Apply slider overlay\n    c = mix(c,cSlider.rgb,cSlider.a);\n    \n    fragColor = vec4(c,1.0);\n}","name":"Image","description":"","type":"image"},{"inputs":[{"id":"4dXGR8","filepath":"\/media\/previz\/buffer00.png","previewfilepath":"\/media\/previz\/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"\/\/Buffer A : slider management (this is not required)\n\n#define saturate(x) clamp(x,0.0,1.0)\nvec4 sliderVal = vec4(0.25,0.22,0,0.31); \/\/Default slider values [0-1]\n\nvoid SLIDER_setValue(float idx, float val)\n{\n    if(idx<0.) return;\n    else if(idx<0.25) sliderVal[0] = saturate(val);\n\telse if(idx<0.50) sliderVal[1] = saturate(val);\n\telse if(idx<0.75) sliderVal[2] = saturate(val);\n\telse if(idx<1.00) sliderVal[3] = saturate(val);\n}\n\nfloat SLIDER_getValue(float idx)\n{\n    if     (idx<0.25) return sliderVal[0];\n    else if(idx<0.50) return sliderVal[1];\n    else if(idx<0.75) return sliderVal[2];\n    else if(idx<1.00) return sliderVal[3];\n\telse return 0.;\n}\n\nvoid SLIDER_init(vec2 mousePos, vec2 cMin, vec2 cMax )\n{\n    vec4 cPingPong = textureLod(iChannel0,vec2(0),0.0);\n    if(length(cPingPong)>0.001)\n        sliderVal = cPingPong;\n        \n    float width = cMax.x-cMin.x;\n    float height = cMax.y-cMin.y;\n    if(mousePos.x>cMin.x && mousePos.x<cMax.x &&\n       mousePos.y>cMin.y && mousePos.y<cMax.y )\n    {\n        float t = (mousePos.y-cMin.y)\/height;\n        t = clamp(t\/0.75-0.125,0.,1.); \/\/25% top\/bottom margins\n\t\tSLIDER_setValue((mousePos.x-cMin.x)\/width, t);\n    }\n}\n\n\/\/Returns the distance from point \"p\" to a given line segment defined by 2 points [a,b]\nfloat UTIL_distanceToLineSeg(vec2 p, vec2 a, vec2 b)\n{\n    \/\/       p\n    \/\/      \/\n    \/\/     \/\n    \/\/    a--e-------b\n    vec2 ap = p-a;\n    vec2 ab = b-a;\n    \/\/Scalar projection of ap in the ab direction = dot(ap,ab)\/|ab| : Amount of ap aligned towards ab\n    \/\/Divided by |ab| again, it becomes normalized along ab length : dot(ap,ab)\/(|ab||ab|) = dot(ap,ab)\/dot(ab,ab)\n    \/\/The clamp provides the line seg limits. e is therefore the \"capped orthogogal projection\", and length(p-e) is dist.\n    vec2 e = a+clamp(dot(ap,ab)\/dot(ab,ab),0.0,1.0)*ab;\n    return length(p-e);\n}\n\n\/\/uv = slider pixel in local space [0-1], t = slider value [0-1], ar = aspect ratio (w\/h)\nvec4 SLIDER_drawSingle(vec2 uv, float t, vec2 ar, bool bHighlighted)\n{\n    const vec3  ITEM_COLOR = vec3(1);\n    const vec3  HIGHLIGHT_COLOR = vec3(0.2,0.7,0.8);\n    const float RAD = 0.05;  \/\/Cursor radius, in local space\n    const float LW  = 0.030; \/\/Line width\n    float aa  = 14.\/iResolution.x; \/\/antialiasing width (smooth transition)\n    vec3 selectionColor = bHighlighted?HIGHLIGHT_COLOR:ITEM_COLOR;\n    vec3 cheapGloss   = 0.8*selectionColor+0.2*smoothstep(-aa,aa,uv.y-t-0.01+0.01*sin(uv.x*12.));\n    vec2 bottomCenter = vec2(0.5,0.0);\n\tvec2 topCenter    = vec2(0.5,1.0);\n    vec2 cursorPos    = vec2(0.5,t);\n    float distBar = UTIL_distanceToLineSeg(uv*ar, bottomCenter*ar, topCenter*ar);\n    float distCur = length((uv-cursorPos)*ar)-RAD;\n    float alphaBar = 1.0-smoothstep(2.0*LW-aa,2.0*LW+aa, distBar);\n    float alphaCur = 1.0-smoothstep(2.0*LW-aa,2.0*LW+aa, distCur);\n    vec4  colorBar = vec4(mix(   vec3(1),vec3(0),smoothstep(LW-aa,LW+aa, distBar)),alphaBar);\n    vec4  colorCur = vec4(mix(cheapGloss,vec3(0),smoothstep(LW-aa,LW+aa, distCur)),alphaCur);\n    return mix(colorBar,colorCur,colorCur.a);\n}\n\n#define withinUnitRect(a) (a.x>=0. && a.x<=1. && a.y>=0. && a.y<=1.0)\nvec4 SLIDER_drawAll(vec2 uv, vec2 cMin, vec2 cMax, vec2 muv)\n{\n    float width = cMax.x-cMin.x;\n    float height = cMax.y-cMin.y;\n    vec2 ar = vec2(0.30,1.0);\n    uv  = (uv -cMin)\/vec2(width,height); \/\/pixel Normalization\n    muv = (muv-cMin)\/vec2(width,height); \/\/mouse Normalization\n    if( withinUnitRect(uv) )\n    {\n        float t = SLIDER_getValue(uv.x);\n\t\tbool bHighlight = withinUnitRect(muv) && abs(floor(uv.x*4.0)-floor(muv.x*4.0))<0.01;\n\t\tuv.x = fract(uv.x*4.0); \/\/repeat 4x\n\t\tuv.y = uv.y\/0.75-0.125; \/\/25% margins\n        return SLIDER_drawSingle(uv,t,ar,bHighlight);\n    }\n    return vec4(0);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 cMinSliders = vec2(0.9,0.80);\n    vec2 cMaxSliders = vec2(1.0,1.00);\n    vec2 uvSliders = fragCoord.xy \/ iResolution.xy;\n    vec2 mousePos = iMouse.xy \/ iResolution.xy;\n    SLIDER_init(mousePos, cMinSliders, cMaxSliders);\n    vec4 cSlider = SLIDER_drawAll(uvSliders,cMinSliders, cMaxSliders, mousePos);\n    \n    if(length(fragCoord.xy-vec2(0,0))<1.) \n        fragColor = sliderVal;\n\telse fragColor = cSlider;\n}","name":"Buf A","description":"","type":"buffer"}]},{"ver":"0.1","info":{"id":"MdcXzn","date":"1457308311","viewed":12295,"name":"Geomechanical","username":"Bers","description":"Generative, smooth edged hexagonal prism primitive, shaded with arithmetic PBR Lights.","likes":195,"published":3,"flags":0,"usePreview":0,"tags":[]},"renderpass":[{"inputs":[],"outputs":[{"id":"4dfGRr","channel":0}],"code":"\/\/ Author : Sebastien Berube\n\/\/ Created : March 2015\n\/\/ Modified : Jan 2016\n\/\/ \n\/\/ Composition made from a repeated hexagon prism pattern.\n\/\/ Hexagon prism distance function had to be modified to smooth out vertical edges.\n\/\/\n\/\/ Sources:\n\/\/ Inigo Quilez\n\/\/ https:\/\/iquilezles.org\/articles\/distfunctions\n\/\/ https:\/\/iquilezles.org\/articles\/raymarchingdf\n\/\/ For those interested in the origin of sphere tracing:\n\/\/ Sphere Tracing: A Geometric Method for the Antialiased Ray Tracing of Implicit Surfaces (1994)\n\/\/ http:\/\/citeseer.ist.psu.edu\/viewdoc\/summary?doi=10.1.1.48.3825\n\/\/ Spline\n\/\/ http:\/\/www.lighthouse3d.com\/tutorials\/maths\/catmull-rom-spline\/\n\/\/\n\/\/ License : Creative Commons Non-commercial (NC) license\n\/\/\n\n\/\/----------------------\n\/\/ Constants\nconst float PI = 3.14159;\nconst float SCALE = 1.0;\nconst float MAX_DIST = 1000.0;\nconst float FLOOR_HEIGHT  = 0.0;\nconst float X_REPEAT_DIST = 0.90*SCALE;\nconst float Z_REPEAT_DIST = 1.05*SCALE;\nconst float PRIM_HEIGHT    = 1.0;\nconst float HEX_HALF_WIDTH = 0.26*SCALE;\nconst float GEOMETRY_DISPLACEMENT = 1.00;\nfloat g_time;\n\nstruct AnimationChannels\n{\n    float material_roughness;   \/\/[0-1 range]\n    float geometry_width;       \/\/[0-1 range]\n    float geometry_scale;       \/\/[0-1 range]\n    float geometry_displacement;\/\/[0-1 range]\n\tfloat geometry_smoothness;  \/\/[0-1 range]\n    vec3 camPos;                \/\/[IR range]\n    vec3 camLookAt;             \/\/[IR range]\n};\nAnimationChannels g_animationChannels;\n\n\/\/Material ID enum\nconst int MATERIALID_NONE      = 0;\nconst int MATERIALID_FLOOR     = 1;\nconst int MATERIALID_SKY       = 2;\nconst int MATERIALID_PLASTIC   = 3;\nconst int MATERIALID_METAL     = 4;\n\n\/\/Debug flag enum\nconst int DEBUG_RAYLEN  = 0;\nconst int DEBUG_GEODIST = 1;\nconst int DEBUG_NORMAL  = 2;\nconst int DEBUG_MATID   = 3;\n\nfloat fDEBUG = 0.1;\n\n\/\/Defines\n#define saturate(x) clamp(x,0.0,1.0)\n\/\/----------------------\n\/\/ Camera\nstruct Cam { vec3 R; vec3 U; vec3 D; vec3 o; float lens; float zoom; }; \/\/Right, Up, Direction, origin\nCam    CAM_lookAt(vec3 target, float pitchAngleRad, float dist, float theta);\nCam    CAM_mouseLookAt(vec3 at, float dst);\nCam    CAM_animate(vec2 uv, float fTime);\nvec3   CAM_getRay(Cam cam, vec2 uv);\n\n\/\/----------------------\n\/\/ Post Process\nvec3 POST_ProcessFX(vec3 c, vec2 uv);\n\n\/\/----------------------\n\/\/ Analytic Intersections\nfloat RAYINTERSEC_plane(vec3 o, vec3 d, vec3 po, vec3 pn)\n{\n    return dot(po-o,pn)\/dot(d,pn); \n}\n\nstruct repeatInfo\n{\n    vec3 smpl; \/\/object-space, cyclic\n    vec3 anchor; \/\/world space\n};\n    \n#define normalized_wave(a) (0.5*a+0.5)\nrepeatInfo DF_repeatHex(vec3 p)\n{\n    \/\/Repetition\n    float xRepeatDist = X_REPEAT_DIST;\n    float zRepeatDist = Z_REPEAT_DIST*0.5;\n    float latticeX = (fract(p.x\/xRepeatDist+0.5)-0.5)*xRepeatDist;\n    float latticeY = (fract(p.z\/zRepeatDist+0.5)-0.5)*zRepeatDist;\n    vec2 anchorPosXZ = p.xz-vec2(latticeX,latticeY);\n    p.x = latticeX; \/\/Cyclic coords.\n    p.z = latticeY;\n    \n    \/\/Variation\n    float period = fract(g_time\/30.)*3.0;\n    float theta = period*2.0*PI;\n    float overallAmplitude = normalized_wave(-cos(theta)); \/\/Overall amplitude modulation\n    float waveAmplitude = g_animationChannels.geometry_displacement\n                         *normalized_wave(sin(anchorPosXZ.x+anchorPosXZ.y+theta*4.0));\n    float primHeight = FLOOR_HEIGHT+overallAmplitude*waveAmplitude;\n     \n    repeatInfo outData;\n    outData.anchor = vec3(anchorPosXZ[0], primHeight, anchorPosXZ[1]);\n    outData.smpl = p;\n    \n    return outData;\n}\n\n#define zclamp(a) max(a,0.0) \/\/Clamp negative values at zero\nfloat DF_RoundedHex( vec3 p, float width, float height)\n{\n    \/\/Modified version (smooth edges) of the exagon prism found here:\n    \/\/https:\/\/iquilezles.org\/articles\/distfunctions\n    float smoothRadius = g_animationChannels.geometry_smoothness*0.2;\n    width -= smoothRadius*2.0;\n    \n    \/\/Hexagon prism constructed using X,Y,Z symmetry.\n    \/\/Only quadrant 1 needs to be solved, but the joining diagonal to quadrant IV is also\n    \/\/required for distance blending (see db).\n    p = abs(p);\n    \n    \/\/Hexagonal edge distances :\n    \/\/Note : [.8666,0.5] = [sin(PI\/3,cos(PI\/3)] -> Hexagon edges rotation coeff (60 degrees).\n    float da = (p.x*0.866025+p.z*0.5)-width; \/\/quadrant I diagonal edge distance\n    float db = (p.x*0.866025-p.z*0.5)-width; \/\/quadrant IV diagonal edge distance (needed for blending)\n    float dc = p.z-width; \/\/upper distance\n    \n    vec3 d = zclamp(vec3(da,db,dc));\n    \/\/Note: this is not an euclidian length, therefore this operation slightly distorts our distance field.\n    \/\/Yet, it is harmless to convergence, and does the smoothing job quite well.\n    float dw = length(d)-smoothRadius; \/\/hexagonal part smoothness (blending at 60 deg)\n    float dh = p.y-height;\n    \n    \/\/Now that we have xz distance(dw) and y distance (dh), we can compute the distance \n    \/\/for the given isovalue (the smoothing radius).\n    \/\/Note : internal distance (maxX,maxY,maxZ) is also used to genereate internal signed dist,\n    \/\/       helping convergence when overstepping (very frequent with domain repetition).\n    float externalDistance = length(zclamp(vec2(dh,dw)))-smoothRadius; \/\/Smoothed, unsigned\n\tfloat internalDistance = max(max(da,dc),dh); \/\/Sharp, signed.\n    return min(externalDistance,internalDistance);\n}\n\nstruct DF_out\n{\n    float d;\n    int matID;\n    vec3 objectPos;\n};\n    \n\/\/The distance field composition.\n\/\/::DF_composition\nDF_out DF_composition( in vec3 pos )\n{\n    \/\/Explanation:\n    \/\/https:\/\/iquilezles.org\/articles\/distfunctions\n    DF_out oFloor;\n    DF_out oHexA;\n    DF_out oHexB;\n    \n    oHexA.matID = MATERIALID_PLASTIC;\n    repeatInfo infoA = DF_repeatHex(pos-vec3(0));\n\toHexA.objectPos = infoA.anchor;\n    oHexA.d = DF_RoundedHex( infoA.smpl-vec3(0,infoA.anchor.y,0),\n\t                         g_animationChannels.geometry_width*HEX_HALF_WIDTH, PRIM_HEIGHT );\n    \n    oHexB.matID = MATERIALID_PLASTIC;\n    repeatInfo infoB = DF_repeatHex(pos-vec3(X_REPEAT_DIST*0.5,0, Z_REPEAT_DIST*0.25));\n\toHexB.objectPos = infoB.anchor;\n    oHexB.d = DF_RoundedHex( infoB.smpl-vec3(0,infoB.anchor.y,0),\n\t                         g_animationChannels.geometry_width*HEX_HALF_WIDTH, PRIM_HEIGHT );\n    \n    if(oHexA.d<oHexB.d)\n        return oHexA;\n    else\n        return oHexB;\n}\n\n\/\/The distance field gradient\nvec3 DF_gradient( in vec3 p )\n{\n    \/\/The field gradient is the distance derivative along each axis.\n    \/\/The surface normal follows the direction where this variation is strongest.\n\tconst float d = 0.001;\n\tvec3 grad = vec3(DF_composition(p+vec3(d,0,0)).d-DF_composition(p-vec3(d,0,0)).d,\n                     DF_composition(p+vec3(0,d,0)).d-DF_composition(p-vec3(0,d,0)).d,\n                     DF_composition(p+vec3(0,0,d)).d-DF_composition(p-vec3(0,0,d)).d);\n\treturn grad\/(2.0*d);\n}\n\n#define OVERSTEP_COMPENSATION 1\n\n\/\/o = ray origin, d = direction, t = distance travelled along ray, starting from origin\nfloat RAYMARCH_isosurface( vec3 o, vec3 d, float isoSurfaceValue)\n{\n    \/\/Learned from Inigo Quilez DF ray marching :\n    \/\/https:\/\/iquilezles.org\/articles\/raymarchingdf\n    \/\/Original articles (interesting read) :\n    \/\/Sphere Tracing: A Geometric Method for the Antialiased Ray Tracing of Implicit Surfaces (1989)\n    \/\/http:\/\/mathinfo.univ-reims.fr\/IMG\/pdf\/hart94sphere.pdf\n    \/\/John C. Hart Sphere Tracing: A Geometric Method for the Antialiased Ray Tracing of Implicit Surfaces (1994)\n    \/\/http:\/\/citeseer.ist.psu.edu\/viewdoc\/summary?doi=10.1.1.48.3825 p. 5.75-5.85\n    \n    const float tolerance = 0.0001;\n    float t = 0.0;\n    float dist = MAX_DIST;\n    #if OVERSTEP_COMPENSATION\n    for( int i=0; i<30; i++ )\n    {\n        dist = DF_composition( o+d*t ).d;\n        dist -= isoSurfaceValue;\n        \n        if( abs(dist)<tolerance*100.0 ) break;\n        t += dist;\n    }\n    \n    t -= Z_REPEAT_DIST\/2.0;\n    \n    for( int i=0; i<30; i++ )\n    {\n        dist = DF_composition( o+d*t ).d;\n        dist -= isoSurfaceValue;\n        \n        if( abs(dist)<tolerance ) break;\n        \n        t += min(dist,Z_REPEAT_DIST\/5.0);\n    }\n    #else\n    for( int i=0; i<70; i++ )\n    {\n        dist = DF_composition( o+d*t ).d;\n        dist -= isoSurfaceValue;\n        \n        if( abs(dist)<tolerance ) break;\n        t += dist;\n    }\n    #endif\n    \n    return t;\n}\n\n#define saturate(x) clamp(x,0.0,1.0)\nfloat RAYMARCH_DFSS( vec3 o, vec3 L, float coneWidth )\n{\n    \/\/Variation of the Distance Field Soft Shadow from : https:\/\/www.shadertoy.com\/view\/Xds3zN\n    \/\/Initialize the minimum aperture (angle tan) allowable with this distance-field technique\n    \/\/(45deg: sin\/cos = 1:1)\n    float minAperture = 1.0; \n    float t = 0.0; \/\/initial travel distance, from geometry surface (usually, pretty close)\n    float dist = 10.0;\n    for( int i=0; i<7; i++ )\n    {\n        vec3 p = o+L*t; \/\/Sample position = ray origin + ray direction * travel distance\n        float dist = DF_composition( p ).d;\n        dist = min(dist,t);\n        float curAperture = dist\/t; \/\/Aperture ~= cone angle tangent (sin=dist\/cos=travelDist)\n        minAperture = min(minAperture,curAperture);\n        \/\/Step size : limit range (0.02-0.42)\n        t += 0.02+min(dist,0.4);\n    }\n    \n    \/\/The cone width controls shadow transition. The narrower, the sharper the shadow.\n    return saturate(minAperture\/coneWidth); \/\/Should never exceed [0-1]. 0 = shadow, 1 = fully lit.\n}\n\nfloat RAYMARCH_DFAO( vec3 o, vec3 N, float isoSurfaceValue)\n{\n    \/\/Variation of DFAO from : https:\/\/www.shadertoy.com\/view\/Xds3zN\n    \/\/Interesting reads:\n    \/\/https:\/\/docs.unrealengine.com\/latest\/INT\/Engine\/Rendering\/LightingAndShadows\/DistanceFieldAmbientOcclusion\/index.html#howdoesitwork?\n    \/\/Implementation notes:\n    \/\/-Doubling step size at each iteration\n    \/\/-Allowing negative distance field values to contribute, making cracks much darker\n    \/\/-Not reducing effect with distance (specific to this application)\n    float MaxOcclusion = 0.0;\n    float TotalOcclusion = 0.0;\n    const int nSAMPLES = 4;\n    float stepSize = 0.11\/float(nSAMPLES);\n    for( int i=0; i<nSAMPLES; i++ )\n    {\n        float t = 0.01 + stepSize;\n        \/\/Double distance each iteration (only valid for small sample count, e.g. 4)\n        stepSize = stepSize*2.0;\n        float dist = DF_composition( o+N*t ).d-isoSurfaceValue;\n        \/\/Occlusion factor inferred from the difference between the \n        \/\/distance covered along the ray, and the distance from other surrounding geometry.\n        float occlusion = zclamp(t-dist);\n        TotalOcclusion += occlusion;\/\/Not reducing contribution on each iteration\n        MaxOcclusion += t;\n    }\n    \n    \/\/Here, TotalOcclusion can actually exceed MaxOcclusion, where the rays\n    \/\/get inside the shape and grab negative occlusion values. It does look good\n    \/\/that way IMHO (much darker in the cracks), therefore the maximum occlusion is bumped\n    \/\/25% to allow those cracks to get darker.\n    return saturate(1.0-TotalOcclusion\/(MaxOcclusion*1.25));\n}\n\nstruct TraceData\n{\n    float rayLen;  \/\/Ray travel distance\n    vec3  rayDir;  \/\/Ray direction\n    float geoDist; \/\/Distance to geometry (error on final position)\n    vec3  normal;  \/\/Geometry normal\n    vec3  objectPos; \/\/Object position (center)\n    int   matID;     \/\/Material ID\n};\n    \nTraceData new_TraceData()\n{\n    TraceData td;\n    td.rayLen = 0.;\n    td.rayDir = vec3(0);\n    td.geoDist = 0.;\n    td.normal = vec3(0);\n    td.objectPos = vec3(0);\n    td.matID = MATERIALID_NONE;\n    return td;\n}\n\nvec3 PBR_HDRremap(vec3 c)\n{\n    float fHDR = smoothstep(2.900,3.0,c.x+c.y+c.z);\n    return mix(c,1.3*vec3(4.5,3.5,3.0),fHDR);\n}\n\n\/\/http:\/\/refractiveindex.info\/?shelf=3d&book=liquids&page=water\nconst float F_DIELECTRIC_PLASTIC = 1.49; \/\/@550nm\nconst float F_DIELECTRIC_WATER   = 1.33; \/\/@550nm\nconst float F_DIELECTRIC_DIAMOND = 2.42; \/\/@550nm\n\n\/\/ior = index of refraction\n\/\/n = refraction index\nvec3 PBR_Fresnel_Schlick_Dielectric(vec3 n, float VdotH)\n{\n\t\/\/<Source : https:\/\/en.wikipedia.org\/wiki\/Schlick%27s_approximation>\n\tvec3 F0 = abs ((1.0 - n) \/ (1.0 + n));\n\treturn F0 + (1.-F0) * pow( 1. - VdotH, 5.);\n    \/\/<\/Source : https:\/\/en.wikipedia.org\/wiki\/Schlick%27s_approximation>\n}\n\nvec3 PBR_ABL_Equation(vec3 V, vec3 L, vec3 N, float roughness, float metallic, vec3 ior_n, vec3 ior_k)\n{\n    roughness = max(roughness,0.01);\n    \n\tvec3 H = normalize(L+V);\n\tfloat NdotH = dot(N,H);\/\/Nn.H;\n\tfloat NdotL = dot(N,L);\/\/Nn.Ln;\n\tfloat VdotH = dot(V,H);\/\/Vn.H;\n    float NdotV = dot(N,V);\/\/Nn.Vn;\n    \n    \/\/Distribution term\n    \/\/This D value is an approximation of the probability for a given light to bounce into the viewing vector direction.\n\t\/\/It is not necessarily 100% mathematically\/physically correct : this is still just a function which has a curve that decently\n    \/\/matches the physical distribution.\n    \/\/<Source: https:\/\/de45xmedrsdbp.cloudfront.net\/Resources\/files\/2013SiggraphPresentationsNotes-26915738.pdf p.3\/59>\n    float PI = 3.14159;\n    float alpha2 = roughness * roughness;\n    float NoH2 = NdotH * NdotH;\n    float den = NoH2*(alpha2-1.0)+1.0;\n    float D = (NdotH>0.)?alpha2\/(PI*den*den):0.0;\n\t\/\/<\/https:\/\/de45xmedrsdbp.cloudfront.net\/Resources\/files\/2013SiggraphPresentationsNotes-26915738.pdf p.3\/59>\n    \n    \/\/Fresnel term\n    vec3 F = PBR_Fresnel_Schlick_Dielectric(ior_n, VdotH);\n    \n    \/\/Geometric term\n    \/\/<Source: https:\/\/de45xmedrsdbp.cloudfront.net\/Resources\/files\/2013SiggraphPresentationsNotes-26915738.pdf p.3\/59>\n    float Gk = (roughness+1.)*(roughness+1.)\/8.; \/\/<-Disney's modification for ABL\n    float Gl = max(NdotL,0.)\/(NdotL*(1.0-Gk)+Gk);\n    float Gv = max(NdotV,0.)\/(NdotV*(1.0-Gk)+Gk);\n    float G = Gl*Gv;\n    \/\/<\/https:\/\/de45xmedrsdbp.cloudfront.net\/Resources\/files\/2013SiggraphPresentationsNotes-26915738.pdf p.3\/59>\n    \n    \/\/The PBR equation seen pretty much everywhere:\n    \/\/<Source : https:\/\/seblagarde.wordpress.com\/2015\/07\/14\/siggraph-2014-moving-frostbite-to-physically-based-rendering\/ p.14>\n    \/\/<Source : http:\/\/www.codinglabs.net\/article_physically_based_rendering_cook_torrance.aspx>\n    float softTr = 0.2; \/\/ Valid range : [0.001-0.25]. Will reduce reflexivity on edges if too high.\n    \/\/Personal addition : This parameter softens up the transition at grazing angles (otherwise too sharp IMHO).\n    vec3 Rs = D*F*G \/ (4.*NdotV*NdotL*(1.0-softTr)+softTr);\n    \/\/<Source : http:\/\/www.codinglabs.net\/article_physically_based_rendering_cook_torrance.aspx>\n    \n\treturn Rs;\n}\n\n#define saturate(x) clamp(x,0.0,1.0)\nvec3 MAT_Plastic(TraceData traceData, vec3 cDiff, vec3 N, vec3 V, vec3 L0, vec3 L1, float dfao, float dfss0, float dfss1)\n{\n    vec3 col = vec3(0);\n    \n    float fRoughness = g_animationChannels.material_roughness;\n    \n    \/\/Ambient directional contribution (3x):\n    \/\/           color*directionalContribution(<normal,ambientDir>)\n    \/\/This give a basic \"ambient\" shading, which varies with normal angle\n    vec3 cAmb  = vec3(0.26,0.24,0.23)*vec3(0.5+0.5*dot(traceData.normal,vec3(+0.08,1,+0.1)))\n               + vec3(0.25,0.25,0.30)*vec3(0.5+0.5*dot(traceData.normal,vec3(-0.28,1,-0.17)))\n               + vec3(0.19,0.25,0.30)*vec3(0.5+0.5*dot(traceData.normal,vec3(+0.28,1,-0.27)));\n    \/\/2 x PBR lights\n    vec3 CL0  = PBR_HDRremap(vec3(1))*PBR_ABL_Equation(V,L0,traceData.normal, fRoughness, 0., vec3(F_DIELECTRIC_PLASTIC), vec3(0));\n    vec3 CL1  = PBR_HDRremap(vec3(1))*PBR_ABL_Equation(V,L1,traceData.normal, fRoughness, 0., vec3(F_DIELECTRIC_PLASTIC), vec3(0));\n    \n    col = cAmb*dfao;\n    col *= saturate(0.30+fRoughness*0.5+0.2*(dfss0+dfss1));\n    col += (dfss0+fRoughness*0.25)*CL0;\n    col += (dfss1+fRoughness*0.25)*CL1;\n    \n    return col*0.75;\n}\n\nfloat SAMPLER_trilinear(vec3 p)\n{\n    \/\/Noise layering trick from Inigo Quilez.\n    \/\/See this for more explanation: https:\/\/www.shadertoy.com\/view\/Ms3SRr\n    const float TEXTURE_RES = 256.0; \/\/Noise texture resolution\n    p *= TEXTURE_RES;   \/\/Computation in pixel space (1 unit = 1 pixel)\n    vec3 pixCoord = floor(p);\/\/Pixel coord, integer [0,1,2,3...256...]\n    vec3 t = p-pixCoord;     \/\/Pixel interpolation position, linear range [0-1] (fractional part)\n    t = (3.0 - 2.0 * t) * t * t; \/\/interpolant easing function : linear->cubic\n    vec2 layer_translation = -pixCoord.y*vec2(37.0,17.0)\/TEXTURE_RES; \/\/noise volume stacking trick : g layer = r layer shifted by (37x17 pixels -> this is no keypad smashing, but the actual translation embedded in the noise texture).\n    vec2 layer1_layer2 = texture(iChannel0,layer_translation+(pixCoord.xz+t.xz+0.5)\/TEXTURE_RES,-100.0).xy; \/\/Note : +0.5 to fall right on pixel center\n    return mix( layer1_layer2.x, layer1_layer2.y, t.y ); \/\/Layer interpolation (trilinear\/volumetric)\n}\n\nfloat MAT_remap_angle_probability(float x_01)\n{\n    \/\/cos(jitter) is used to alter probabilty distribution : \n    \/\/it remaps an evenly distributed function into another \n    \/\/one where closer angles are more probable, and wider\n    \/\/angles are less probable.\n    return (1.0-cos(x_01*PI\/2.0));\n}\n\nvec3 MAT_addFog(float travelDist, in vec3 color, in vec3 p, in vec3 c_atmosphere)\n{\n    float a = 0.08;\n    float NORMALIZATION_TERM = log((1.+a)\/a);\n    float da = travelDist\/50.0;\n    da = log((da+a)\/a)\/NORMALIZATION_TERM;\n    vec3 FinalColor = mix(color,c_atmosphere,saturate(da));\n    return FinalColor;\n}\n\n\/\/::MAT_apply\nvec4 MAT_apply(vec3 pos, TraceData traceData)\n{\n    vec3 c_atmosphere = mix(vec3(0.87,0.94,1.0),vec3(0.6,0.80,1.0),clamp(3.0*pos.y\/length(pos.xz),0.,1.));\n    \n    if(traceData.matID==MATERIALID_SKY)\n    {\n        return vec4(c_atmosphere,1.0);\n    }\n    \n    vec4 col = vec4(0);\n    vec3 N = traceData.normal;\n    vec3 V = normalize(-traceData.rayDir);\n    vec3 L0 = normalize(vec3(0.5,1.2,0.3));\n    vec3 L1 = normalize(vec3(-L0.x,L0.y,-L0.z+0.5));\n    \n    \/\/<Jittered AO Samples around Y axis, to reduce artifacts associated with closely repeated geometry>\n    float fNoiseAmplitude = 0.4;\n    float jitter_01 = SAMPLER_trilinear(pos*10.0+g_time*50.0);\n    float t = MAT_remap_angle_probability(jitter_01)*fNoiseAmplitude;\n    vec3 Na = vec3(N.xz*mat2(cos(t),sin(t),-sin(t),cos(t)),N.y).xzy; \/\/Rotate(t)\n    jitter_01 = SAMPLER_trilinear(5.0+pos*9.11);\n    t = MAT_remap_angle_probability(jitter_01)*fNoiseAmplitude;\n    vec3 Nb = vec3(N.xz*mat2(cos(t),-sin(t),sin(t),cos(t)),N.y).xzy; \/\/Rotate(-t)\n    float dfaoA = RAYMARCH_DFAO( pos, Na, 0.02);\n    float dfaoB = RAYMARCH_DFAO( pos, Nb, 0.02);\n    float dfaoAveraged = 0.5*(dfaoA+dfaoB);\n    \/\/<\/Jittered AO Samples>\n    \n    float dfss0 = RAYMARCH_DFSS( pos+L0*0.01, L0, 0.2);\n    float dfss1 = RAYMARCH_DFSS( pos+L1*0.01, L1, 0.2);\n    \n    if(traceData.matID==MATERIALID_PLASTIC)\n    {\n        col.rgb = MAT_Plastic(traceData, vec3(1), N, V, L0, L1, dfaoAveraged, dfss0, dfss1);\n    }\n    \n    col.rgb = MAT_addFog(traceData.rayLen*0.3, col.rgb, pos, c_atmosphere);\n    \n    return col;\n}\n\nfloat TRACE_zprime(vec3 o, vec3 d)\n{\n    float geometryCeiling = FLOOR_HEIGHT+PRIM_HEIGHT\n\t                       +g_animationChannels.geometry_displacement*GEOMETRY_DISPLACEMENT;\n    float t = RAYINTERSEC_plane(o, d, vec3(0,geometryCeiling,0), vec3(0,1,0));\n    return (t<0.0)?MAX_DIST:t;\n    return t;\n}\n\n\/\/o=ray origin, d=ray direction\n\/\/::TRACE_geometry\nTraceData TRACE_geometry(vec3 o, vec3 d)\n{\n    \/\/Raymarching (the expensive function)\n    TraceData dfTrace;\n    float rayLen = RAYMARCH_isosurface(o,d,0.0);\n    vec3 dfHitPosition = o+rayLen*d;\n    \n    \/\/Additional sample, to gather material ID and other info\n    \/\/(we want that stuff coompiled out of the raymarching loop, it clutters the code and might slow things down)\n    DF_out compInfo = DF_composition( dfHitPosition );\n    rayLen += compInfo.d;\n    dfHitPosition = o+rayLen*d;\n        \n    dfTrace.rayLen     = rayLen;\n    dfTrace.matID      = compInfo.matID;\n    dfTrace.objectPos  = compInfo.objectPos;\n    dfTrace.geoDist    = compInfo.d;\n    dfTrace.rayDir     = d;\n    dfTrace.normal     = normalize(DF_gradient(dfHitPosition));\n    \n    return dfTrace;\n}\n\nvec3 TRACE_debug(TraceData traceData, int elemID)\n{\n    if(elemID==DEBUG_RAYLEN)  return vec3(log(traceData.rayLen)*0.2);\n    if(elemID==DEBUG_GEODIST) return vec3(traceData.geoDist);\n    if(elemID==DEBUG_NORMAL)  return traceData.normal;\n    if(elemID==DEBUG_MATID)   return traceData.matID==MATERIALID_PLASTIC?vec3(1):\n                                     vec3(traceData.matID==MATERIALID_FLOOR?1:0,\n                                          traceData.matID==MATERIALID_METAL?1:0,\n                                          traceData.matID==MATERIALID_SKY?1:0);\n    return vec3(0);\n}\n\nconst int SPLINE_POINT_COUNT = 8;\nstruct SPLINE_CtrlPts\n{\n    vec4 p[SPLINE_POINT_COUNT];\n};\nvec4 SPLINE_PointArray(int i, SPLINE_CtrlPts ctrlPts)\n{\n    \/\/Just a way to get around the fact global arrays do not support random index access.\n    \/\/(only texture\/resources)\n    if(i==0 || i==SPLINE_POINT_COUNT  ) return ctrlPts.p[0];\n    if(i==1 || i==SPLINE_POINT_COUNT+1) return ctrlPts.p[1];\n    if(i==2 || i==SPLINE_POINT_COUNT+2) return ctrlPts.p[2];\n    if(i==3) return ctrlPts.p[3];\n    if(i==4) return ctrlPts.p[4];\n    if(i==5) return ctrlPts.p[5];\n    if(i==6) return ctrlPts.p[6];\n    if(i==7) return ctrlPts.p[7];\n    return vec4(0);\n}\n\nvec4 SPLINE_catmullRom(float fTime, SPLINE_CtrlPts ctrlPts)\n{\n    float t = fract(fTime);\n    const float n = float(SPLINE_POINT_COUNT);\n    \n    int idxOffset = int(t*n);\n    vec4 p1 = SPLINE_PointArray(idxOffset,ctrlPts);\n    vec4 p2 = SPLINE_PointArray(idxOffset+1,ctrlPts);\n    vec4 p3 = SPLINE_PointArray(idxOffset+2,ctrlPts);\n    vec4 p4 = SPLINE_PointArray(idxOffset+3,ctrlPts);\n    \n    \/\/For some reason, fract(t) returns garbage on my machine with small values of t.\n    \/\/return fract(n*t);\n    \/\/Using this below yields the same results, minus the glitches.\n    t *= n;\n    t = (t-float(int(t)));\n    \n    \/\/A classic catmull-rom\n    \/\/e.g.\n    \/\/http:\/\/steve.hollasch.net\/cgindex\/curves\/catmull-rom.html\n    \/\/http:\/\/www.lighthouse3d.com\/tutorials\/maths\/catmull-rom-spline\/\n    vec4 val = 0.5 * ((-p1 + 3.*p2 -3.*p3 + p4)*t*t*t\n               + (2.*p1 -5.*p2 + 4.*p3 - p4)*t*t\n               + (-p1+p3)*t\n               + 2.*p2);\n    return val;\n}\n\nvoid ANIM_main(float fTime)\n{\n    float t1 = 0.010*fTime;\n    float t2 = 0.010*fTime+0.03;\n    \n    SPLINE_CtrlPts cameraPosKeyFrames; \/\/100 sec cycle.\n    \/\/                    DATA: PosX,PosY,PosZ,Tilt\n    cameraPosKeyFrames.p[1] = vec4(10.0,2.70,05.0,1.90); \/\/t=00.0s\n    cameraPosKeyFrames.p[2] = vec4(16.0,3.30,08.5,1.00); \/\/t=12.5s\n    cameraPosKeyFrames.p[3] = vec4(20.0,6.80,05.0,2.97); \/\/t=25.0s\n    cameraPosKeyFrames.p[4] = vec4(40.0,3.40,17.5,0.82); \/\/t=37.5s\n    cameraPosKeyFrames.p[5] = vec4(30.0,3.10,27.5,1.97); \/\/t=50.0s\n    cameraPosKeyFrames.p[6] = vec4(25.0,3.20,22.5,1.93); \/\/t=62.5s\n    cameraPosKeyFrames.p[7] = vec4(15.0,3.00,24.5,1.95); \/\/t=75.0s\n    cameraPosKeyFrames.p[0] = vec4(05.0,2.80,12.5,1.20); \/\/t=87.5s\n    vec4 cameraPos = SPLINE_catmullRom(t1,cameraPosKeyFrames);\n    vec4 cameraDir = normalize(SPLINE_catmullRom(t2,cameraPosKeyFrames)-cameraPos);\n        \n    SPLINE_CtrlPts geometryKeyFrames; \/\/25 sec cycle.\n    \/\/                      DATA: round,width,roughness,displacement\n\tgeometryKeyFrames.p[1] = vec4(0.070,1.000,0.30,1.000); \/\/t=00.0s\n    geometryKeyFrames.p[2] = vec4(0.090,0.900,0.50,0.900); \/\/t=01.25s\n    geometryKeyFrames.p[3] = vec4(0.080,1.000,0.20,1.000); \/\/t=02.50s\n    geometryKeyFrames.p[4] = vec4(0.150,0.970,0.50,0.990); \/\/t=03.75s\n    geometryKeyFrames.p[5] = vec4(0.090,0.820,0.50,0.820); \/\/t=05.00s\n    geometryKeyFrames.p[6] = vec4(0.110,0.970,0.50,0.990); \/\/t=06.25s\n    geometryKeyFrames.p[7] = vec4(0.050,0.930,0.50,0.930); \/\/t=07.50s\n    geometryKeyFrames.p[0] = vec4(0.120,0.950,0.50,0.980); \/\/t=08.75s\n    vec4 geoPose = SPLINE_catmullRom(t1*25.0,geometryKeyFrames);\n    \n    g_animationChannels.camPos    = cameraPos.xyz;\n    g_animationChannels.camLookAt = cameraPos.xyz+cameraDir.xyz-vec3(0,cameraPos.w,0);\n    g_animationChannels.geometry_smoothness = geoPose[0];\n    g_animationChannels.material_roughness = 0.45;\n    g_animationChannels.geometry_width = geoPose[1];\n    g_animationChannels.geometry_displacement = GEOMETRY_DISPLACEMENT;\n}\n\nvec3 TRACE_main( vec3 o, vec3 dir, vec2 uv)\n{ \n    float fRemainingAlpha = 1.0;\n    float zStart = TRACE_zprime(o, dir);\n    vec3 pt = o+dir*zStart;\n    vec3 ptGeo = vec3(0);\n    \n    TraceData geometryTraceData;\n    if(zStart< MAX_DIST)\n    {\n        geometryTraceData = TRACE_geometry(pt, dir);\n        geometryTraceData.rayLen += zStart;\n        ptGeo = o+dir*geometryTraceData.rayLen;\n    }\n    else\n    {\n        geometryTraceData.rayLen     = MAX_DIST;\n    \tgeometryTraceData.matID      = MATERIALID_SKY;\n    \tgeometryTraceData.objectPos  = pt;\n    \tgeometryTraceData.geoDist    = 0.0;\n    \tgeometryTraceData.rayDir     = dir;\n        ptGeo = pt;\n    }\n    \n    \/\/return TRACE_debug(geometryTraceData, DEBUG_RAYLEN);  \/\/OK\n    \/\/return TRACE_debug(geometryTraceData, DEBUG_GEODIST); \/\/OK\n    \/\/return TRACE_debug(geometryTraceData, DEBUG_NORMAL);  \/\/OK\n    \/\/return TRACE_debug(geometryTraceData, DEBUG_MATID);   \/\/OK\n    \n    vec4 cFinal = MAT_apply(ptGeo,geometryTraceData);\n        \n    return cFinal.rgb;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    g_time = iTime+2.6; \/\/Time offset for better preview\n    vec2 uv = (fragCoord.xy-0.5*iResolution.xy) \/ iResolution.xx;\n    \n    float fTime = g_time+2.1;\n    ANIM_main(fTime);\n    \n    Cam cam = CAM_animate(uv,fTime);\n    vec3 d = CAM_getRay(cam,uv);\n    vec3 c = TRACE_main(cam.o, d, uv);\n    \n    \/\/No supersampling required for most PostProcessFX.\n    c = POST_ProcessFX(c,uv);\n    \n    fragColor = vec4(c,1.0);\n}\n\nvec3 POST_ProcessFX(vec3 c, vec2 uv)\n{\n    \/\/Vignetting\n    float lensRadius = 0.65;\n    uv \/= lensRadius;\n    float sin2 = uv.x*uv.x+uv.y*uv.y;\n    float cos2 = 1.0-min(sin2*sin2,1.0);\n    float cos4 = cos2*cos2;\n    c *= cos4;\n    \n    \/\/Gamma\n    c = pow(c,vec3(0.4545));\n    return c;\n}\n\n\/\/----------------------\n\/\/ Camera\n\/\/::CAM\nCam CAM_animate(vec2 uv, float fTime)\n{\n    Cam cam;\n    cam.o = g_animationChannels.camPos;\n    cam.D = normalize(g_animationChannels.camLookAt-cam.o);\n\tcam.R = normalize(cross(cam.D,vec3(0,1,0)));\n    cam.U = normalize(cross(cam.R,cam.D));\n    cam.lens = 1.2+0.3*sin(fTime*0.1);\n    cam.zoom = 3.0+sin(fTime*0.1)\/cam.lens;\n\treturn cam;\n}\n\nvec3 CAM_getRay(Cam cam,vec2 uv)\n{\n    uv = cam.lens*uv\/(cam.lens-length(uv)*length(uv));\n    uv *= cam.zoom;\n    return normalize(uv.x*cam.R+uv.y*cam.U+cam.D);\n}","name":"Image","description":"","type":"image"}]},{"ver":"0.1","info":{"id":"ld3SRr","date":"1457308996","viewed":8983,"name":"Image Based PBR Material","username":"Bers","description":"Importance sampling is used, since no cubemap mipmap available for blurry reflections. Cubemap sampling was HDR-ized and gamma balanced.","likes":184,"published":3,"flags":32,"usePreview":0,"tags":[]},"renderpass":[{"inputs":[{"id":"XsfGzn","filepath":"\/media\/a\/585f9546c092f53ded45332b343144396c0b2d70d9965f585ebc172080d8aa58.jpg","previewfilepath":"\/media\/ap\/585f9546c092f53ded45332b343144396c0b2d70d9965f585ebc172080d8aa58.jpg","type":"cubemap","channel":2,"sampler":{"filter":"mipmap","wrap":"clamp","vflip":"false","srgb":"false","internal":"byte"},"published":1},{"id":"4sfGzn","filepath":"\/media\/a\/793a105653fbdadabdc1325ca08675e1ce48ae5f12e37973829c87bea4be3232.png","previewfilepath":"\/media\/ap\/793a105653fbdadabdc1325ca08675e1ce48ae5f12e37973829c87bea4be3232.png","type":"cubemap","channel":3,"sampler":{"filter":"mipmap","wrap":"clamp","vflip":"false","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"\/media\/previz\/buffer00.png","previewfilepath":"\/media\/previz\/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"XsXGR8","filepath":"\/media\/previz\/buffer01.png","previewfilepath":"\/media\/previz\/buffer01.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"\/\/ Author : S\u00c3\u00a9bastien B\u00c3\u00a9rub\u00c3\u00a9\n\/\/ Created : Dec 2015\n\/\/ Modified : Jan 2016\n\/\/\n\/\/ A ShaderToy implementation of Image Based PBR Material.\n\/\/ I struggled quite a bit with the TextureCubes available :\n\/\/ \t\t-One is gamma corrected, the other is not.\n\/\/      -The skylight boundary between low and the high detail Cubemaps won't align\n\/\/       with each other, unless the sky color value is cranked up very much where saturated.\n\/\/       With the Cubemaps \"HDR remapped\", they finally aligned properly.\n\/\/       \n\/\/ Importance Sampling is used, where mipmaps would usually be used in a game engine (much more efficient).\n\/\/ I ended up using a mix between random samples and a fixed sampling pattern.\n\/\/ Random sampling was too jittery, unless a very high sample count was used.\n\/\/\n\/\/ Platic Materials lack a diffuse base. I have a WIP coming for this. It requires another cubemap lightness\n\/\/ hemisphere integration, for the diffuse part. Should be done in a seperate pass, not to kill the framerate.\n\/\/\n\/\/ Regarding the IBL version of the PBR Equation, I also struggled to balance lighting. Most articles\n\/\/ and code examples are about point lights, and some pieces of code I found could not be used in the \n\/\/ IBL Scenario. A popular version of the geometric term as proposed by Disney, for example, has a modified \"k\" value \n\/\/ to \"reduce hotness\", which don't give good results with IBL (edges reflections, at grazing angles, would be\n\/\/ too dark, see Unreal4 2013SiggraphPresentationsNotes pdf link p.3 below).\n\/\/ Also, GGX Distribution term must not be used with IBL, because 1) it will look like garbage and 2)it makes no\n\/\/ sense (for \"perfect\" reflection angles (H==N), GGX value goes to the stratosphere, which you really don't want\n\/\/ with IBL). Energy conservation problems don't show as much with point lights, but they really do with Image Based\n\/\/ Lighting.\n\/\/\n\/\/ HDR Color was choosen arbitrarily. You can change from red to blue using the second rightmost slider.\n\/\/ \n\/\/ Sources:\n\/\/ https:\/\/de45xmedrsdbp.cloudfront.net\/Resources\/files\/2013SiggraphPresentationsNotes-26915738.pdf\n\/\/ https:\/\/seblagarde.wordpress.com\/2011\/08\/17\/feeding-a-physical-based-lighting-mode\/\n\/\/ http:\/\/blog.selfshadow.com\/publications\/s2012-shading-course\/burley\/s2012_pbs_disney_brdf_slides_v2.pdf\n\/\/ https:\/\/www.youtube.com\/watch?v=LP7HgIMv4Qo [impressive realtime materials with Substance, see 16m00s, 25m00s]\n\/\/ http:\/\/sirkan.iit.bme.hu\/~szirmay\/fresnel.pdf\n\/\/ http:\/\/www.codinglabs.net\/article_physically_based_rendering_cook_torrance.aspx\n\/\/ http:\/\/refractiveindex.info\/?shelf=3d&book=liquids&page=water\n\/\/ http:\/\/www.filmetrics.com\/refractive-index-database\/Al\/Aluminium\n\/\/ https:\/\/www.shadertoy.com\/view\/4djSRW Dave Hoskin's hash without sine\n\/\/\n\/\/ License : Creative Commons Non-commercial (NC) license\n\/\/\n\n\/\/----------------------\n\/\/ Constants \nconst float GEO_MAX_DIST   = 50.0;\nconst int MATERIALID_SKY    = 2;\nconst int MATERIALID_SPHERE = 3;\nconst vec3  F_ALU_N  = vec3(1.600,0.912,0.695); \/\/(Red ~ 670 nm; Green ~ 540 nm; Blue ~ 475 nm)\nconst vec3  F_ALU_K  = vec3(8.010,6.500,5.800); \/\/(Red ~ 670 nm; Green ~ 540 nm; Blue ~ 475 nm)\n\n\/\/----------------------\n\/\/ Slider bound globals. Use the slider, don't change the value here.\nfloat ROUGHNESS_AMOUNT       = 0.85;\/\/Valid range : [0-1] 0=shiny, 1=rough map\nfloat SKY_COLOR              = 0.0; \/\/[0.0=Red, 1.0=Blue)\nfloat ABL_LIGHT_CONTRIBUTION = 0.0; \/\/[0-1] Additional ABL Light Contribution\n\n#define saturate(x) clamp(x,0.0,1.0)\n\n\/\/PBR Equation for both (IBL) or (ABL), plastic or metal.\nvec3 PBR_Equation(vec3 V, vec3 L, vec3 N, float roughness, const vec3 ior_n, const vec3 ior_k, const bool metallic, const bool bIBL)\n{\n    float cosT = saturate( dot(L, N) );\n    float sinT = sqrt( 1.0 - cosT * cosT);\n\tvec3 H = normalize(L+V);\n\tfloat NdotH = dot(N,H);\/\/Nn.H;\n\tfloat NdotL = dot(N,L);\/\/Nn.Ln;\n\tfloat VdotH = dot(V,H);\/\/Vn.H;\n    float NdotV = dot(N,V);\/\/Nn.Vn;\n    \n    \/\/Distribution Term\n    float PI = 3.14159;\n    float alpha2 = roughness * roughness;\n    float NoH2 = NdotH * NdotH;\n    float den = NoH2*(alpha2-1.0)+1.0;\n    float D = 1.0; \/\/Distribution term is externalized from IBL version\n    if(!bIBL)\n        D = (NdotH>0.)?alpha2\/(PI*den*den):0.0; \/\/GGX Distribution.\n\t\n    \/\/Fresnel Term\n\tvec3 F;\n    if(metallic)\n    {\n        float cos_theta = 1.0-NdotV;\n        F =  ((ior_n-1.)*(ior_n-1.)+ior_k*ior_k+4.*ior_n*pow(1.-cos_theta,5.))\n\t\t    \/((ior_n+1.)*(ior_n+1.)+ior_k*ior_k);\n    }\n    else \/\/Dielectric (Note: R\/G\/B do not really differ for dielectric materials)\n    {\n        float F0 = pow((1.0 - ior_n.x) \/ (1.0 + ior_n.x),2.0);\n  \t\tF = vec3(F0 + (1.-F0) * pow( 1. - VdotH, 5.));\n    }\n    \n    \/\/Geometric term (Source: Real Shading in Unreal Engine 4 2013 Siggraph Presentation p.3\/59)\n    \/\/k = Schlick model (IBL) : Disney's modification to reduce hotness (point light)\n    float k = bIBL?(roughness*roughness\/2.0):(roughness+1.)*(roughness+1.)\/8.; \n    float Gl = max(NdotL,0.)\/(NdotL*(1.0-k)+k);\n    float Gv = max(NdotV,0.)\/(NdotV*(1.0-k)+k);\n    float G = Gl*Gv;\n    \n    float softTr = 0.1; \/\/ Valid range : [0.001-0.25]. Transition softness factor, close from dot(L,N) ~= 0\n    float angleLim = 0.;\/\/2.75; \/\/ Valid range : [0-0.75]. Compensates for IBL integration suface size.\n    \/\/sinT = 1.;\n    if(bIBL)\n        return (F*G*(angleLim+sinT)\/(angleLim+1.0) \/ (4.*NdotV*saturate(NdotH)*(1.0-softTr)+softTr));\n    else\n        return D*F*G \/ (4.*NdotV*NdotL*(1.0-softTr)+softTr);\n}\n\nvec3 PBR_HDRremap(vec3 c)\n{\n    float fHDR = smoothstep(2.900,3.0,c.x+c.y+c.z);\n    vec3 cRedSky   = mix(c,1.3*vec3(4.5,2.5,2.0),fHDR);\n    vec3 cBlueSky  = mix(c,1.8*vec3(2.0,2.5,3.0),fHDR);\n    return mix(cRedSky,cBlueSky,SKY_COLOR);\n}\n\nvec3 PBR_HDRCubemap(vec3 sampleDir, float LOD_01)\n{\n    vec3 linearGammaColor_sharp = PBR_HDRremap(pow(texture( iChannel2, sampleDir ).rgb,vec3(2.2)));\n    vec3 linearGammaColor_blur  = PBR_HDRremap(pow(texture( iChannel3, sampleDir ).rgb,vec3(1)));\n    vec3 linearGammaColor = mix(linearGammaColor_sharp,linearGammaColor_blur,saturate(LOD_01));\n    return linearGammaColor;\n}\n\n\/\/Arbitrary axis rotation (around u, normalized)\nmat3 PBR_axisRotationMatrix( vec3 u, float ct, float st ) \/\/u=axis, co=cos(t), st=sin(t)\n{\n    return mat3(  ct+u.x*u.x*(1.-ct),     u.x*u.y*(1.-ct)-u.z*st, u.x*u.z*(1.-ct)+u.y*st,\n\t              u.y*u.x*(1.-ct)+u.z*st, ct+u.y*u.y*(1.-ct),     u.y*u.z*(1.-ct)-u.x*st,\n\t              u.z*u.x*(1.-ct)-u.y*st, u.z*u.y*(1.-ct)+u.x*st, ct+u.z*u.z*(1.-ct) );\n}\n\nvec3 PBR_importanceSampling(vec3 sampleDir, float roughness, float e1, float e2, out float range)\n{\n    const float PI = 3.14159;\n    range = atan( roughness*sqrt(e1)\/sqrt(1.0-e1) );\n    float phi = 2.0*PI*e2;\n    \/\/Improve this? https:\/\/blog.selfshadow.com\/2011\/10\/17\/perp-vectors\/\n    vec3 notColinear   = (abs(sampleDir.y)<0.8)?vec3(0,1,0):vec3(1,0,0);\n    vec3 othogonalAxis = normalize(cross(notColinear,sampleDir));\n\tmat3 m1 = PBR_axisRotationMatrix(normalize(othogonalAxis), cos(range), sin(range));\n\tmat3 m2 = PBR_axisRotationMatrix(normalize(sampleDir),     cos(phi),   sin(phi));\n\treturn sampleDir*m1*m2;\n}\n\nvec3 PBR_visitSamples(vec3 V, vec3 N, float roughness, bool metallic, vec3 ior_n, vec3 ior_k )\n{\n    const float MIPMAP_SWITCH  = 0.29; \/\/sampling angle delta (rad) equivalent to the lowest LOD.\n    const ivec2 SAMPLE_COUNT = ivec2(05,15); \/\/(5 random, 15 fixed) samples\n    const vec2 weight = vec2(1.\/float(SAMPLE_COUNT.x),1.\/float(SAMPLE_COUNT.y));\n    float angularRange = 0.;    \n    vec3 vCenter = reflect(-V,N);\n    \n    \/\/Randomized Samples : more realistic, but jittery\n    float randomness_range = 0.75; \/\/Cover only the closest 75% of the distribution. Reduces range, but improves stability.\n    float fIdx = 0.0;              \/\/valid range = [0.5-1.0]. Note : it is physically correct at 1.0.\n    vec3 totalRandom = vec3(0.0);\n    for(int i=0; i < SAMPLE_COUNT[0]; ++i)\n    {\n        \/\/Random noise from DaveHoskin's hash without sine : https:\/\/www.shadertoy.com\/view\/4djSRW\n        vec3 p3 = fract(vec3(fIdx*10.0+vCenter.xyx*100.0) * vec3(.1031,.11369,.13787)); \n    \tp3 += dot(p3.zxy, p3.yzx+19.19);\n    \tvec2 jitter = fract(vec2((p3.x + p3.y)*p3.z, (p3.x+p3.z)*p3.y));\n        vec3 sampleDir    = PBR_importanceSampling(vCenter, roughness, jitter.x*randomness_range, jitter.y, angularRange);\n        vec3 sampleColor  = PBR_HDRCubemap( sampleDir, angularRange\/MIPMAP_SWITCH);\n        vec3 contribution = PBR_Equation(V, sampleDir, N, roughness, ior_n, ior_k, metallic, true)*weight[0];\n    \ttotalRandom += contribution*sampleColor;\n\t\t++fIdx;\n    }\n    \n    \/\/Fixed Samples : More stable, but can create sampling pattern artifacts (revealing the sampling pattern)\n    fIdx = 0.0;\n    vec3 totalFixed = vec3(0.0);\n    for(int i=0; i < SAMPLE_COUNT[1]; ++i)\n    {\n        vec2 jitter = vec2( clamp(weight[1]*fIdx,0.0,0.50), fract(weight[1]*fIdx*1.25)+3.14*fIdx); \/\/Fixed sampling pattern.\n        vec3 sampleDir    = PBR_importanceSampling(vCenter, roughness, jitter.x, jitter.y, angularRange);\n        vec3 sampleColor  = PBR_HDRCubemap( sampleDir, angularRange\/MIPMAP_SWITCH);\n        vec3 contribution = PBR_Equation(V, sampleDir, N, roughness, ior_n, ior_k, metallic, true)*weight[1];\n        totalFixed += contribution*sampleColor;\n\t\t++fIdx;\n    }\n    \n    return (totalRandom*weight[1]+totalFixed*weight[0])\/(weight[0]+weight[1]);\n}\n\nvec4 MAT_triplanarTexturing(vec3 p, vec3 n)\n{\n    p = fract(p+0.5);\n    \n    float sw = 0.20; \/\/stiching width\n    vec3 stitchingFade = vec3(1.)-smoothstep(vec3(0.5-sw),vec3(0.5),abs(p-0.5));\n    \n    float fTotal = abs(n.x)+abs(n.y)+abs(n.z);\n    vec4 cX = abs(n.x)*texture(iChannel1,p.zy);\n    vec4 cY = abs(n.y)*texture(iChannel1,p.xz);\n    vec4 cZ = abs(n.z)*texture(iChannel1,p.xy);\n    \n    return  vec4(stitchingFade.y*stitchingFade.z*cX.rgb\n                +stitchingFade.x*stitchingFade.z*cY.rgb\n                +stitchingFade.x*stitchingFade.y*cZ.rgb,cX.a+cY.a+cZ.a)\/fTotal;\n}\n\nstruct TraceData\n{\n    float rayLen; \/\/Run Distance\n    vec3  rayDir; \/\/Run Direction\n    vec3  normal; \/\/Hit normal\n    int   matID;  \/\/Hit material ID\n};\n\n\/\/The main material function.\nvec3 MAT_apply(vec3 pos, TraceData traceData)\n{\n    \/\/Roughness texture\n    vec4 roughnessBuffer = MAT_triplanarTexturing(pos*1.5,traceData.normal);\n    roughnessBuffer += MAT_triplanarTexturing(pos*1.5+0.75,traceData.normal);\n    float roughness = (roughnessBuffer.x+roughnessBuffer.y+roughnessBuffer.z)\/3.0;\n    roughness = roughnessBuffer.w+saturate(roughness-1.00+ROUGHNESS_AMOUNT)*0.25;\n    \n    \/\/IBL and ABL PBR Lighting\n    vec3 rd  = traceData.rayDir;\n    vec3 V = normalize(-traceData.rayDir);\n    vec3 N = traceData.normal;\n    vec3 L = normalize(vec3(1,1,0));\n    vec3 col = PBR_visitSamples(V,N,roughness, true, F_ALU_N, F_ALU_K);\n    vec3 L0  = PBR_Equation(V,L,N,roughness+0.01, F_ALU_N, F_ALU_K, true, false);\n    col     += PBR_HDRremap(vec3(1))*L0*ABL_LIGHT_CONTRIBUTION;\n    \n    \/\/Anti-aliasing trick (normal-based)\n    vec3 backgroundColor = pow(texture( iChannel2, traceData.rayDir ).xyz,vec3(2.2));\n    float aaAmount = 0.095;\n    float smoothFactor = 1.0-clamp(-dot(N,traceData.rayDir)\/(aaAmount), 0.0, 1.0);\n    col = (dot(N,-traceData.rayDir)<aaAmount)? mix(col, backgroundColor, smoothFactor) : col;\n    \n    return traceData.matID==MATERIALID_SKY?backgroundColor:col;\n}\n\nfloat map( in vec3 pos )\n{\n    const float GEO_SPHERE_RAD = 0.5;\n    return length(pos)-GEO_SPHERE_RAD;\n}\n\n\/\/o=ray origin, d=ray direction\nTraceData TRACE_geometry(vec3 o, vec3 d)\n{\n    float t = 0.0;\n    float tmax = GEO_MAX_DIST;\n    float dist = GEO_MAX_DIST;\n    for( int i=0; i<50; i++ )\n    {\n\t    dist = map( o+d*t );\n        if( abs(dist)<0.001 || t>GEO_MAX_DIST ) break;\n        t += dist;\n    }\n    \n    vec3 dfHitPosition  = o+t*d;\n    bool bBackground = (dist>0.01 || t>GEO_MAX_DIST);\n    \n    return TraceData(t,d,normalize(dfHitPosition),bBackground?MATERIALID_SKY:MATERIALID_SPHERE);\n}\n\nvec4 processSliders(in vec2 fragCoord)\n{\n    vec4 sliderVal = texture(iChannel0,vec2(0,0));\n\tROUGHNESS_AMOUNT        = sliderVal[1];\n    SKY_COLOR               = sliderVal[2];\n    ABL_LIGHT_CONTRIBUTION  = sliderVal[3];\n    \n    if(length(fragCoord.xy-vec2(0,0))>1.)\n    {\n    \treturn texture(iChannel0,fragCoord.xy\/iResolution.xy);\n    }\n    return vec4(0);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    \/\/Camera & setup\n    vec4 cSlider = processSliders(fragCoord);\n    float rotX = ((iMouse.z>0.)&&any(lessThan(iMouse.xy\/iResolution.xy,vec2(0.9,0.80))))?\n\t             ((iMouse.x\/iResolution.x)*2.0*3.14) : (iTime*0.3);\n    vec2 uv = 2.5*(fragCoord.xy-0.5*iResolution.xy) \/ iResolution.xx;\n    vec3 camO = vec3(cos(rotX),0.4,sin(rotX))*0.95;\n    vec3 camD = normalize(vec3(0)-camO);\n    vec3 camR = normalize(cross(camD,vec3(0,1,0)));\n    vec3 camU = cross(camR,camD);\n   \tvec3 dir =  normalize(uv.x*camR+uv.y*camU+camD);\n    \n    \/\/Raytrace\n    TraceData geometryTraceData = TRACE_geometry(camO, dir);\n    vec3 ptGeo = (geometryTraceData.rayLen < GEO_MAX_DIST)? camO+dir*geometryTraceData.rayLen : vec3(0);\n    \n    \/\/Material\n    vec3 c = MAT_apply(ptGeo,geometryTraceData).xyz;\n    \n    \/\/Post-processing\n    float sin2 = dot(uv\/1.6,uv\/1.6);\n    float vignetting = pow(1.0-min(sin2*sin2,1.0),2.);\n    c = pow(c*vignetting,vec3(0.4545)); \/\/2.2 Gamma compensation\n    \n    \/\/Slider overlay\n    fragColor = vec4(mix(c,cSlider.rgb,cSlider.a),1.0);\n}","name":"Image","description":"","type":"image"},{"inputs":[{"id":"4dXGR8","filepath":"\/media\/previz\/buffer00.png","previewfilepath":"\/media\/previz\/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"\/\/ Buffer A : Sliders\n\/\/\n\/\/ Author : S\u00c3\u00a9bastien B\u00c3\u00a9rub\u00c3\u00a9\n\/\/ Created : Dec 2015\n\/\/ Modified : Mar 2016\n#define saturate(x) clamp(x,0.0,1.0)\nvec4 sliderVal = vec4(0.30,0.75,0.0,0.10); \/\/Default slider values [0-1]\n\nvoid SLIDER_setValue(float idx, float val)\n{\n    if(idx<0.) return;\n    else if(idx<0.25) sliderVal[0] = saturate(val);\n\telse if(idx<0.50) sliderVal[1] = saturate(val);\n\telse if(idx<0.75) sliderVal[2] = saturate(val);\n\telse if(idx<1.00) sliderVal[3] = saturate(val);\n}\n\nfloat SLIDER_getValue(float idx)\n{\n    if     (idx<0.25) return sliderVal[0];\n    else if(idx<0.50) return sliderVal[1];\n    else if(idx<0.75) return sliderVal[2];\n    else if(idx<1.00) return sliderVal[3];\n\telse return 0.;\n}\n\nvoid SLIDER_init(vec2 mousePos, vec2 cMin, vec2 cMax )\n{\n    vec4 cPingPong = texture(iChannel0,vec2(0));\n    if(length(cPingPong)>0.001)\n        sliderVal = cPingPong;\n        \n    float width = cMax.x-cMin.x;\n    float height = cMax.y-cMin.y;\n    if(mousePos.x>cMin.x && mousePos.x<cMax.x &&\n       mousePos.y>cMin.y && mousePos.y<cMax.y )\n    {\n        float t = (mousePos.y-cMin.y)\/height;\n        t = clamp(t\/0.75-0.125,0.,1.); \/\/25% top\/bottom margins\n\t\tSLIDER_setValue((mousePos.x-cMin.x)\/width, t);\n    }\n}\n\n\/\/Returns the distance from point \"p\" to a given line segment defined by 2 points [a,b]\nfloat UTIL_distanceToLineSeg(vec2 p, vec2 a, vec2 b)\n{\n    \/\/       p\n    \/\/      \/\n    \/\/     \/\n    \/\/    a--e-------b\n    vec2 ap = p-a;\n    vec2 ab = b-a;\n    \/\/Scalar projection of ap in the ab direction = dot(ap,ab)\/|ab| : Amount of ap aligned towards ab\n    \/\/Divided by |ab| again, it becomes normalized along ab length : dot(ap,ab)\/(|ab||ab|) = dot(ap,ab)\/dot(ab,ab)\n    \/\/The clamp provides the line seg limits. e is therefore the \"capped orthogogal projection\", and length(p-e) is dist.\n    vec2 e = a+clamp(dot(ap,ab)\/dot(ab,ab),0.0,1.0)*ab;\n    return length(p-e);\n}\n\n\/\/uv = slider pixel in local space [0-1], t = slider value [0-1], ar = aspect ratio (w\/h)\nvec4 SLIDER_drawSingle(vec2 uv, float t, vec2 ar, bool bHighlighted)\n{\n    const vec3  ITEM_COLOR = vec3(1);\n    const vec3  HIGHLIGHT_COLOR = vec3(0.2,0.7,0.8);\n    const float RAD = 0.05;  \/\/Cursor radius, in local space\n    const float LW  = 0.030; \/\/Line width\n    float aa  = 14.\/iResolution.x; \/\/antialiasing width (smooth transition)\n    vec3 selectionColor = bHighlighted?HIGHLIGHT_COLOR:ITEM_COLOR;\n    vec3 cheapGloss   = 0.8*selectionColor+0.2*smoothstep(-aa,aa,uv.y-t-0.01+0.01*sin(uv.x*12.));\n    vec2 bottomCenter = vec2(0.5,0.0);\n\tvec2 topCenter    = vec2(0.5,1.0);\n    vec2 cursorPos    = vec2(0.5,t);\n    float distBar = UTIL_distanceToLineSeg(uv*ar, bottomCenter*ar, topCenter*ar);\n    float distCur = length((uv-cursorPos)*ar)-RAD;\n    float alphaBar = 1.0-smoothstep(2.0*LW-aa,2.0*LW+aa, distBar);\n    float alphaCur = 1.0-smoothstep(2.0*LW-aa,2.0*LW+aa, distCur);\n    vec4  colorBar = vec4(mix(   vec3(1),vec3(0),smoothstep(LW-aa,LW+aa, distBar)),alphaBar);\n    vec4  colorCur = vec4(mix(cheapGloss,vec3(0),smoothstep(LW-aa,LW+aa, distCur)),alphaCur);\n    return mix(colorBar,colorCur,colorCur.a);\n}\n\n#define withinUnitRect(a) (a.x>=0. && a.x<=1. && a.y>=0. && a.y<=1.0)\nvec4 SLIDER_drawAll(vec2 uv, vec2 cMin, vec2 cMax, vec2 muv)\n{\n    float width = cMax.x-cMin.x;\n    float height = cMax.y-cMin.y;\n    vec2 ar = vec2(0.30,1.0);\n    uv  = (uv -cMin)\/vec2(width,height); \/\/pixel Normalization\n    muv = (muv-cMin)\/vec2(width,height); \/\/mouse Normalization\n    if( withinUnitRect(uv) )\n    {\n        float t = SLIDER_getValue(uv.x);\n\t\tbool bHighlight = withinUnitRect(muv) && abs(floor(uv.x*4.0)-floor(muv.x*4.0))<0.01;\n\t\tuv.x = fract(uv.x*4.0); \/\/repeat 4x\n\t\tuv.y = uv.y\/0.75-0.125; \/\/25% margins\n        return SLIDER_drawSingle(uv,t,ar,bHighlight);\n    }\n    return vec4(0);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 cMinSliders = vec2(0.9,0.80);\n    vec2 cMaxSliders = vec2(1.0,1.00);\n    vec2 uvSliders = fragCoord.xy \/ iResolution.xy;\n    vec2 mousePos = iMouse.xy \/ iResolution.xy;\n    SLIDER_init(mousePos, cMinSliders, cMaxSliders);\n    vec4 cSlider = SLIDER_drawAll(uvSliders,cMinSliders, cMaxSliders, mousePos);\n    \n    if(length(fragCoord.xy-vec2(0,0))<1.) \n        fragColor = sliderVal;\n\telse fragColor = cSlider;\n}","name":"Buffer A","description":"","type":"buffer"},{"inputs":[{"id":"XdXGzn","filepath":"\/media\/a\/3083c722c0c738cad0f468383167a0d246f91af2bfa373e9c5c094fb8c8413e0.png","previewfilepath":"\/media\/ap\/3083c722c0c738cad0f468383167a0d246f91af2bfa373e9c5c094fb8c8413e0.png","type":"texture","channel":1,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"Xsf3zn","filepath":"\/media\/a\/f735bee5b64ef98879dc618b016ecf7939a5756040c2cde21ccb15e69a6e1cfb.png","previewfilepath":"\/media\/ap\/f735bee5b64ef98879dc618b016ecf7939a5756040c2cde21ccb15e69a6e1cfb.png","type":"texture","channel":2,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"false","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"\/media\/previz\/buffer00.png","previewfilepath":"\/media\/previz\/buffer00.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"XsXGR8","channel":0}],"code":"\/\/ Buffer B : Material Roughness map\n\/\/\n\/\/ Author : S\u00c3\u00a9bastien B\u00c3\u00a9rub\u00c3\u00a9\n\/\/\n\/\/ This is just noise, you could implement whatever roughness map you want.\n\/\/ This needs some clean-up, as it was originally coded as 3D noise, but only a 2D slice is used here.\n\n#define saturate(x) clamp(x,0.0,1.0)\nfloat UTIL_distanceToLineSeg(vec2 p, vec2 a, vec2 b)\n{\n    \/\/Scalar projection of ap in the ab direction = dot(ap,ab)\/|ab| : Amount of ap aligned towards ab\n    \/\/Divided by |ab| again, it becomes normalized along ab length : dot(ap,ab)\/(|ab||ab|) = dot(ap,ab)\/dot(ab,ab)\n    \/\/The clamp provides the line seg limits. e is therefore the \"capped orthogogal projection\".\n    \/\/       p\n    \/\/      \/\n    \/\/     \/\n    \/\/    a--e-------b\n    vec2 ap = p-a;\n    vec2 ab = b-a;\n    vec2 e = a+clamp(dot(ap,ab)\/dot(ab,ab),0.0,1.0)*ab;\n    return length(p-e);\n}\nvec2 noise(vec2 p)\n{\n    return texture(iChannel1,p,-100.0).xy;\n}\nstruct repeatInfo\n{\n\tvec2 pRepeated;\n    vec2 anchor;\n};\nrepeatInfo UTIL_repeat(vec2 p, float interval)\n{\n    repeatInfo rInfo;\n    rInfo.pRepeated = p \/ interval; \/\/Normalize\n    rInfo.pRepeated = fract(rInfo.pRepeated+0.5)-0.5; \/\/centered fract\n    rInfo.pRepeated *= interval; \/\/Rescale\n    rInfo.anchor = p-rInfo.pRepeated;\n    return rInfo;\n}\nfloat MAT_scratchTexture(vec2 p)\n{\n    const float squareWidth = 0.10*2.0;\n    const float moveAmp   = squareWidth*0.75;\n    const float lineWidth = 0.0005;\n    float repeatInterval = squareWidth+moveAmp;\n    repeatInfo rInfo = UTIL_repeat(p,repeatInterval);\n    float margin = repeatInterval-squareWidth;\n    \n    vec2 a = moveAmp*noise(rInfo.anchor);\n    vec2 b = -moveAmp*noise(rInfo.anchor+10.0);\n    float dseg = 1000.0*UTIL_distanceToLineSeg(rInfo.pRepeated, a, b)\/squareWidth;\n    return saturate(10.0\/dseg-0.5)*0.25;\n}\n\nfloat MAT_layeredScratches(vec2 p)\n{\n    const mat2 m2 = mat2(0.8,-0.6,0.6,0.8);\n    float I = MAT_scratchTexture(p);\n    p = m2*p;\n    I += MAT_scratchTexture(p*1.11+2.0);\n    p = m2*p;\n    I += MAT_scratchTexture(p*1.24+3.8);\n    p = m2*p;\n    I += MAT_scratchTexture(p*1.34+5.3);\n    p = m2*p;\n    I += MAT_scratchTexture(p*1.34+5.3);\n    p = m2*p;\n    I += MAT_scratchTexture(p*1.34+5.3);\n        \n    return I;\n}\n\nfloat MAT_triplanarScratches(vec3 p, vec3 n)\n{\n    \/\/Idea from http:\/\/http.developer.nvidia.com\/GPUGems3\/gpugems3_ch01.html\n    \/\/Figure 1-23 Triplanar Texturing\n    float fTotal = abs(n.x)+abs(n.y)+abs(n.z);\n    return ( abs(n.x)*MAT_layeredScratches(p.zy)\n            +abs(n.y)*MAT_layeredScratches(p.xz)\n            +abs(n.z)*MAT_layeredScratches(p.xy))\/fTotal;\n}\n\nvec4 NOISE_trilinearWithDerivative(vec3 p)\n{\n    \/\/Trilinear extension over noise derivative from (Elevated), & using the noise stacking trick from (Clouds).\n\t\/\/Inspiration & Idea from :\n    \/\/https:\/\/www.shadertoy.com\/view\/MdX3Rr (Elevated)\n    \/\/https:\/\/www.shadertoy.com\/view\/XslGRr (Clouds)\n    \n    \/\/For more information, see also:\n    \/\/NoiseVolumeExplained : https:\/\/www.shadertoy.com\/view\/XsyGWz\n\t\/\/2DSignalDerivativeViewer : https:\/\/www.shadertoy.com\/view\/ldGGDR\n    \n    const float TEXTURE_RES = 256.0; \/\/Noise texture resolution\n    vec3 pixCoord = floor(p);\/\/Pixel coord, integer [0,1,2,3...256...]\n    \/\/noise volume stacking trick : g layer = r layer shifted by (37x17 pixels)\n    \/\/(37x17)-> this value is the actual translation embedded in the noise texture, can't get around it.\n\t\/\/Note : shift is different from g to b layer (but it also works)\n    vec2 layer_translation = -pixCoord.z*vec2(37.0,17.0)\/TEXTURE_RES; \n    \n    vec2 c1 = texture(iChannel2,layer_translation+(pixCoord.xy+vec2(0,0)+0.5)\/TEXTURE_RES,-100.0).rg;\n    vec2 c2 = texture(iChannel2,layer_translation+(pixCoord.xy+vec2(1,0)+0.5)\/TEXTURE_RES,-100.0).rg; \/\/+x\n    vec2 c3 = texture(iChannel2,layer_translation+(pixCoord.xy+vec2(0,1)+0.5)\/TEXTURE_RES,-100.0).rg; \/\/+z\n    vec2 c4 = texture(iChannel2,layer_translation+(pixCoord.xy+vec2(1,1)+0.5)\/TEXTURE_RES,-100.0).rg; \/\/+x+z\n    \n    vec3 x = p-pixCoord; \/\/Pixel interpolation position, linear range [0-1] (fractional part)\n    \n    vec3 x2 = x*x;\n    vec3 t = (6.*x2-15.0*x+10.)*x*x2; \/\/Quintic ease-in\/ease-out function.\n    vec3 d_xyz = (30.*x2-60.*x+30.)*x2; \/\/dt\/dx : Ease-in ease-out derivative.\n    \n    \/\/Lower quad corners\n    float a = c1.x; \/\/(x+0,y+0,z+0)\n    float b = c2.x; \/\/(x+1,y+0,z+0)\n    float c = c3.x; \/\/(x+0,y+1,z+0)\n    float d = c4.x; \/\/(x+1,y+1,z+0)\n    \n    \/\/Upper quad corners\n    float e = c1.y; \/\/(x+0,y+0,z+1)\n    float f = c2.y; \/\/(x+1,y+0,z+1)\n    float g = c3.y; \/\/(x+0,y+1,z+1)\n    float h = c4.y; \/\/(x+1,y+1,z+1)\n    \n    \/\/Trilinear noise interpolation : (1-t)*v1+(t)*v2, repeated along the 3 axis of the interpolation cube.\n    float za = ((a+(b-a)*t.x)*(1.-t.y)\n               +(c+(d-c)*t.x)*(   t.y));\n    float zb = ((e+(f-e)*t.x)*(1.-t.y)\n               +(g+(h-g)*t.x)*(   t.y));\n    float value = (1.-t.z)*za+t.z*zb;\n    \n    \/\/Derivative scaling (texture lookup slope, along interpolation cross sections).\n    \/\/This could be factorized\/optimized but I fear it would make it cryptic.\n    float sx =  ((b-a)+t.y*(a-b-c+d))*(1.-t.z)\n               +((f-e)+t.y*(e-f-g+h))*(   t.z);\n    float sy =  ((c-a)+t.x*(a-b-c+d))*(1.-t.z)\n               +((g-e)+t.x*(e-f-g+h))*(   t.z);\n    float sz =  zb-za;\n    \n    return vec4(value,d_xyz*vec3(sx,sy,sz));\n}\n\nfloat ROUGHNESS_MAP_UV_SCALE = 6.00;\/\/Valid range : [0.1-100.0]\n\n\/\/Stacked perlin noise\nvec3 NOISE_volumetricRoughnessMap(vec3 p, float rayLen)\n{\n    vec4 sliderVal = vec4(0.5,0.85,0,0.5);\n    ROUGHNESS_MAP_UV_SCALE *= 0.1*pow(10.,2.0*sliderVal[0]);\n    \n    float f = iTime;\n    const mat3 R1  = mat3(0.500, 0.000, -.866,\n\t                     0.000, 1.000, 0.000,\n                          .866, 0.000, 0.500);\n    const mat3 R2  = mat3(1.000, 0.000, 0.000,\n\t                      0.000, 0.500, -.866,\n                          0.000,  .866, 0.500);\n    const mat3 R = R1*R2;\n    p *= ROUGHNESS_MAP_UV_SCALE;\n    p = R1*p;\n    vec4 v1 = NOISE_trilinearWithDerivative(p);\n    p = R1*p*2.021;\n    vec4 v2 = NOISE_trilinearWithDerivative(p);\n    p = R1*p*2.021+1.204*v1.xyz;\n    vec4 v3 = NOISE_trilinearWithDerivative(p);\n    p = R1*p*2.021+0.704*v2.xyz;\n    vec4 v4 = NOISE_trilinearWithDerivative(p);\n    \n    return (v1\n\t      +0.5*(v2+0.25)\n\t      +0.4*(v3+0.25)\n\t      +0.6*(v4+0.25)).yzw;\n}\n\nvoid processSliders(in vec2 fragCoord)\n{\n    vec4 sliderVal = texture(iChannel0,vec2(0,0));\n\tROUGHNESS_MAP_UV_SCALE *= 0.1*pow(10.,2.0*sliderVal[0]);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    processSliders(fragCoord);\n    vec2 uv = 3.0*fragCoord.xy\/iResolution.xy;\n    vec3 roughnessNoise = NOISE_volumetricRoughnessMap(vec3(2.0*uv,0),1.0).rgb;\n    float scratchTex = MAT_scratchTexture(2.0*uv);\n    scratchTex += MAT_layeredScratches(uv+0.25);\n    scratchTex += MAT_layeredScratches(1.7*uv+vec2(0.35));\n    scratchTex += MAT_scratchTexture(uv+vec2(1.15));\n    scratchTex += MAT_scratchTexture(uv+vec2(2.75));\n    fragColor = vec4(roughnessNoise,scratchTex*0.3);\n}","name":"Buffer B","description":"","type":"buffer"}]},{"ver":"0.1","info":{"id":"ls3Szr","date":"1457322397","viewed":3327,"name":"Irradiance cubemap","username":"Bers","description":"Plastic PBR materials with irradiance cubemap progressively computed and folded in Buffer A Texture.","likes":60,"published":3,"flags":32,"usePreview":0,"tags":[]},"renderpass":[{"inputs":[{"id":"XsfGzn","filepath":"\/media\/a\/585f9546c092f53ded45332b343144396c0b2d70d9965f585ebc172080d8aa58.jpg","previewfilepath":"\/media\/ap\/585f9546c092f53ded45332b343144396c0b2d70d9965f585ebc172080d8aa58.jpg","type":"cubemap","channel":2,"sampler":{"filter":"mipmap","wrap":"clamp","vflip":"false","srgb":"false","internal":"byte"},"published":1},{"id":"4sfGzn","filepath":"\/media\/a\/793a105653fbdadabdc1325ca08675e1ce48ae5f12e37973829c87bea4be3232.png","previewfilepath":"\/media\/ap\/793a105653fbdadabdc1325ca08675e1ce48ae5f12e37973829c87bea4be3232.png","type":"cubemap","channel":3,"sampler":{"filter":"mipmap","wrap":"clamp","vflip":"false","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"\/media\/previz\/buffer00.png","previewfilepath":"\/media\/previz\/buffer00.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4sXGR8","filepath":"\/media\/previz\/buffer02.png","previewfilepath":"\/media\/previz\/buffer02.png","type":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"\/\/ Author : S\u00c3\u00a9bastien B\u00c3\u00a9rub\u00c3\u00a9\n\/\/ Created : Dec 2015\n\/\/ Modified : March 2016\n\/\/\n\/\/ BufferA :\n\/\/     __________________________________________\n\/\/    |    Face 6      |    Face 6      |        |\n\/\/    |   z- lower     |   z- upper     |MetaData|\n\/\/    |________________|________________|________|\n\/\/    |        |                |                |\n\/\/    |        |                |                |\n\/\/    |Face 3  |     Face 4     |     Face 5     |\n\/\/    |  y+    |       y-       |       z+       |\n\/\/    |________|________________|________________|\n\/\/    |                |                |        |\n\/\/    |                |                |        |\n\/\/    |    Face 1      |    Face 2      |  Face 3|\n\/\/    |      X+        |      X-        |    y+  |\n\/\/    |________________|________________|________|\n\/\/     \n\/\/\n\/\/ Same Image-based PBR equations as https:\/\/www.shadertoy.com\/view\/ld3SRr, with the addition\n\/\/ of an irradiance cubemap for the diffuse contribution on plastic material (BufferA).\n\/\/ \n\/\/ Sources:\n\/\/ http:\/\/www.codinglabs.net\/article_physically_based_rendering.aspx\n\/\/\n\/\/ License : Creative Commons Non-commercial (NC) license\n\/\/\n\n\/\/----------------------\n\/\/ Settings (change them!)\nconst float ROUGHNESS_AMOUNT       = 0.85;\/\/Valid range : [0-1] 0=shiny, 1=rough map\nconst float SKY_COLOR              = 0.0; \/\/[0.0=Red, 1.0=Blue)\nconst float ABL_LIGHT_CONTRIBUTION = 0.5; \/\/[0-1] Additional ABL Light Contribution\n\n\/\/----------------------\n\/\/ internal constants\nconst float GEO_MAX_DIST   = 1000.0;\nconst float CAM_FOV        = 2.5; \/\/proj plane width\nconst float MIPMAP_SWITCH  = 0.29; \/\/sampling angle delta (rad) equivalent to the lowest LOD.\nconst int MATERIALID_ENV = 1;\nconst int MATERIALID_OBJ = 2;\n\/\/http:\/\/www.filmetrics.com\/refractive-index-database\/Al\/Aluminium\n\/\/http:\/\/refractiveindex.info\/?shelf=3d&book=liquids&page=water\n\/\/https:\/\/seblagarde.wordpress.com\/2011\/08\/17\/feeding-a-physical-based-lighting-mode\/\nconst vec3  F_ALU_N  = vec3(1.600,0.912,0.695); \/\/(Red ~ 670 nm; Green ~ 540 nm; Blue ~ 475 nm)\nconst vec3  F_ALU_K  = vec3(8.010,6.500,5.800); \/\/(Red ~ 670 nm; Green ~ 540 nm; Blue ~ 475 nm)\nconst vec3  F_GOLD_N = vec3(0.161,0.402,1.242); \/\/(Red ~ 670 nm; Green ~ 540 nm; Blue ~ 475 nm)\nconst vec3  F_GOLD_K = vec3(3.446,2.540,1.796); \/\/(Red ~ 670 nm; Green ~ 540 nm; Blue ~ 475 nm)\nconst float F_DIELECTRIC_PLASTIC = 1.49; \/\/@550nm, does not change much with wavelength for dielectric\nconst float F_DIELECTRIC_WATER   = 1.33; \/\/@550nm\nconst float F_DIELECTRIC_DIAMOND = 2.42; \/\/@550nm\n\nstruct Cam\n{\n    vec3 R;\/\/Right, \n    vec3 U;\/\/Up,\n    vec3 D;\/\/Direction,\n    vec3 o;\/\/origin (pos)\n};\n    \nstruct TraceData\n{\n    float rayLen; \/\/Run Distance\n    vec3  rayDir; \/\/Run Direction\n    float geoDist;\/\/Hit error (might not always converge)\n    vec3  normal; \/\/Hit normal\n    int   matID;  \/\/Hit material ID\n};\n\nmat3  UTIL_axisRotationMatrix(vec3 axis, float theta);\n\n#define saturate(x) clamp(x,0.0,1.0)\n\/\/From Dave Hoskin's hash without sine\n#define MOD3 vec3(.1031,.11369,.13787) \n\n\/\/PBR Equation for a single sample (IBL) or a single point point (ABL)\nvec3 PBR_Equation(vec3 V, vec3 L, vec3 N, float roughness, vec3 ior_n, vec3 ior_k, const bool metallic, const bool bIBL)\n{\n    float cosT = saturate( dot(L, N) );\n    float sinT = sqrt( 1.0 - cosT * cosT);\n    \n\tvec3 H = normalize(L+V);\n\tfloat NdotH = dot(N,H);\/\/Nn.H;\n\tfloat NdotL = dot(N,L);\/\/Nn.Ln;\n\tfloat VdotH = dot(V,H);\/\/Vn.H;\n    float NdotV = dot(N,V);\/\/Nn.Vn;\n    \n    \/\/-----------------------------------------\n\t\/\/            Distribution Term\n    \/\/-----------------------------------------\n    float PI = 3.14159;\n    float alpha2 = roughness * roughness;\n    float NoH2 = NdotH * NdotH;\n    float den = NoH2*(alpha2-1.0)+1.0;\n    float D = 1.0; \/\/Distribution term is externalized from IBL version\n    if(!bIBL)\n        D = (NdotH>0.)?alpha2\/(PI*den*den):0.0; \/\/GGX Distribution.\n\t\n    \/\/-----------------------------------------\n\t\/\/            Fresnel Term\n    \/\/-----------------------------------------\n    vec3 F;\n    if(metallic)\n    {\n        \/\/Source: http:\/\/sirkan.iit.bme.hu\/~szirmay\/fresnel.pdf p.3 above fig 5\n        float cos_theta = 1.0-NdotV;\/\/REVIEWME : NdotV or NdotL ?\n        F =  ((ior_n-1.)*(ior_n-1.)+ior_k*ior_k+4.*ior_n*pow(1.-cos_theta,5.))\n\t\t    \/((ior_n+1.)*(ior_n+1.)+ior_k*ior_k);\n    }\n    else\n    {\n        \/\/Fresnel Schlick Dielectric formula \n        \/\/Sources: https:\/\/en.wikipedia.org\/wiki\/Schlick%27s_approximation\n        \/\/          http:\/\/www.codinglabs.net\/article_physically_based_rendering_cook_torrance.aspx\n        \/\/Note: R\/G\/B do not really differ for dielectric materials\n        float F0 = abs ((1.0 - ior_n.x) \/ (1.0 + ior_n.x));\n  \t\tF = vec3(F0 + (1.-F0) * pow( 1. - VdotH, 5.));\n    }\n    \n    \/\/-----------------------------------------\n\t\/\/            Geometric term\n    \/\/-----------------------------------------\n    \/\/Source: Real Shading in Unreal Engine 4 2013 Siggraph Presentation\n    \/\/https:\/\/de45xmedrsdbp.cloudfront.net\/Resources\/files\/2013SiggraphPresentationsNotes-26915738.pdf p.3\/59\n    \/\/k = Schlick model (IBL) : Disney's modification to reduce hotness (point light)\n    float k = bIBL?(roughness*roughness\/2.0):(roughness+1.)*(roughness+1.)\/8.; \n    float Gl = max(NdotL,0.)\/(NdotL*(1.0-k)+k);\n    float Gv = max(NdotV,0.)\/(NdotV*(1.0-k)+k);\n    float G = Gl*Gv;\n    \n    \/\/-----------------------------------------\n\t\/\/     PBR Equation (ABL & IBL versions)\n    \/\/-----------------------------------------\n    \/\/Two flavors of the PBR equation (IBL\/point light).\n    \/\/Personal addition: This parameter softens up the transition at grazing angles (otherwise too sharp IMHO).\n    float softTr = 0.1; \/\/ Valid range : [0.001-0.25]. It will reduce reflexivity on edges when too high, however.\n    \/\/Personal addition: This parameter limits the reflexivity loss at 90deg viewing angle (black spot in the middle?).\n    float angleLim = 0.15; \/\/ Valid range : [0-0.75] (Above 1.0, become very mirror-like and diverges from a physically plausible result)\n    \/\/Source: http:\/\/www.codinglabs.net\/article_physically_based_rendering_cook_torrance.aspx\n    if(bIBL)\n        return (F*G*(angleLim+sinT)\/(angleLim+1.0) \/ (4.*NdotV*saturate(NdotH)*(1.0-softTr)+softTr)); \/\/IBL\n    else\n        return D*F*G \/ (4.*NdotV*NdotL*(1.0-softTr)+softTr);\t\/\/ABL\n}\n\nvec3 PBR_HDRremap(vec3 c)\n{\n    float fHDR = smoothstep(2.900,3.0,c.x+c.y+c.z);\n    \/\/vec3 cRedSky   = mix(c,1.3*vec3(4.5,2.5,2.0),fHDR);\n    vec3 cBlueSky  = mix(c,1.8*vec3(2.0,2.5,3.0),fHDR);\n    return cBlueSky;\/\/mix(cRedSky,cBlueSky,SKY_COLOR);\n}\n\nvec3 PBR_HDRCubemap(vec3 sampleDir, float LOD_01)\n{\n    vec3 linearGammaColor_sharp = PBR_HDRremap(pow(texture( iChannel2, sampleDir ).rgb,vec3(2.2)));\n    vec3 linearGammaColor_blur  = PBR_HDRremap(pow(texture( iChannel3, sampleDir ).rgb,vec3(1)));\n    vec3 linearGammaColor = mix(linearGammaColor_sharp,linearGammaColor_blur,saturate(LOD_01));\n    return linearGammaColor;\n}\n\nvec2 hash22(vec2 p)\n{\n    \/\/From DaveHoskin's hash without sine\n    \/\/https:\/\/www.shadertoy.com\/view\/4djSRW\n\tvec3 p3 = fract(vec3(p.xyx) * MOD3);\n    p3 += dot(p3.zxy, p3.yzx+19.19);\n    return fract(vec2((p3.x + p3.y)*p3.z, (p3.x+p3.z)*p3.y));\n}\n\nvec3 PBR_nudgeSample(vec3 sampleDir, float roughness, float e1, float e2, out float range)\n{\n    const float PI = 3.14159;\n    \/\/Importance sampling :\n    \/\/Source : http:\/\/www.codinglabs.net\/article_physically_based_rendering_cook_torrance.aspx\n    \/\/The higher the roughness, the broader the range.\n    \/\/In any case, wide angles are less probable than narrow angles.\n    range = atan( roughness*sqrt(e1)\/sqrt(1.0-e1) );\n    \/\/Circular angle has an even distribution (could be improved?).\n\tfloat phi = 2.0*PI*e2;\n    \n\tvec3 up = vec3(0,1,0); \/\/arbitrary\n\tvec3 tAxis = cross(up,sampleDir);\n\tmat3 m1 = UTIL_axisRotationMatrix(normalize(tAxis),range);\n\tmat3 m2 = UTIL_axisRotationMatrix(normalize(sampleDir), phi);\n        \n\treturn sampleDir*m1*m2;\n}\n\nvec3 PBR_visitSamples(vec3 V, vec3 N, float roughness, bool metallic, vec3 ior_n, vec3 ior_k )\n{\n    \/\/Direct relection vector\n    vec3 vCenter = reflect(-V,N);\n    \n    \/\/------------------------------------------------\n\t\/\/  Randomized Samples : more realistic, but\n    \/\/  a lot of samples before it stabilizes \n    \/\/------------------------------------------------\n    float randomness_range = 0.75; \/\/Cover only the closest 75% of the distribution. Reduces range, but improves stability.\n    float fIdx = 0.0;              \/\/valid range = [0.5-1.0]. Note : it is physically correct at 1.0.\n    const int ITER_RDM = 05;\n    const float w_rdm = 1.0\/float(ITER_RDM);\n    vec3 totalRandom = vec3(0.0);\n    for(int i=0; i < ITER_RDM; ++i)\n    {\n        \/\/Random jitter note : very sensitive to hash quality (patterns & artifacts).\n        vec2 jitter = hash22(fIdx*10.0+vCenter.xy*100.0);\n    \tfloat angularRange = 0.;    \n        vec3 sampleDir    = PBR_nudgeSample(vCenter, roughness, jitter.x*randomness_range, jitter.y, angularRange);\n        vec3 sampleColor  = PBR_HDRCubemap( sampleDir, angularRange\/MIPMAP_SWITCH);\n        vec3 contribution = PBR_Equation(V, sampleDir, N, roughness, ior_n, ior_k, metallic, true)*w_rdm;\n    \ttotalRandom += contribution*sampleColor;\n\t\t++fIdx;\n    }\n    \n    \/\/------------------------------------------------\n\t\/\/  Fixed Samples : More stable, but creates\n    \/\/  sampling pattern artifacts and the reach is\n    \/\/  limited.\n    \/\/------------------------------------------------\n    fIdx = 0.0;\n    const int ITER_FIXED = 15;\n    const float w_fixed = 1.0\/float(ITER_FIXED); \/\/Sample\n    vec3 totalFixed = vec3(0.0);\n    for(int i=0; i < ITER_FIXED; ++i)\n    {\n        \/\/Stable pseudo-random jitter (to improve stability with low sample count)\n        \/\/Beware here! second component controls the sampling pattern \"swirl\", and it must be choosen \n        \/\/             so that samples do not align by doing complete 360deg cycles at each iteration.\n        vec2 jitter = vec2( clamp(w_fixed*fIdx,0.0,0.50),\n                            fract(w_fixed*fIdx*1.25)+3.14*fIdx);\n        float angularRange = 0.;\n        vec3 sampleDir    = PBR_nudgeSample(vCenter, roughness, jitter.x, jitter.y, angularRange);\n        vec3 sampleColor  = PBR_HDRCubemap( sampleDir, angularRange\/MIPMAP_SWITCH);\n        vec3 contribution = PBR_Equation(V, sampleDir, N, roughness, ior_n, ior_k, metallic, true)*w_fixed;\n        totalFixed += contribution*sampleColor;\n\t\t++fIdx;\n    }\n    \n    return (totalRandom*float(ITER_RDM)+totalFixed*float(ITER_FIXED))\/(float(ITER_RDM)+float(ITER_FIXED));\n}\n\n\/\/Cubemap folding\nstruct MyCubeMap_FaceInfo\n{\n    vec2 uv; \/\/[0-1]\n    float id; \/\/[0=x+,1=x-,2=y+,3=y-,4=z+,5=z-]\n};\n\/\/Cubemap folding\nvec4 MyCubeMap_cube(vec3 ro, vec3 rd, vec3 pos, vec3 size)\n{\n    ro = ro-pos;\n    float cullingDir = all(lessThan(abs(ro),size))?1.:-1.;\n    vec3 viewSign = cullingDir*sign(rd);\n    vec3 t = (viewSign*size-ro)\/rd;\n    vec2 uvx = (ro.zy+t.x*rd.zy)\/size.zy; \/\/face uv : [-1,1]\n    vec2 uvy = (ro.xz+t.y*rd.xz)\/size.xz;\n    vec2 uvz = (ro.xy+t.z*rd.xy)\/size.xy;\n    if(      all(lessThan(abs(uvx),vec2(1))) && t.x > 0.) return vec4(t.x,(uvx+1.)\/2.,0.5-viewSign.x\/2.0);\n    else if( all(lessThan(abs(uvy),vec2(1))) && t.y > 0.) return vec4(t.y,(uvy+1.)\/2.,2.5-viewSign.y\/2.0);\n    else if( all(lessThan(abs(uvz),vec2(1))) && t.z > 0.) return vec4(t.z,(uvz+1.)\/2.,4.5-viewSign.z\/2.0);\n\treturn vec4(2000.0,0,0,-1);\n}\n\/\/Cubemap unfolding\n#define SEAMLESS 1\n\/\/Converts a cube face ID & face uv into 2D texture [0-1] uv mapping\nvec2 MyCubeMap_faceToUV(MyCubeMap_FaceInfo info)\n{\n    const float freq = 2.5;\n    info.id   += (info.id>=4.99 && info.uv.y>0.5)?1.:0.;\n#if SEAMLESS\n    const float eps = 0.003;\n    bool bHalf = (info.id>5.99);\n    if(bHalf)\n    {\n        info.uv.y -= 0.5;\n\t\tinfo.uv.y = min(info.uv.y,0.5-eps);\n    }\n    info.uv = min(info.uv,1.-eps);\n    info.uv = max(info.uv,eps);\n#else\n    info.uv.y -= (info.id>5.99)?0.5:0.;\n#endif    \n    \n    vec2 huv = vec2(info.uv.x+info.id,info.uv.y);\n    huv.y = huv.y\/freq+floor(huv.x\/freq)\/freq;\n    return vec2(fract(huv.x\/freq),huv.y);\n}\n\nvec4 MAT_triplanarRoughness(vec3 p, vec3 n)\n{\n    p = fract(p+0.5);\n    \n    float sw = 0.20; \/\/stiching width\n    vec3 stitchingFade = vec3(1.)-smoothstep(vec3(0.5-sw),vec3(0.5),abs(p-0.5));\n    \n    float fTotal = abs(n.x)+abs(n.y)+abs(n.z);\n    vec4 cX = abs(n.x)*texture(iChannel0,p.zy);\n    vec4 cY = abs(n.y)*texture(iChannel0,p.xz);\n    vec4 cZ = abs(n.z)*texture(iChannel0,p.xy);\n    \n    return  vec4(stitchingFade.y*stitchingFade.z*cX.rgb\n                +stitchingFade.x*stitchingFade.z*cY.rgb\n                +stitchingFade.x*stitchingFade.y*cZ.rgb,cX.a+cY.a+cZ.a)\/fTotal;\n}\n\n\/\/The main material function.\nvec4 MAT_apply(vec3 pos, TraceData traceData)\n{\n    vec3 backgroundColor = pow(texture( iChannel2, traceData.rayDir ).xyz,vec3(2.2));\n    \n    if(traceData.matID==MATERIALID_ENV)\n    {\n        return vec4(backgroundColor,1);\n    }\n    \n    \/\/-----------------------------------------\n\t\/\/            Roughness texture\n    \/\/-----------------------------------------\n    vec4 roughnessBuffer = MAT_triplanarRoughness(pos,traceData.normal);\n    float fRoughness = (roughnessBuffer.x+roughnessBuffer.y+roughnessBuffer.z)\/3.0;\n    fRoughness = saturate(fRoughness-1.0+ROUGHNESS_AMOUNT)*0.25;\n    fRoughness += roughnessBuffer.w*800.0\/iResolution.x;\n    \n    \/\/-----------------------------------------\n\t\/\/         IBL and ABL PBR Lighting\n    \/\/-----------------------------------------\n    vec3 rd  = traceData.rayDir;\n    vec4 col = vec4(0);\n    vec3 V = normalize(-traceData.rayDir);\n    vec3 N = traceData.normal;\n    vec3 L = normalize(vec3(1,1,0));\n    \n    \/\/Position dependent parameters\n    \/\/(this could use some cleaning up)\n    bool bMetallic = fract(pos.x)>0.5;\n    vec3 ior_N = bMetallic?F_ALU_N:vec3(F_DIELECTRIC_PLASTIC);\n    vec3 ior_K = bMetallic?F_ALU_K:vec3(0);\n    vec3 cDiff = vec3(1);\n    if(all(lessThan(pos.xz,vec2(-0.5))))\n\t\tcDiff = vec3(0.02);\n    if(all(greaterThan(pos.xz,vec2(0.5))))\n\t\tcDiff = vec3(0.95,0.05,0.05);\n    if(pos.x>0.5 && bMetallic)\n    {\n        ior_N = F_GOLD_N;\n    \tior_K = F_GOLD_K;\n    }\n    \n    vec4 rVal = MyCubeMap_cube(vec3(0),N,vec3(0),vec3(2));\n    MyCubeMap_FaceInfo faceInfo = MyCubeMap_FaceInfo(rVal.yz,rVal.w);\n    vec3 cHemisphereDiffuse = texture(iChannel1,MyCubeMap_faceToUV(faceInfo),-100.0).rgb;\n    \n    cDiff *= cHemisphereDiffuse;\n    \n    col.rgb = PBR_visitSamples(V, N, fRoughness, bMetallic, ior_N, ior_K);\n    vec3 L0 = PBR_Equation(V,L,N, fRoughness+0.01, ior_N, ior_K, bMetallic, false);\n    col.rgb += L0;\n    if(!bMetallic) col.rgb += cDiff;\n    \n    \/\/-----------------------------------------\n\t\/\/      normal-based edge antialiasing\n    \/\/-----------------------------------------\n    \/\/Fade out to background as the view-normal angles reaches 90deg\n    \/\/This is very application-specific\n    \/\/vec3 backgroundColor = pow(texture( iChannel2, traceData.rayDir ).xyz,vec3(2.2));\n    float aaAmount = 0.15;\n    if(dot(N,traceData.rayDir) > -aaAmount)\n    {\n        float smoothFactor = 1.0-clamp(-dot(N,traceData.rayDir)\/(aaAmount), 0.0, 1.0);\n        col.rgb = mix(col.rgb, backgroundColor, smoothFactor);\n    }\n    \n    return col;\n}\n\nstruct DF_out\n{\n    float d;  \/\/Distance to geometry\n    int matID;\/\/Geometry material ID\n};\n\nfloat DF_smoothMerge( float d1, float d2, float d3 )\n{\n    float k = 22.0;\n\treturn -log(exp(-k*d1)+exp(-k*d2)+exp(-k*d3))\/k;\n}\n\nfloat DF_cube( vec3 p, vec3 size )\n{\n    vec3 dEdge = abs(p)-size; \/\/distance to cube edge, along each axis\n    float internalDist = max(dEdge.x,max(dEdge.y,dEdge.z)); \/\/Inside cube : manhattan distance, negative values\n    float externalDist = length(max(dEdge,vec3(0))); \/\/Outside cube : euclidian distance where axis dist > 0\n    return externalDist+min(internalDist,0.0); \/\/min(internal,0) to avoid internal\/external condition.\n}\n\nfloat DF_sphere( vec3 p, float size )\n{\n\treturn length(p)-size;    \n}\n\nDF_out DF_composition( in vec3 _pos )\n{\n\t\/\/Explanation:\n    \/\/https:\/\/iquilezles.org\/articles\/distfunctions\n    float fRadius = 0.4;\n        \n    \/\/Repetition\n    vec3 pos = _pos;\n    pos.xz = fract(pos.xz+0.5)-0.5;\n    \/\/Limits\n    if(abs(_pos.x)>1.5) \n        pos.x = _pos.x - sign(_pos.x);\n    if(abs(_pos.z)>1.5) \n        pos.z = _pos.z - sign(_pos.z);\n    \n    float sd_sphere = DF_sphere( pos, fRadius ); \n    float sd_cube = DF_cube( pos-vec3(0.0,0.4,0.0), vec3(fRadius)\/2.0 ); \n\tfloat sd_sphere2 = DF_sphere( pos-vec3(0.0,0.8,0.0), fRadius\/2.0 ); \n    \n    DF_out dfOut;\n    dfOut.d = DF_smoothMerge(sd_sphere,sd_sphere2,sd_cube);\n    dfOut.matID = MATERIALID_OBJ;\n    return dfOut;\n    \n}\n\nvec3 DF_gradient( in vec3 p )\n{\n\tconst float d = 0.001;\n\tvec3 grad = vec3(DF_composition(p+vec3(d,0,0)).d-DF_composition(p-vec3(d,0,0)).d,\n                     DF_composition(p+vec3(0,d,0)).d-DF_composition(p-vec3(0,d,0)).d,\n                     DF_composition(p+vec3(0,0,d)).d-DF_composition(p-vec3(0,0,d)).d);\n\treturn grad;\n}\n\n\/\/o = ray origin, d = direction, t = distance travelled along ray, starting from origin\nvec2 RAYMARCH_distanceField( vec3 o, vec3 dir)\n{\n    \/\/From Inigo Quilez DF ray marching :\n    \/\/https:\/\/iquilezles.org\/articles\/raymarchingdf\n    float tmax = GEO_MAX_DIST;\n    float t = 0.0;\n    float dist = GEO_MAX_DIST;\n    for( int i=0; i<50; i++ )\n    {\n\t    dist = DF_composition( o+dir*t ).d;\n        if( abs(dist)<0.0001 || t>GEO_MAX_DIST ) break;\n        t += dist;\n    }\n    \n    return vec2( t, dist );\n}\n    \nTraceData new_TraceData()\n{\n    TraceData td;\n    td.rayLen = 0.;\n    td.rayDir = vec3(0);\n    td.geoDist = 0.;\n    td.normal = vec3(0);\n    td.matID = MATERIALID_ENV;\n    return td;\n}\n\n\n\/\/o=ray origin, d=ray direction\nTraceData TRACE_geometry(vec3 o, vec3 d)\n{\n    TraceData skyData;\n    skyData.rayLen  = 50.0;\n    skyData.rayDir  = d;\n\tskyData.geoDist = 0.0;\n\tskyData.normal  = -d; \/\/Shere center\n\tskyData.matID   = MATERIALID_ENV;\n    \n    TraceData dfTrace;\n    vec2 rayLen_geoDist = RAYMARCH_distanceField(o,d);\n    vec3 dfHitPosition  = o+rayLen_geoDist.x*d;\n    dfTrace.rayDir     = d;\n    dfTrace.rayLen     = rayLen_geoDist.x;\n    dfTrace.geoDist    = rayLen_geoDist.y;\n    dfTrace.normal     = normalize(DF_gradient(dfHitPosition));\n    dfTrace.matID = MATERIALID_OBJ;\n    \n    if(dfTrace.geoDist>0.01 || skyData.rayLen<dfTrace.rayLen)\n    {\n        return skyData;\n    }\n    else\n    {\n        return dfTrace;\n    }\n}\n\n\/\/Arbitrary axis rotation (around u, normalized)\nmat3 UTIL_axisRotationMatrix( vec3 u, float t )\n{\n    float c = cos(t);\n    float s = sin(t);\n    \/\/  _        _   _           _     _                    _ \n    \/\/ |_px py pz_| | m11 m21 m31 |   | px*m11+py*m21+pz*m31 |\n    \/\/              | m12 m22 m32 | = | px*m12+py*m22+pz*m32 |\n    \/\/              |_m13 m23 m33_|   |_px*m13+py*m23+pz*m33_|\n    return mat3(  c+u.x*u.x*(1.-c),     u.x*u.y*(1.-c)-u.z*s, u.x*u.z*(1.-c)+u.y*s,\n\t              u.y*u.x*(1.-c)+u.z*s, c+u.y*u.y*(1.-c),     u.y*u.z*(1.-c)-u.x*s,\n\t              u.z*u.x*(1.-c)-u.y*s, u.z*u.y*(1.-c)+u.x*s, c+u.z*u.z*(1.-c) );\n}\n\n\nCam CAM_animate(vec2 uv, float rotX, bool useMouse)\n{\n    if(useMouse)\/\/Mouse button down : user rotation control\n    {\n        float PI = 3.14159;\n    \trotX = 2.0*PI*(iMouse.x\/iResolution.x);\n    }\n    Cam cam;\n    cam.o = vec3(cos(rotX),0.5,sin(rotX))*2.5;\n    cam.D = normalize(vec3(0)-cam.o);\n    cam.R = normalize(cross(cam.D,vec3(0,1,0)));\n    cam.U = cross(cam.R,cam.D);\n    return cam;\n}\n\nvec3 CAM_getRay(Cam cam,vec2 uv)\n{\n    uv *= CAM_FOV;\n    return normalize(uv.x*cam.R+uv.y*cam.U+cam.D);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv = (fragCoord.xy-0.5*iResolution.xy) \/ iResolution.xx;\n    vec2 mousePos = iMouse.xy \/ iResolution.xy;\n    bool bMouseRotate = (iMouse.z > 0.0) ;\n    Cam cam = CAM_animate(uv,iTime*0.3,bMouseRotate);\n    vec3 d = CAM_getRay(cam,uv);\n    \n    vec3 ptGeo = vec3(0);\n    \n    TraceData geometryTraceData = TRACE_geometry(cam.o, d);\n    \n    if(geometryTraceData.rayLen < GEO_MAX_DIST)\n    {\n        ptGeo = cam.o+d*geometryTraceData.rayLen;\n    }\n    \n    vec3 c = MAT_apply(ptGeo,geometryTraceData).rgb;\n    \n    \/\/Vignetting\n    float lensRadius = 0.65;\n    uv \/= lensRadius;\n    float sin2 = uv.x*uv.x+uv.y*uv.y;\n    float cos2 = 1.0-min(sin2*sin2,1.0);\n    float cos4 = cos2*cos2;\n    c *= cos4;\n    \n    \/\/Gamma\n    c = pow(c,vec3(0.4545)); \/\/2.2 Gamma compensation\n    \n    fragColor = vec4(c,1.0);\n    \n    vec2 irrandianceBufferSize = vec2(120,75);\n    if(all(lessThan(fragCoord.xy,irrandianceBufferSize+1.)))\n        fragColor = vec4(1);\n    if(all(lessThan(fragCoord.xy,irrandianceBufferSize)))\n        fragColor = texture(iChannel1,(fragCoord.xy)\/irrandianceBufferSize);\n}","name":"Image","description":"","type":"image"},{"inputs":[{"id":"4sfGzn","filepath":"\/media\/a\/793a105653fbdadabdc1325ca08675e1ce48ae5f12e37973829c87bea4be3232.png","previewfilepath":"\/media\/ap\/793a105653fbdadabdc1325ca08675e1ce48ae5f12e37973829c87bea4be3232.png","type":"cubemap","channel":0,"sampler":{"filter":"mipmap","wrap":"clamp","vflip":"false","srgb":"false","internal":"byte"},"published":1},{"id":"4dXGR8","filepath":"\/media\/previz\/buffer00.png","previewfilepath":"\/media\/previz\/buffer00.png","type":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dXGR8","channel":0}],"code":"\/\/Author : S\u00c3\u00a9bastien B\u00c3\u00a9rub\u00c3\u00a9\n\/\/Buffer A : Hemisphere integration to compute environment diffuse contribution.\n\/\/           The result is \"cubemapped\" and folded into the current buffer output,\n\/\/           using uvToFace() and faceToRay().\n\/\/           \n\/\/           function \"FaceInfo uvToFace(vec2 uv)\" converts a [0-1] uv input into the cubemap face info (face ID + face UV).\n\/\/           function \"vec3 faceToRay(FaceInfo info)\" converts a face info into a 3D direction.\n\/\/           \n\/\/    BufferA :\n\/\/     __________________________________________\n\/\/    |    Face 6      |    Face 6      |        |\n\/\/    |   z- lower     |   z- upper     |MetaData|\n\/\/    |________________|________________|________|\n\/\/    |        |                |                |\n\/\/    |        |                |                |\n\/\/    |Face 3  |     Face 4     |     Face 5     |\n\/\/    |  y+    |       y-       |       z+       |\n\/\/    |________|________________|________________|\n\/\/    |                |                |        |\n\/\/    |                |                |        |\n\/\/    |    Face 1      |    Face 2      |  Face 3|\n\/\/    |      X+        |      X-        |    y+  |\n\/\/    |________________|________________|________|\n\/\/     \n\/\/#define HIGH_QUALITY \/\/Time needs to be reset when defining this value.\n\n#ifdef HIGH_QUALITY\nconst int SAMPLES_PER_ITERATION = 30;\nconst int CONVERGENCE_FRAME_COUNT = 200;\n#else\nconst int SAMPLES_PER_ITERATION = 5;\nconst int CONVERGENCE_FRAME_COUNT = 100;\n#endif\n\n\n\/\/Arbitrary axis rotation (around normalized u, cos theta, sin theta)\nmat3 UTIL_axisRotationMatrix( vec3 u, float ct, float st )\n{\n    return mat3(  ct+u.x*u.x*(1.-ct),     u.x*u.y*(1.-ct)-u.z*st, u.x*u.z*(1.-ct)+u.y*st,\n\t              u.y*u.x*(1.-ct)+u.z*st, ct+u.y*u.y*(1.-ct),     u.y*u.z*(1.-ct)-u.x*st,\n\t              u.z*u.x*(1.-ct)-u.y*st, u.z*u.y*(1.-ct)+u.x*st, ct+u.z*u.z*(1.-ct) );\n}\n\nvec3 rotateSample(vec3 sampleDir, float range_01, float circular_01, out float range_angle)\n{\n    const float PI = 3.14159;    \n    float theta = 2.0*PI*circular_01;\n    \n\tvec3 notColinear = (abs(sampleDir.y)<0.8)?vec3(0,1,0):vec3(1,0,0);\n\tvec3 othogonalAxis = normalize(cross(notColinear,sampleDir));\n    \n    range_angle = atan( sqrt(range_01)\/sqrt(1.0-range_01) );\n    float cost = sqrt(1.0-range_01);\/\/=cos(range_angle);\n    float sint = sqrt(range_01);\/\/=sin(range_angle);\n\tmat3 m1 = UTIL_axisRotationMatrix(othogonalAxis, cost, sint);\n\tmat3 m2 = UTIL_axisRotationMatrix(sampleDir, cos(theta), sin(theta));\n    return sampleDir*m1*m2;\n}\n\nvec3 integrateHemisphere(vec3 normal, float progress)\n{\n    \/\/Add some randomness in between progress steps.\n    float ff = 0.5-(fract(normal.x*4913.)\n\t               +fract(normal.y*4913.)\n\t               +fract(normal.z*4913.))\/6.0;\n    \n    progress += max(0.,ff\/float(CONVERGENCE_FRAME_COUNT));\n        \n    vec3 up = vec3(0,1,0);\n    vec3 right = normalize(cross(up,normal));\n    up = cross(normal,right);\n\n    vec3 sampledColour = vec3(0,0,0);\n    float index = 0.;\n    float theta = 0.;\n    \n    \/\/http:\/\/www.codinglabs.net\/article_physically_based_rendering.aspx\n    for(int j=0; j < SAMPLES_PER_ITERATION; ++j)\n    {\n        float circular_angle_01 = index\/float(SAMPLES_PER_ITERATION)+fract(progress*87316.)\/float(SAMPLES_PER_ITERATION);\n        vec3 sampleVector = rotateSample(normal, progress, circular_angle_01, theta);\n\t\tvec3 linearGammaColor = pow(texture( iChannel0, sampleVector, -100.0 ).rgb,vec3(2.2));\n        float sampledArea = sin(theta);\n\t\tsampledColour += linearGammaColor * cos(theta) * sampledArea;\n\t\tindex ++;\n\t}\n\n    return vec3( 3.14159 * sampledColour \/ index);\n}\n\nstruct FaceInfo\n{\n    vec2 uv; \/\/[0-1]\n    float id; \/\/[0=x+,1=x-,2=y+,3=y-,4=z+,5=z-]\n};\n\n\/\/receives a faceID + uv, which it converts into a 3D direction from cube center to face point.\nvec3 faceToRay(FaceInfo info)\n{\n    \/\/info.id = [0=x+,1=x-, 2=y+,3=y-, 4=z+,5=z-]\n    \/\/fAxis   = [0.01;0.51; 1.01;1.51; 2.01;2.51]\n    float eps = 0.01;              \n    float fAxis = info.id\/2.0+eps;\n    bvec3 axis  = lessThan(abs(floor(fAxis)-vec3(0,1,2)),vec3(eps));\n    vec3 camU = (axis.y)?vec3(0,0,1):vec3(0,1,0);\n    vec3 camD = vec3(axis.x?1:0,axis.y?1:0,axis.z?1:0);\n    vec3 camR = cross(axis.z?-camD:camD,camU);\n    float axisSign = (fract(fAxis)<0.5)?1.:-1.;\n    return  normalize(camR*(info.uv.x*2.-1.)\n                     +camU*(info.uv.y*2.-1.)\n                     +camD*axisSign);\n}\n\n\/\/Converts a 2D texture into its tile uv and its [0..5] index;\nFaceInfo uvToFace(vec2 uv)\n{\n    \/\/huv is the \"horizontally unrolled\" wide uv coord, where u.x=[0-6] and u.y=[0-1].\n    \/\/tuv is the tile uv coord, back to [0-1]. Note: 6th anf 7th tiles are cut in half and combined.\n    const float freq = 2.5;\n    uv *= freq;\n    vec2 huv = vec2(uv.x+freq*floor(uv.y),fract(uv.y));\n    float idx = floor(huv.x);\n    vec2 tuv = vec2(fract(huv.x),huv.y+(idx>5.01?0.5:0.));\n    return FaceInfo( tuv, min(idx,5.) );\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv = fragCoord.xy\/iResolution.xy;\n    \n    FaceInfo info = uvToFace(uv);\n    vec3 rayDir = faceToRay(info);\n    \n    vec3 cBuf = texture(iChannel1,vec2(1),-100.0).xyz;\n    vec2 prevRes = cBuf.xy;\n    float frameCount = cBuf.z;\n\t        \n    vec3 accumColor = texture(iChannel1,uv,-100.0).rgb;\n    if(iTime<0.1 || length(prevRes-iResolution.xy) > 1.)\n    {\n        \/\/Init\/reset on resolution change\n        accumColor = vec3(0);\n        frameCount = 0.0;\n    }\n    \n    float progress = frameCount\/float(CONVERGENCE_FRAME_COUNT);\n    vec3 cCurrentContribution = integrateHemisphere(rayDir, progress)\/float(CONVERGENCE_FRAME_COUNT);\n    vec3 c = accumColor+((progress<1.)?cCurrentContribution:vec3(0.));\n\tfragColor = vec4(c,1.0);\n    \n    \/\/Use top-right texture pixel to store computation resolution & frame count.\n    if(length(uv-vec2(1))<0.01)\n    {\n        fragColor.xyz = vec3(iResolution.xy,frameCount+1.);\n    }\n}","name":"Buf A","description":"","type":"buffer"},{"inputs":[{"id":"XdXGzn","filepath":"\/media\/a\/3083c722c0c738cad0f468383167a0d246f91af2bfa373e9c5c094fb8c8413e0.png","previewfilepath":"\/media\/ap\/3083c722c0c738cad0f468383167a0d246f91af2bfa373e9c5c094fb8c8413e0.png","type":"texture","channel":1,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"Xsf3zn","filepath":"\/media\/a\/f735bee5b64ef98879dc618b016ecf7939a5756040c2cde21ccb15e69a6e1cfb.png","previewfilepath":"\/media\/ap\/f735bee5b64ef98879dc618b016ecf7939a5756040c2cde21ccb15e69a6e1cfb.png","type":"texture","channel":0,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"false","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4sXGR8","channel":0}],"code":"\/\/Author : S\u00c3\u00a9bastien B\u00c3\u00a9rub\u00c3\u00a9\n\/\/Buffer C : Material Roughness map.\n\/\/           This is just noise, you could implement whatever roughness map you want.\n\/\/           This needs some clean-up, as it was originally coded as 3D noise, but only a 2D slice is used here.\n\n#define saturate(x) clamp(x,0.0,1.0)\nfloat UTIL_distanceToLineSeg(vec2 p, vec2 a, vec2 b)\n{\n    \/\/Scalar projection of ap in the ab direction = dot(ap,ab)\/|ab| : Amount of ap aligned towards ab\n    \/\/Divided by |ab| again, it becomes normalized along ab length : dot(ap,ab)\/(|ab||ab|) = dot(ap,ab)\/dot(ab,ab)\n    \/\/The clamp provides the line seg limits. e is therefore the \"capped orthogogal projection\".\n    \/\/       p\n    \/\/      \/\n    \/\/     \/\n    \/\/    a--e-------b\n    vec2 ap = p-a;\n    vec2 ab = b-a;\n    vec2 e = a+clamp(dot(ap,ab)\/dot(ab,ab),0.0,1.0)*ab;\n    return length(p-e);\n}\nvec2 noise(vec2 p)\n{\n    return texture(iChannel1,p,-100.0).xy;\n}\nstruct repeatInfo\n{\n\tvec2 pRepeated;\n    vec2 anchor;\n};\nrepeatInfo UTIL_repeat(vec2 p, float interval)\n{\n    repeatInfo rInfo;\n    rInfo.pRepeated = p \/ interval; \/\/Normalize\n    rInfo.pRepeated = fract(rInfo.pRepeated+0.5)-0.5; \/\/centered fract\n    rInfo.pRepeated *= interval; \/\/Rescale\n    rInfo.anchor = p-rInfo.pRepeated;\n    return rInfo;\n}\nfloat MAT_scratchTexture(vec2 p)\n{\n    const float squareWidth = 0.10*2.0;\n    const float moveAmp   = squareWidth*0.75;\n    const float lineWidth = 0.0005;\n    float repeatInterval = squareWidth+moveAmp;\n    repeatInfo rInfo = UTIL_repeat(p,repeatInterval);\n    float margin = repeatInterval-squareWidth;\n    \n    vec2 a = moveAmp*noise(rInfo.anchor);\n    vec2 b = -moveAmp*noise(rInfo.anchor+10.0);\n    float dseg = 1000.0*UTIL_distanceToLineSeg(rInfo.pRepeated, a, b)\/squareWidth;\n    return saturate(10.0\/dseg-0.5)*0.25;\n}\n\nfloat MAT_layeredScratches(vec2 p)\n{\n    const mat2 m2 = mat2(0.8,-0.6,0.6,0.8);\n    float I = MAT_scratchTexture(p);\n    p = m2*p;\n    I += MAT_scratchTexture(p*1.11+2.0);\n    p = m2*p;\n    I += MAT_scratchTexture(p*1.24+3.8);\n    p = m2*p;\n    I += MAT_scratchTexture(p*1.34+5.3);\n    p = m2*p;\n    I += MAT_scratchTexture(p*1.34+5.3);\n    p = m2*p;\n    I += MAT_scratchTexture(p*1.34+5.3);\n        \n    return I;\n}\n\nfloat MAT_triplanarScratches(vec3 p, vec3 n)\n{\n    \/\/Idea from http:\/\/http.developer.nvidia.com\/GPUGems3\/gpugems3_ch01.html\n    \/\/Figure 1-23 Triplanar Texturing\n    float fTotal = abs(n.x)+abs(n.y)+abs(n.z);\n    return ( abs(n.x)*MAT_scratchTexture(p.zy)\n            +abs(n.y)*MAT_scratchTexture(p.xz)\n            +abs(n.z)*MAT_scratchTexture(p.xy))\/fTotal;\n}\n\nvec4 NOISE_trilinearWithDerivative(vec3 p)\n{\n    \/\/Trilinear extension over noise derivative from (Elevated), & using the noise stacking trick from (Clouds).\n\t\/\/Inspiration & Idea from :\n    \/\/https:\/\/www.shadertoy.com\/view\/MdX3Rr (Elevated)\n    \/\/https:\/\/www.shadertoy.com\/view\/XslGRr (Clouds)\n    \n    \/\/For more information, see also:\n    \/\/NoiseVolumeExplained : https:\/\/www.shadertoy.com\/view\/XsyGWz\n\t\/\/2DSignalDerivativeViewer : https:\/\/www.shadertoy.com\/view\/ldGGDR\n    \n    const float TEXTURE_RES = 256.0; \/\/Noise texture resolution\n    vec3 pixCoord = floor(p);\/\/Pixel coord, integer [0,1,2,3...256...]\n    \/\/noise volume stacking trick : g layer = r layer shifted by (37x17 pixels)\n    \/\/(37x17)-> this value is the actual translation embedded in the noise texture, can't get around it.\n\t\/\/Note : shift is different from g to b layer (but it also works)\n    vec2 layer_translation = -pixCoord.z*vec2(37.0,17.0)\/TEXTURE_RES; \n    \n    vec2 c1 = texture(iChannel0,layer_translation+(pixCoord.xy+vec2(0,0)+0.5)\/TEXTURE_RES,-100.0).rg;\n    vec2 c2 = texture(iChannel0,layer_translation+(pixCoord.xy+vec2(1,0)+0.5)\/TEXTURE_RES,-100.0).rg; \/\/+x\n    vec2 c3 = texture(iChannel0,layer_translation+(pixCoord.xy+vec2(0,1)+0.5)\/TEXTURE_RES,-100.0).rg; \/\/+z\n    vec2 c4 = texture(iChannel0,layer_translation+(pixCoord.xy+vec2(1,1)+0.5)\/TEXTURE_RES,-100.0).rg; \/\/+x+z\n    \n    vec3 x = p-pixCoord; \/\/Pixel interpolation position, linear range [0-1] (fractional part)\n    \n    vec3 x2 = x*x;\n    vec3 t = (6.*x2-15.0*x+10.)*x*x2; \/\/Quintic ease-in\/ease-out function.\n    vec3 d_xyz = (30.*x2-60.*x+30.)*x2; \/\/dt\/dx : Ease-in ease-out derivative.\n    \n    \/\/Lower quad corners\n    float a = c1.x; \/\/(x+0,y+0,z+0)\n    float b = c2.x; \/\/(x+1,y+0,z+0)\n    float c = c3.x; \/\/(x+0,y+1,z+0)\n    float d = c4.x; \/\/(x+1,y+1,z+0)\n    \n    \/\/Upper quad corners\n    float e = c1.y; \/\/(x+0,y+0,z+1)\n    float f = c2.y; \/\/(x+1,y+0,z+1)\n    float g = c3.y; \/\/(x+0,y+1,z+1)\n    float h = c4.y; \/\/(x+1,y+1,z+1)\n    \n    \/\/Trilinear noise interpolation : (1-t)*v1+(t)*v2, repeated along the 3 axis of the interpolation cube.\n    float za = ((a+(b-a)*t.x)*(1.-t.y)\n               +(c+(d-c)*t.x)*(   t.y));\n    float zb = ((e+(f-e)*t.x)*(1.-t.y)\n               +(g+(h-g)*t.x)*(   t.y));\n    float value = (1.-t.z)*za+t.z*zb;\n    \n    \/\/Derivative scaling (texture lookup slope, along interpolation cross sections).\n    \/\/This could be factorized\/optimized but I fear it would make it cryptic.\n    float sx =  ((b-a)+t.y*(a-b-c+d))*(1.-t.z)\n               +((f-e)+t.y*(e-f-g+h))*(   t.z);\n    float sy =  ((c-a)+t.x*(a-b-c+d))*(1.-t.z)\n               +((g-e)+t.x*(e-f-g+h))*(   t.z);\n    float sz =  zb-za;\n    \n    return vec4(value,d_xyz*vec3(sx,sy,sz));\n}\n\n\/\/Stacked perlin noise\nvec3 NOISE_volumetricRoughnessMap(vec3 p, float rayLen)\n{\n    float ROUGHNESS_MAP_UV_SCALE = 6.00;\/\/Valid range : [0.1-100.0]\n    vec4 sliderVal = vec4(0.5,0.85,0,0.5);\n    ROUGHNESS_MAP_UV_SCALE *= 0.1*pow(10.,2.0*sliderVal[0]);\n    \n    float f = iTime;\n    const mat3 R1  = mat3(0.500, 0.000, -.866,\n\t                     0.000, 1.000, 0.000,\n                          .866, 0.000, 0.500);\n    const mat3 R2  = mat3(1.000, 0.000, 0.000,\n\t                      0.000, 0.500, -.866,\n                          0.000,  .866, 0.500);\n    const mat3 R = R1*R2;\n    p *= ROUGHNESS_MAP_UV_SCALE;\n    p = R1*p;\n    vec4 v1 = NOISE_trilinearWithDerivative(p);\n    p = R1*p*2.021;\n    vec4 v2 = NOISE_trilinearWithDerivative(p);\n    p = R1*p*2.021+1.204*v1.xyz;\n    vec4 v3 = NOISE_trilinearWithDerivative(p);\n    p = R1*p*2.021+0.704*v2.xyz;\n    vec4 v4 = NOISE_trilinearWithDerivative(p);\n    \n    return (v1\n\t      +0.5*(v2+0.25)\n\t      +0.4*(v3+0.25)\n\t      +0.6*(v4+0.25)).yzw;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 uv = fragCoord.xy\/iResolution.xy;\n    vec3 roughnessNoise = NOISE_volumetricRoughnessMap(vec3(2.0*uv,0),1.0).rgb;\n    float scratchTex = MAT_scratchTexture(2.0*uv);\n    scratchTex += MAT_layeredScratches(uv+0.25);\n    scratchTex += MAT_layeredScratches(uv+vec2(0.35));\n    scratchTex += MAT_scratchTexture(uv+vec2(1.15));\n    scratchTex += MAT_scratchTexture(uv+vec2(2.75));\n    fragColor = vec4(roughnessNoise,scratchTex);\n}","name":"Buf C","description":"","type":"buffer"}]},{"ver":"0.1","info":{"id":"MdcSzn","date":"1457307549","viewed":2538,"name":"Analytic Derivative Viewer2D","username":"Bers","description":"A signal viewer meant to be useful at validating the analytic derivative of a given function.","likes":62,"published":3,"flags":0,"usePreview":0,"tags":[]},"renderpass":[{"inputs":[],"outputs":[{"id":"4dfGRr","channel":0}],"code":"\/\/ Author : S\u00c3\u00a9bastien B\u00c3\u00a9rub\u00c3\u00a9\n\/\/ Created : May 2015\n\/\/ Modified : Jan 2016\n\/\/\n\/\/ This shader was written with the intent of easing the pain of finding and validating \n\/\/ analytic derivatives. I had decided to do this after having read an interesting article, from Inigo Quilez :\n\/\/ https:\/\/iquilezles.org\/articles\/morenoise\n\/\/\n\/\/ Although deriving a function in a theorical context is not so difficult, it can still \n\/\/ quickly become an overwhelming task if you stack up multiple layers of rotated, scaled, and distorted noise.\n\/\/ How do you rotate the derivatives, do you simply rotate the gradient in the same direction as the noise function?\n\/\/ What do you do with time multiplier, is it always derived as a constant factor?\n\/\/ Do you also have to derive the bilinear \/ trilinear equation, or just the ease function?\n\/\/ \n\/\/\n\/\/ License : Creative Commons Non-commercial (NC) license\n\nconst int COUNT = 5;                 \/\/Graph Count\nconst float HORIZONTAL_UNITS = 15.0; \/\/Horizontal Span (domain units)\nconst float INFINITY = 10000.0;\nconst float VERTICAL_UNITS = float(COUNT);\nconst float FUNC_A = 0.25; \/\/ A constant expression used in the wave function. It control how \"spikey\" they are.\nfloat g_animTime = 0.0;  \n\nfloat genRdm( vec2 p )\n{\n    \/\/(Numbers are arbitrary, this is pseudo-random)\n    return fract(sin(p.x*347.1+p.y*283.1)*987643.21234);\n}\n\n\/\/ -----------------------------------------------------------\n\/\/ The 4 corners of the bilinear interpolation (view from top)\n\/\/\n\/\/       (1,0)              (1,1)\n\/\/ 1    c-----------f------d\n\/\/ |    |           .      |\n\/\/ |    |           .      |\n\/\/ |    |           .      |\n\/\/t.y   g...........v......h\n\/\/ |    |           .      |\n\/\/ |    |           .      |\n\/\/ |    |           .      |\n\/\/ |    |           .      |  \n\/\/ |    |(0,0)      .      |(1,0)  \n\/\/ 0    a-----------e------b      ->x\n\/\/\n\/\/                  \n\/\/      0__________t.x_____1\n\/\/    \n\/\/ -----------------------------------------------\n\/\/ And the ease function below (value view, with tangent)\n\/\/\n\/\/ Here, the ease function to               ......h\n\/\/ interpolate from g to h.           ......      \n\/\/ The value delta between        ....            \n\/\/ h and g is indeed         \/ ...                \n\/\/ a scaling multiplier     \/..\n\/\/ applied on top          \/.                     \n\/\/ of the ease            \/.\n\/\/ function            ..\/\n\/\/ derivative      .... \/\n\/\/           ......\n\/\/   g.......                                      \n\/\/\n#define CUBIC   1\n#define QUINTIC 2\n#define SINE    3\n#define EASE_FUNC QUINTIC\nvec3 bilinearNoise( in vec2 p, float fTime ) \n{\n    const float PI = 3.14159;\n    p.xy += fTime;\n    vec2 x = fract( p );\t\n    vec2 i = p-x;\n#if(EASE_FUNC==CUBIC)\n    \/\/Option 1 : Cubic ease function\n    vec2 t = x*x*(3.0-2.0*x); \/\/ease function\n    vec2 d_xy = 6.0*x*(1.0-x);\/\/derivative\n#elif(EASE_FUNC==QUINTIC)\n    \/\/Option 1 : Quintic ease function\n    vec2 t = (6.*x*x-15.0*x+10.)*x*x*x; \/\/ease function\n    vec2 d_xy = (30.*x*x-60.*x+30.)*x*x;  \/\/derivative\n#elif(EASE_FUNC==SINE)\n    \/\/Option 3 : Trigonometric ease function\n    vec2 t = 0.5+0.5*sin(-PI\/2.0+x*PI);   \/\/ease function\n    vec2 d_xy = 0.5*PI*cos(-PI\/2.0+x*PI); \/\/derivative\n#endif\n    \n    \/\/bilinear interpolation (abcd = 4 corners)\n\tfloat a = genRdm( i + vec2(0.0,0.0) );\n\tfloat b = genRdm( i + vec2(1.0,0.0) );\n\tfloat c = genRdm( i + vec2(0.0,1.0) );\n\tfloat d = genRdm( i + vec2(1.0,1.0) );\n    \n    \/\/Note : g and h could be factorized out.\n    float e = a+(b-a)*t.x; \/\/Horizontal interpolation 1 (e)\n    float f = c+(d-c)*t.x; \/\/Horizontal interpolation 2 (f)\n\tfloat v = e*(1.-t.y)+f*(t.y); \/\/Vertical interpolation (v)\n    \n    \/\/All this could be factorized and be made more compact.\n    \/\/Step by step is much easier to understand, however.\n    float g = a+(c-a)*t.y; \/\/Vertical interpolation (g)\n\tfloat h = b+(d-b)*t.y; \/\/Vertical interpolation (h)\n    \n    \/\/Noise delta scaling (the lookup value slope along x\/y axis).\n    float sx = h-g; \/\/dv\/dx scaling\n    float sy = f-e; \/\/dv\/dy scaling\n    \n    return vec3(v,\n\t            d_xy.x*sx,\n                d_xy.y*sy);\n    \n    \/\/return [h,dh\/dx,dh\/dy]\n}\n\/\/The 2D function shown in the middle graph.\n\/\/This fonction was created to be used as a base for water waves.\nfloat warpedGrid01(vec2 uv, float fTime)\n{\n    float a = FUNC_A;\n    uv += bilinearNoise(uv,fTime).x;\n    float gx = 0.5+sin(2.0*uv.x)*0.5;\n    float hx = a\/(gx+a);\n    float gy = 0.5+sin(2.0*uv.y)*0.5;\n    float hy = a\/(gy+a);\n    return (hx+hy)*0.5;\n}\n\n\/\/****************************************\n\/\/ Signal 1 (topmost)\nfloat F(float x)\n{\n    \/\/f(x) = noise(x).x\n    return bilinearNoise(vec2(x,0),g_animTime).x;\n}\nfloat dF(float x)\n{\n    \/\/f'(x) = noise(x).y\n    \/\/vec3[h,dx,dy]=waveNoise(x)\n    return bilinearNoise(vec2(x,0),g_animTime).y; \/\/waveNoise(x).y=dh\/dx\n}\n\/\/****************************************\n\/\/ Signal 2 (second from the top)\nfloat G(float x)\n{\n    \/\/g(x) = 0.5 + sin(2f(x))\/2\n    vec2 uv = vec2(x,0);\n    uv += bilinearNoise(uv,g_animTime).x;\n    return 0.5+sin(2.0*uv.x)*0.5;\n}\nfloat dG(float x)\n{\n    \/\/Theory : g'(x) = cos(2f(x))*(1+n'(x)) \n    vec2 uv = vec2(x,0);\n    uv += bilinearNoise(uv,g_animTime).x;\n    return cos(2.0*uv.x)*(1.0+dF(x));\n}\n\/\/****************************************\n\/\/ Signal 3 (third from the top)\nfloat H(float x)\n{\n    float a = FUNC_A;\n    \/\/h(x) = a\/(g(x)+a)\n    vec2 uv = vec2(x,0);\n    uv += bilinearNoise(uv,g_animTime).x;\n    float gx = 0.5+sin(2.0*uv.x)*0.5;\n    float hx = a\/(gx+a);\n    return hx;\n}\nfloat dH(float x)\n{\n    \/\/Theory : h'(x) = -g'(x)*a\/(g(x)+a)^2\n    float a = FUNC_A;\n    float g = G(x);\n    \/\/Application : \n    return -dG(x)*a\/((G(x)+a)*(G(x)+a));\n}\n\n\/\/****************************************\n\/\/ Signal 4 (third from the top) : basic example\nfloat Func4(float x)\n{\n    return 0.5+0.5*sin(x);\n}\nfloat dFunc4(float x)\n{\n    return 0.5*cos(x);\n}\n\/\/****************************************\n\/\/ Signal 5 (third from the top) : basic example\nfloat Func5(float x)\n{\n    return 0.5+0.5*sin(4.*x);\n}\nfloat dFunc5(float x)\n{\n    return 0.5*4.0*cos(4.*x);\n}\n\n\/\/Simple utility function which returns the distance from point \"p\" to a given line segment defined by 2 points [a,b]\nfloat distanceToLineSeg(vec2 p, vec2 a, vec2 b)\n{\n    \/\/e = capped [0,1] orthogonal projection of ap on ab\n    \/\/       p\n    \/\/      \/\n    \/\/     \/\n    \/\/    a--e-------b\n    vec2 ap = p-a;\n    vec2 ab = b-a;\n    vec2 e = a+clamp(dot(ap,ab)\/dot(ab,ab),0.0,1.0)*ab;\n    return length(p-e);\n}\n\n\/\/Returns the domain (x) position at pixel px\nfloat getDomainValue(float px)\n{\n    \/\/The fract(x\/1000.0)*1000.0 is there to prevent precision issues with large numbers.\n    return fract((iTime)\/1000.0)*1000.0 + px*HORIZONTAL_UNITS;\n}\n\n\/\/When the analytic derivative is calculated properly, this function returns\n\/\/the distance to a small segment which must be tangeant to the function signal.\n\/\/(If the derivative computation is wrong, displayed tangent will not match the slope)\nfloat distToAnalyticDerivatives(vec2 p)\n{\n    const float TAN_LEN = 0.05; \/\/The segment (tangent) half-length\n    float imageHeight = iResolution.y\/iResolution.x;\n    \n    \/\/Conversion factor from computation space to image space (Horizontal & Vert)\n    vec2 imgScaling = vec2(1.0\/HORIZONTAL_UNITS,imageHeight\/VERTICAL_UNITS);\n    \n    \/\/px = position (uv.x) at which the derivative is evaluated.\n    float px = 0.5; \/\/0.5 = image center\n    if(iMouse.z > 0.1)\n    {\n        px = iMouse.x\/iResolution.x;\n    }\n    float x = getDomainValue(px);\n    \n    vec2 V_Dx[COUNT];\n    V_Dx[0] = vec2(F(x),dF(x));\n    V_Dx[1] = vec2(G(x),dG(x));\n    V_Dx[2] = vec2(H(x),dH(x));\n    V_Dx[3] = vec2(Func4(x),dFunc4(x));\n    V_Dx[4] = vec2(Func5(x),dFunc5(x));\n    \n    float minDist = INFINITY;\n    for(int i=0; i < COUNT; ++i)\n    {\n        \/\/Signal height, image space [0-imageHeight]\n        float signalHeight = imgScaling.y*float(COUNT-1-i);\n        \n        \/\/Computation space value and tangent\n        float functionValue = V_Dx[i].x; \/\/f(x)\n        vec2 functionTan    = vec2(1.0,V_Dx[i].y); \/\/vec2 = [dx,df'(x)], in other words, the variation of f(x) per unit of x\n        \n        \/\/Image space value and tangent\n        vec2 imageValue = vec2(px,signalHeight+functionValue*imgScaling.y);\n        vec2 imageTangent = normalize(functionTan*imgScaling)*TAN_LEN;\n                                \n    \tminDist = min(minDist,distanceToLineSeg(p,imageValue-imageTangent,imageValue+imageTangent));\n    }\n\treturn minDist;\n}\n\n\/\/Returns the vertical distance of point p to graph line.\nfloat distanceToGraphValue(vec2 p)\n{\n    \/\/Vertical span for each signal\n    float vSpan = float(COUNT)*(iResolution.x\/iResolution.y);\n    \/\/x pos at pixel p.x\n    float x = getDomainValue(p.x);\n    \n    float graphValues[COUNT];\n    graphValues[0] = F(x);\n    graphValues[1] = G(x);\n    graphValues[2] = H(x);\n    graphValues[3] = Func4(x);\n    graphValues[4] = Func5(x);\n    \n    float minDist = INFINITY;\n    for(int i=0; i < COUNT; ++i)\n    {\n        float vOffset = float(COUNT-1-i)\/vSpan;\n        vec2 p = vec2(p.x,(p.y-vOffset)*vSpan);\n\t\tminDist = min(minDist,abs(p.y-graphValues[i]));\n    }\n\treturn minDist;\n}\n\n\/\/Returns the [x,y] gradient magnitude. All signals are processed.\nvec2 absGrad(vec2 p, float d0)\n{\n    \/\/Note : using max(d+,d-) derivative to reduce artifacts.\n    const float fEps = 0.001;\n    float dxp = abs(distanceToGraphValue(p+vec2(fEps,0))-d0);\n    float dyp = abs(distanceToGraphValue(p+vec2(0,fEps))-d0);\n    float dxm = abs(distanceToGraphValue(p-vec2(fEps,0))-d0);\n    float dym = abs(distanceToGraphValue(p-vec2(0,fEps))-d0);\n    return vec2(max(dxp,dxm),max(dyp,dym))\/fEps;\n}\n\n\/\/Note : the valueGradient could be computed at the end, just like the normal is computed \n\/\/       using the global terrain\/map function. In fact, the entire graph program could probably be written\n\/\/       just like a distance field.\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    \/\/uv : x:[0,1]\n    vec2 uv = fragCoord.xy \/ iResolution.xx;\n    \n    \/\/Vertical span for a single signal\n    float vSpan = VERTICAL_UNITS*(iResolution.x\/iResolution.y);\n    g_animTime = iTime;\n\t\n    \/\/<Distance To Graph Value>\n    float d = distanceToGraphValue(uv); \/\/Vertical Distance\n    vec2 aGrad = absGrad(uv,d); \/\/Gradient\n    d = d\/length(aGrad);        \/\/Slope compensation, to keep the line width constant.\n    \/\/<\/Distance To Graph Value>\n    \n    \/\/<Distance To Derivative Line>\n    float der = distToAnalyticDerivatives(uv);\n    \/\/<\/Distance To Graph Value>\n    \n    \/\/<Background + graph window separation>\n    float dSigWin = abs(fract((uv.y)*vSpan+0.5)-0.5);\n    float cSigWin = smoothstep(0.0, 0.005*VERTICAL_UNITS, dSigWin);\n    vec3 cBack = mix(vec3(0,0,0.8),vec3(1),cSigWin);\n    \/\/<\/Background + graph window separation>\n    \n    \/\/Darken the background along plot lines\n    cBack *= smoothstep(0.0, 0.003, d); \/\/Close = 0(Black), Far(>.003) = 1(White)\n    \n    \/\/Mix derivative Color with whatever is behind\n    float derivativeLineIntensity = 1.0-smoothstep(0.0, 0.003, der);\n    cBack = mix(cBack,vec3(1,0.2,0.2),derivativeLineIntensity);\n    \n    \/\/Return Final Color\n\tfragColor = vec4(cBack, 1);\n}","name":"Image","description":"","type":"image"}]},{"ver":"0.1","info":{"id":"ld3XRr","date":"1457309810","viewed":2188,"name":"Dirty Water","username":"Bers","description":"A \"sunset dome\" I made a while ago recycled to test water reflections.","likes":31,"published":3,"flags":0,"usePreview":0,"tags":[]},"renderpass":[{"inputs":[{"id":"4sfGRn","filepath":"\/media\/a\/fb918796edc3d2221218db0811e240e72e340350008338b0c07a52bd353666a6.jpg","previewfilepath":"\/media\/ap\/fb918796edc3d2221218db0811e240e72e340350008338b0c07a52bd353666a6.jpg","type":"texture","channel":1,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"Xsf3zn","filepath":"\/media\/a\/f735bee5b64ef98879dc618b016ecf7939a5756040c2cde21ccb15e69a6e1cfb.png","previewfilepath":"\/media\/ap\/f735bee5b64ef98879dc618b016ecf7939a5756040c2cde21ccb15e69a6e1cfb.png","type":"texture","channel":0,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"false","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"\/\/ Author : S\u00c3\u00a9bastien B\u00c3\u00a9rub\u00c3\u00a9\n\/\/ Created : Dec 2015\n\/\/ Modified : Jan 2016\n\/\/\n\/\/ For this shader, a \"sunset dome\" I made a while ago was recycled to test Image-Based Lighting\n\/\/ PBR materials (water reflection). Not much effort was invested in the wave movement (sines), the focus\n\/\/ was rather on shimmering\/reflection.\n\/\/\n\/\/ Still a lot of room for improvement, most notably:\n\/\/  -IBL PBR Material is expensive\n\/\/  -Sampling pattern artifacts\n\/\/  -Rocky formation look like bad CG from the '80s :). I need to improve my generative\n\/\/   modeling skills.\n\/\/  -Water surface lighting missing over reflexions.\n\/\/  -Sky dome does not look good in some angles. Need to work on this too.\n\/\/  -Fog, lens flares, etc.\n\/\/\n\/\/ License : Creative Commons Non-commercial (NC) license\n\/\/\n\n\/\/----------------------\n\/\/ Constants \/ enums\nconst float BUMP_MAP_UV_SCALE = 0.020;\nconst float MAX_DIST = 2000.0;\nconst float PI = 3.14159;\nconst vec3 LColor = vec3(1,0.95,0.7)*0.25;\nconst int MATERIALID_NONE      = 0;\nconst int MATERIALID_FLOOR     = 1;\nconst int MATERIALID_SKY       = 2;\nconst int MATERIALID_STONE     = 3;\nconst int MATERIALID_WATER     = 4;\nconst int MATERIALID_B         = 5;\nconst int MATERIALID_C         = 6;\nconst int MATERIALID_D         = 7;\nconst int DEBUG_RAYLEN  = 0;\nconst int DEBUG_GEODIST = 1;\nconst int DEBUG_NORMAL  = 2;\nconst int DEBUG_MATUVW  = 3;\nconst int DEBUG_MATID   = 4;\nconst int DEBUG_ALPHA   = 5;\nconst float fWaterVariation = 0.35;\nconst float fMinWaterHeight = 0.0;\n\n\/\/----------------------\n\/\/ Camera\nstruct Cam { vec3 R; vec3 U; vec3 D; vec3 o; }; \/\/Right, Up, Direction, origin\nCam    CAM_animate(vec2 uv, float fTime);\nvec3   CAM_getRay(Cam cam, vec2 uv);\n\n\/\/----------------------\n\/\/ sampling functions\nfloat SAMPLER_trilinear(vec3 p); \/\/Volumetric function\nvec3 SAMPLER_triplanarChannel1(vec3 p, vec3 n); \/\/Surface triplanar projection\nvec3 NOISE_roughnessMap(vec3 p, float rayLen);\n\n\/\/ color conversion\nvec3 hsv2rgb(vec3 c)\n{\n    vec4 K = vec4(1.0, 2.0 \/ 3.0, 1.0 \/ 3.0, 3.0);\n    vec3 p = abs(fract(c.xxx + K.xyz) * 6.0 - K.www);\n    return c.z * mix(K.xxx, clamp(p - K.xxx, 0.0, 1.0), c.y);\n}\n\n\/\/----------------------\n\/\/ Analytic Intersections\nfloat RAYCAST_plane(vec3 o, vec3 d, vec3 po, vec3 pn)\n{\n    return dot(po-o,pn)\/dot(d,pn); \n}\nfloat RAYCAST_floor(vec3 ro, vec3 rd)\n{\n\tfloat t = RAYCAST_plane(ro,rd,vec3(0,0,0),vec3(0,1,0));\n    return (t<0.0)?MAX_DIST:t;\n}\n\nfloat RAYCAST_sphere(vec3 o, vec3 d, vec3 c, float r)\n{\n    vec3 dn = d;\n    dn = normalize(dn);\n\tfloat a = RAYCAST_plane(o,d,c,normalize(d));\n    vec3 p1 = o+a*d;\n    vec3 vp1c = p1-c;\n    float dc2 = dot(vp1c,vp1c);\/\/norm2\n    float r2 = r*r;\n    if( dc2 < r2)\n    {\n        \/\/float fDepth2 = sqrt(r2-dc2);\n        return a+sqrt(r2-dc2);\n\t}\n    return -1.;\n}\n\nvec3 SKY_grad(float h, float fTime)\n{\n    \/\/Gradient values sampled from a reference image.\n    const vec3 r1 = vec3(195.\/255.,43.\/255.,6.\/255.);\n\tconst vec3 r2 = vec3(228.\/255.,132.\/255.,28.\/255.);\n\tconst vec3 bg1 = vec3(168.\/255.,139.\/255.,83.\/255.);\n\tconst vec3 bl1 = vec3(86.\/255.,120.\/255.,147.\/255.);\n\tconst vec3 bl2 = vec3(96.\/255.,130.\/255.,158.\/255.);\n\tconst vec3 bl3 = vec3(96.\/255.,130.\/255.,218.\/255.);\n    \n    h = h-h*0.25*sin(fTime);\n    vec3 c;\n    if(h<0.25)\n        c = mix(r1,r2,4.*h);\n    else if(h<0.5)\n        c = mix(r2,bg1,4.*(h-0.25));\n    else\n    \tc = mix(bg1,bl2,2.*(h-0.5));\n    \n    float light = 1.0+0.25*sin(fTime);\n    return mix(c,bl3,0.25+0.25*sin(fTime))*light;\n}\n\nvec3 SKY_main(vec3 p, float fTime, bool addSun)\n{\n    vec3 sunPos = vec3(0.,sin(fTime),cos(fTime));\n    fTime = -1.95;\n    \n    p = normalize(p);\n    vec3 nSunPos = normalize(sunPos);\n        \n    \/\/Pseudo - Rayleight scattering (daylight blue)\n    float anlgePosSun_FromOrigin = acos(dot(p,nSunPos));\n    anlgePosSun_FromOrigin = clamp(anlgePosSun_FromOrigin,0.,PI);\n    float posAngle = asin(p.y);\n    \n    float fAtmosphereThickness = 2.0;\n    float fTraversalDistance = 0.35*cos(sqrt(clamp(12.3*posAngle,0.0,100.0))-0.8)+0.65;\n    \n    float dayV = 0.25+0.666*(0.3+fTraversalDistance)*(dot(p,nSunPos)+1.0)\/2.0;\n    float dayS = 0.9-fTraversalDistance\/1.60;\n    float dayH = mix(0.61,0.65,p.y);\n    \n    vec3 day = hsv2rgb(vec3(dayH,dayS,dayV));\n    vec3 gradS = SKY_grad(0.75-0.75*dot(p,nSunPos)*clamp(1.0-3.0*p.y,0.0,1.0)*fTraversalDistance,fTime);\n    vec3 gradF = (gradS+day)\/2.0;\n    \n    if(addSun)\n    {\n\t\t\/\/1\/x for rapid rise close from d=0\n\t\t\/\/2^abs(x) for soft long range ramp down\n        float d = length(sunPos-p)*10.;\n    \tfloat I = 0.015\/abs(d)+pow(2.,-abs(d*2.))*0.4;\n    \tvec3 c = vec3(255.\/255.,213.\/255.,73.\/255.);\n\t    gradF += c*I*2.0;\n    }\n        \n    \/\/Distribute the excess R light on other components\n    if(gradF.x > 1.0)\n        gradF = gradF + vec3(0,(gradF.x-1.0)\/1.5,(gradF.x-1.0)\/0.75);\n   \treturn gradF;\n}\n\n\/\/------------------------------------------------------\n\/\/ Water stuff\n\/\/------------------------------------------------------\n#define remap_01(a) (0.5+0.5*a)\nfloat WATER_height(vec2 p,float fTime)\n{\n    const float HF_I = 0.005;\n    const float HF_F1 = 6.01;\n    const float HF_F2 = 7.27;\n    fTime = -fTime;\n    return fMinWaterHeight+fWaterVariation*(0.495+0.495*sin(length(p-vec2(12,-5))+fTime*1.5)\n               \/* +0.15+0.15*sin(3.0*length(p-vec2(3,-12))+sin((iTime\/10.0)*0.05+2.0)*iTime*-1.)*\/\n                +HF_I*remap_01(sin(HF_F1*(length(p-vec2(2.5,-2.5))+fTime))))\n                +HF_I*remap_01(sin(HF_F2*(length(p-vec2(5,-25))+fTime)));\n}\nfloat WATER_heightLF(vec2 p,float fTime)\n{\n    fTime = -fTime;\n    return fMinWaterHeight+fWaterVariation*(0.495*remap_01(sin(length(p-vec2(0,0))+fTime*1.5)));\n}\nvec3 WATER_normal(vec3 p,float fTime)\n{\n    float eps = 0.1;\n    float h = WATER_height(p.xz,fTime);\n    vec3 px = p+vec3(eps,0,0);\n    vec3 pz = p+vec3(0,0,eps);\n    vec3 vx = vec3(eps,WATER_height(px.xz,fTime)-h,0  );\n    vec3 vz = vec3(  0,WATER_height(pz.xz,fTime)-h,eps);\n    vec3 n = normalize(cross(vz,vx));\n    return mix(n,vec3(0,1,0),clamp(abs(p.z)\/75.0,0.,1.));\n}\nvec3 WATER_intersec(vec3 o, vec3 d, float fTime)\n{   \n    \/\/Initialize at average water height.\n    float avgWaterHeight = fMinWaterHeight+fWaterVariation*0.5;\n    float t = RAYCAST_plane(o,d,vec3(0,avgWaterHeight,0),vec3(0,1,0));\n    if(t<0.0)\n        return vec3(MAX_DIST);\n    vec3 p = o+t*d; \n    float rLen = 1.0\/abs(d.y);\n    for(int i=0; i < 10; ++i)\n    {\n        float h = WATER_heightLF(p.xz, fTime);\n        float dist = p.y-h;\n        p += d*dist;\n        if(abs(dist)<0.001) \/\/refine until acceptable.\n            break;\n    }\n    return p;\n}\n\n\/\/------------------------------------------------------\n\/\/ Geometry stuff\n\/\/------------------------------------------------------\n\nfloat DF_cube( vec3 p, vec3 size );\nfloat DF_sphere( vec3 p, float rad );\nfloat DF_merge( float d1, float d2 );\nfloat DF_smoothMerge( float d1, float d2, float d3, float k );\nfloat sdCappedCylinder( vec3 p, vec2 h )\n{\n  vec2 d = abs(vec2(length(p.xz),p.y)) - h;\n  return min(max(d.x,d.y),0.0) + length(max(d,0.0));\n}\n\nstruct DF_out\n{\n    float d;\n    int matID;\n};\n\n\/\/::DF_composition\nDF_out DF_composition( in vec3 pos, const bool addNoise )\n{\n    const float noiseStrength = 0.3;\n    const float isoContour = 0.2;\n    const float xRepeatDist = 7.0;\n    float repeatedX = (fract(pos.x\/xRepeatDist+0.5)-0.5)*xRepeatDist;\n    float randomSeed = pos.x-repeatedX;\n    if(abs(pos.x) < xRepeatDist*1.5)\n    \tpos.x = repeatedX+((pos.x<xRepeatDist\/2.0)?0.:1.);\n    \n    \/\/Rotation matrix\n    const mat3 rx45 = mat3(1.000,+0.000,0.000,\n\t                       0.000,+0.707,0.707,\n\t                       0.000,-0.707,0.707);\n    const mat3 rz45 = mat3(+0.707,0.707,0.000,\n\t                       -0.707,0.707,0.000,\n\t                       +0.000,0.000,1.000);\n    const mat3 rxrz45 = rx45*rz45; \/\/Computed at compile time.\n    \n    vec3 pos_rx_rz = rxrz45*pos;\n\tfloat sd_water  = 10000.0;\n    vec3 objectCenter = vec3(0,1,abs(pos.x)\/4.0);\n    pos-=objectCenter;\n    \n    vec3 randomPos = vec3(2.5*sin(randomSeed*8.3),6.0,2.5*sin(randomSeed*2.2));\n    float randomRad = float(0.95+0.25*sin(randomSeed*8.3));\n    \n    \/\/Explanation: https:\/\/iquilezles.org\/articles\/distfunctions\n    float sd_cube = DF_cube(pos_rx_rz-rxrz45*randomPos, vec3(1,1,1)*0.9 );\n    float sd_cylA = sdCappedCylinder(pos-vec3(0,3.5,0),vec2(randomRad*1.25+0.2*sin(0.5*pos.y-1.9),2.1));\n    float sd_cylB = sdCappedCylinder(pos,              vec2(0.6,4.1));\n\tfloat sd_sphere = DF_sphere(pos    -vec3(0.0,1.1,1.0), 0.1 );\n    float dMin = DF_smoothMerge(sd_cylA,sd_cube,sd_cylB, 1.3);\n    dMin = min(sd_water,dMin);\n    \n    DF_out dfOut;\n    dfOut.d = dMin-isoContour;\n    dfOut.matID = MATERIALID_STONE;\n    \n    if(addNoise)\n    {\n    \tfloat mainFreq = 0.005;\n\t\tpos *= mainFreq;\n    \tfloat distNoiseA = 0.500*(-0.5+SAMPLER_trilinear(1.00*pos*vec3(1.0,5.0,1.0)));\n    \tfloat distNoiseB = 0.250*(-0.5+SAMPLER_trilinear(2.01*pos*vec3(0.8,2.0,1.2)+distNoiseA*0.02));\n    \tfloat distNoise = noiseStrength*(distNoiseA+distNoiseB);\n        dfOut.d = dMin-isoContour+distNoise;\n    }\n    \n    return dfOut;\n}\n\nvec3 DF_gradient( in vec3 p )\n{\n\tconst float eps = 0.01;\n\tvec3 grad = vec3(DF_composition(p+vec3(eps,0,0),true).d-DF_composition(p-vec3(eps,0,0),true).d,\n                     DF_composition(p+vec3(0,eps,0),true).d-DF_composition(p-vec3(0,eps,0),true).d,\n                     DF_composition(p+vec3(0,0,eps),true).d-DF_composition(p-vec3(0,0,eps),true).d);\n\treturn grad;\n}\n\nstruct rayMarchOut\n{\n\tfloat rayLen;\n    float geoDist;\n    vec3 hitPos;\n    bool bReflect;\n};\n\n\/\/::RAYMARCH_reflect\nrayMarchOut RAYMARCH_reflect( vec3 o, vec3 dir, float reflectLen, vec3 reflectDir )\n{\n    rayMarchOut rmOut;\n        \n    \/\/Learned from Inigo Quilez DF ray marching :\n    \/\/https:\/\/iquilezles.org\/articles\/raymarchingdf\n    float tmax = 100.0;\n\tfloat precis = 0.0001;\n    float t = 0.1;\n    float dist = MAX_DIST;\n    rmOut.bReflect = false;\n    vec3 p = vec3(0);\n    for( int i=0; i<40; i++ )\n    {\n        p = o+dir*t;\n\t    dist = DF_composition( o+dir*t,true).d;\n        \/\/This here allows the bouncing on water surface in a single ray marching loop\n        if(t>reflectLen && !rmOut.bReflect)\n        {\n            o=o+reflectLen*dir;\n            dir = reflectDir;\n            t=0.0;\n            rmOut.bReflect = true;\n        }\n        \n        if( abs(dist)<precis || t>tmax ) break;\n        t += dist;\n    }\n    \n    rmOut.rayLen = (t<tmax&&dist<0.1)?t:MAX_DIST;\n    rmOut.geoDist = dist;    \n    rmOut.hitPos = p;\n    return rmOut;\n}\n\nstruct TraceData\n{\n    float rayLen;\n    vec3  rayDir;\n    float geoDist;\n    vec3  normal;\n    int   matID;\n    bool  bReflect;\n    float fReflectDist;\n    vec3  vReflectNormal;\n};\n\nTraceData new_TraceData()\n{\n    TraceData td;\n    td.rayLen = 0.;\n    td.rayDir = vec3(0);\n    td.geoDist = 0.;\n    td.normal = vec3(0);\n    td.matID = MATERIALID_NONE;\n    td.bReflect = false;\n    td.fReflectDist = 0.0;\n    return td;\n}\n\nvec3 MAT_distanceFieldIsolines(vec2 uv);\n\nvec3 horizonColor(vec3 o, vec3 d, float fTime, bool addSun)\n{\n    float fSphereRad = 200.0;\n    vec3 spherePos = vec3(0,0,0);\n    float b = RAYCAST_sphere(o,d,spherePos,fSphereRad);\n    vec3 ph = o+b*d;\n    return SKY_main(ph\/fSphereRad,fTime,addSun);\n}\n\nvec3 PBR_HDRCubemap(vec3 sampleDir, float LOD_01, bool addSun)\n{\n    return pow(horizonColor(vec3(0), sampleDir, 0.10, addSun),vec3(2.2));\n}\n\n#define saturate(a) clamp(a,0.0,1.0)\nvec3 MAT_integrateHemisphere(vec3 normal)\n{\n    \/\/FIXME : Invalid for surfaces facing up.\n    vec3 up = vec3(0,1,0.00);\n    vec3 right = normalize(cross(up,normal));\n    up = cross(normal,right);\n\n    vec3 sampledColour = vec3(0,0,0);\n    float index = 0.;\n    float phi = 0.;\n    const int nMERIDIANS = 3;\n    const int nPARALLELS = 3;\n    for(int i = 0; i < nMERIDIANS; ++i)\n    {\n        float theta = 0.0;\n        for(int j=0; j < nPARALLELS; ++j)\n        {\n            vec3 temp = cos(phi) * right + sin(phi) * up;\n            vec3 sampleVector = cos(theta) * normal + sin(theta) * temp;\n            vec3 linearGammaColor = PBR_HDRCubemap(sampleVector,0.0, false);\n            \/\/<FIXME HACK : reduce lightness when the vector direction is down>\n\t\t\tlinearGammaColor *= saturate(1.0-dot(sampleVector+vec3(0,-0.3,0),vec3(0,-1,0)));\n            sampledColour += linearGammaColor * \n                                      cos(theta) * sin(theta);\n            index ++;\n            theta += 0.5*PI\/float(nPARALLELS);\n        }\n        phi += 2.0*PI\/float(nMERIDIANS);\n    }\n\n    return vec3( PI * sampledColour \/ index);\n}\n\nconst float F_DIELECTRIC_WATER   = 1.33; \/\/@550nm\n\n\/\/#define saturate(a) clamp(a,0.0,1.0)\nvec3 PBR_Equation(vec3 V, vec3 L, vec3 N, float roughness, vec3 ior_n, vec3 ior_k, const bool metallic, const bool bIBL)\n{\n    \/\/<http:\/\/www.codinglabs.net\/article_physically_based_rendering_cook_torrance.aspx>\n    float cosT = saturate( dot(L, N) );\n    float sinT = sqrt( 1.0 - cosT * cosT);\n    \n\tvec3 H = normalize(L+V);\n\tfloat NdotH = dot(N,H);\/\/Nn.H;\n\tfloat NdotL = dot(N,L);\/\/Nn.Ln;\n\tfloat VdotH = dot(V,H);\/\/Vn.H;\n    float NdotV = dot(N,V);\/\/Nn.Vn;\n    \n     \/\/<Distribution Term>\n    float PI = 3.14159;\n    float alpha2 = roughness * roughness;\n    float NoH2 = NdotH * NdotH;\n    float den = NoH2*(alpha2-1.0)+1.0;\n    float D_ABL = 1.0; \/\/Distribution term is externalized from IBL version\n    if(!bIBL)\n        D_ABL = (NdotH>0.)?alpha2\/(PI*den*den):0.0; \/\/GGX Distribution.\n\t\/\/<\/Distribution>\n    \n    \/\/<Fresnel Term>\n    vec3 F;\n    if(metallic)\/\/(TODO: Fix binary condition with a material layering strategy).\n    {\n        \/\/<Source : http:\/\/sirkan.iit.bme.hu\/~szirmay\/fresnel.pdf p.3 above fig 5>\n        float cos_theta = 1.0-NdotV;\/\/REVIEWME : NdotV or NdotL ?\n        F =  ((ior_n-1.)*(ior_n-1.)+ior_k*ior_k+4.*ior_n*pow(1.-cos_theta,5.))\n\t\t                 \/((ior_n+1.)*(ior_n+1.)+ior_k*ior_k);\n        \/\/<\/http:\/\/sirkan.iit.bme.hu\/~szirmay\/fresnel.pdf p.3 above fig 5>\n    }\n    else\n    {\n        \/\/Fresnel Schlick Dielectric formula\n        vec3 F0 = abs ((1.0 - ior_n) \/ (1.0 + ior_n));\n  \t\tF = F0 + (1.-F0) * pow( 1. - VdotH, 5.);\n    }\n    \/\/<\/Fresnel>\n    \n    \/\/<Geometric term>\n    \/\/<Source : Real Shading in Unreal Engine 4 2013 Siggraph Presentation>\n    \/\/https:\/\/de45xmedrsdbp.cloudfront.net\/Resources\/files\/2013SiggraphPresentationsNotes-26915738.pdf p.3\/59\n    float k = bIBL?(roughness*roughness\/2.0):(roughness+1.)*(roughness+1.)\/8.; \/\/Schlick model (IBL) : Disney's modification to reduce hotness (ABL)\n    float Gl = max(NdotL,0.)\/(NdotL*(1.0-k)+k);\n    float Gv = max(NdotV,0.)\/(NdotV*(1.0-k)+k);\n    float G = Gl*Gv;\n    \/\/<\/Real Shading in Unreal Engine 4 2013 Siggraph Presentations>\n    \/\/<\/Geometric term>\n    \n    \/\/Two flavors of the PBR equation seen pretty much everywhere (IBL\/ABL).\n    \/\/Note : Distribution (D) is externalized from IBL version, see source link.\n    \/\/Personal addition : This parameter softens up the transition at grazing angles (otherwise too sharp IMHO).\n    float softTr = 0.1; \/\/ Valid range : [0.001-0.25]. Will reduce reflexivity on edges if too high.\n    \/\/Personal addition : This parameter limits the reflexivity loss at 90deg viewing angle (black spot in the middle?).\n    float angleLim = 0.15; \/\/ Valid range : [0-0.75] (Above 1.0, become very mirror-like and diverges from a physically plausible result)\n    \/\/<Source : http:\/\/www.codinglabs.net\/article_physically_based_rendering_cook_torrance.aspx>\n    if(bIBL)\n        return (F*G*(angleLim+sinT)\/(angleLim+1.0) \/ (4.*NdotV*saturate(NdotH)*(1.0-softTr)+softTr)); \/\/IBL\n    else\n        return D_ABL*F*G \/ (4.*NdotV*NdotL*(1.0-softTr)+softTr);\t\/\/ABL\n    \/\/<Source : http:\/\/www.codinglabs.net\/article_physically_based_rendering_cook_torrance.aspx>\n}\n\n\/\/Arbitrary axis rotation (around u, normalized)\nmat3 rotateAround( vec3 u, float t )\n{\n    \/\/From wikipedia\n    float c = cos(t);\n    float s = sin(t);\n    \/\/  _        _   _           _     _                    _ \n    \/\/ |_px py pz_| | m11 m21 m31 |   | px*m11+py*m21+pz*m31 |\n    \/\/              | m12 m22 m32 | = | px*m12+py*m22+pz*m32 |\n    \/\/              |_m13 m23 m33_|   |_px*m13+py*m23+pz*m33_|\n    return mat3(  c+u.x*u.x*(1.-c),     u.x*u.y*(1.-c)-u.z*s, u.x*u.z*(1.-c)+u.y*s,\n\t              u.y*u.x*(1.-c)+u.z*s, c+u.y*u.y*(1.-c),     u.y*u.z*(1.-c)-u.x*s,\n\t              u.z*u.x*(1.-c)-u.y*s, u.z*u.y*(1.-c)+u.x*s, c+u.z*u.z*(1.-c) );\n}\n\n#define MOD3 vec3(.1031,.11369,.13787)\nvec2 hash22(vec2 p) \/\/From DaveHoskin's hash without sine\n{\n\tvec3 p3 = fract(vec3(p.xyx) * MOD3);\n    p3 += dot(p3.zxy, p3.yzx+19.19);\n    return fract(vec2((p3.x + p3.y)*p3.z, (p3.x+p3.z)*p3.y));\n}\n\nvec3 PBR_jitterSample(vec3 sampleDir, float roughness, float e1, float e2, out float range)\n{\n    \/\/Importance sampling section:\n    \/\/<http:\/\/www.codinglabs.net\/article_physically_based_rendering_cook_torrance.aspx>\n    range = atan( roughness*sqrt(e1)\/sqrt(1.0-e1) );\n\tfloat phi = 2.0*3.14159*e2;\n\t\/\/<http:\/\/www.codinglabs.net\/article_physically_based_rendering_cook_torrance.aspx>\n    \n    \/\/FIXME : Invalid for surfaces facing up.\n\tvec3 up = vec3(0,1,0); \/\/arbitrary\n\tvec3 tAxis = cross(up,sampleDir);\n\tmat3 m1 = rotateAround(normalize(tAxis),range);\n\tmat3 m2 = rotateAround(normalize(sampleDir), phi);\n        \n\treturn sampleDir*m1*m2;\n}\n\nvec3 PBR_visitSamples(vec3 V, vec3 N, float roughness, bool metallic, vec3 ior_n, vec3 ior_k )\n{\n    vec3 vCenter = reflect(-V,N);\n    \n    \/\/<Randomized Samples>\n    float randomness_range = 0.75; \/\/Cover only the closest 75% of the distribution. Reduces range, but improves stability.\n    float fIdx = 0.0;              \/\/valid range = [0.5-1.0]. Note : it is physically correct at 1.0.\n    const int iter_rdm = 5;\n    const float w_rdm = 1.0\/float(iter_rdm);\n    vec3 totalRandom = vec3(0.0);\n    for(int i=0; i < iter_rdm; ++i)\n    {\n        \/\/Random jitter\n        \/\/There is a scaling issue here, where scaling impacts noise precision.\n        vec2 jitter = hash22(fIdx*100.0+vCenter.xy*100.0+fract(iTime)*0.001);\n    \tfloat range = 0.;    \n        vec3 sampleDir = PBR_jitterSample(vCenter, roughness, jitter.x*randomness_range, jitter.y, range);\n        vec3 sampleColor = PBR_HDRCubemap(sampleDir,range\/0.29,true);\n        vec3 contribution = PBR_Equation(V, sampleDir, N, roughness, ior_n, ior_k, metallic, true)*w_rdm;\n    \ttotalRandom += contribution*sampleColor;\n\t\t++fIdx;\n    }\n    \/\/<\/Randomized Samples>\n    \n    \/\/<Fixed Samples : less physically correct, but more stable>\n    \/\/https:\/\/www.shadertoy.com\/view\/4dt3Dj\n    fIdx = 0.0;\n    const int iter_fixed = 15;\n    const float w_fixed = 1.0\/float(iter_fixed);\n    vec3 totalFixed = vec3(0.0);\n    for(int i=0; i < iter_fixed; ++i)\n    {\n        \/\/Stable pseudo-random jitter (to improve stability with low sample count)\n        \/\/Beware here! second component controls the sampling pattern \"swirl\", and it must be choosen \n        \/\/             so that samples do not align by doing complete 360deg cycles at each iteration.\n        vec2 jitter = vec2( clamp(w_fixed*fIdx,0.0,0.50),\n                            fract(w_fixed*fIdx*1.25)+3.14*fIdx);\n        float range = 0.;\n        vec3 sampleDir = PBR_jitterSample(vCenter, roughness, jitter.x, jitter.y, range);\n        vec3 sampleColor = PBR_HDRCubemap(sampleDir,range\/0.29,true);\n        vec3 contribution = PBR_Equation(V, sampleDir, N, roughness, ior_n, ior_k, metallic,true)*w_fixed;\n        totalFixed += contribution*sampleColor;\n\t\t++fIdx;\n    }\n    \/\/<\/Fixed Samples>\n    \n    return (totalRandom*float(iter_rdm)+totalFixed*float(iter_fixed))\/(float(iter_rdm)+float(iter_fixed));\n}\n\nfloat RAYMARCH_DFSS( vec3 o, vec3 L, float coneWidth )\n{\n    \/\/(45deg: sin\/cos = 1:1)\n    float minAperture = 1.0; \n    float t = 0.0;\n    float dist = MAX_DIST;\n    for( int i=0; i<5; i++ )\n    {\n        vec3 p = o+L*t; \/\/Sample position = ray origin + ray direction * travel distance\n        float dist = DF_composition( p, false ).d;\n        float curAperture = dist\/t; \/\/Aperture ~= cone angle tangent (sin=dist\/cos=travelDist)\n        minAperture = min(minAperture,curAperture);\n        \n        t += dist;\n    }\n    \n    \/\/The cone width controls shadow transition. The narrower, the sharper the shadow.\n    return saturate(minAperture\/coneWidth); \/\/Range = [0.0-1.0] : 0 = shadow, 1 = fully lit.\n}\n\nfloat RAYMARCH_DFAO( vec3 o, vec3 N, float isoSurfaceValue)\n{\n    \/\/Variation of : https:\/\/www.shadertoy.com\/view\/Xds3zN\n    \/\/Interesting reads:\n    \/\/https:\/\/docs.unrealengine.com\/latest\/INT\/Engine\/Rendering\/LightingAndShadows\/DistanceFieldAmbientOcclusion\/index.html#howdoesitwork?\n    \/\/Implementation notes:\n    \/\/-Doubling step size at each iteration\n    \/\/-Allowing negative distance field values to contribute\n    \/\/-Not reducing effect with distance (specific to this application)\n    float MaxOcclusion = 0.0;\n    float TotalOcclusion = 0.0;\n    const int nSAMPLES = 4;\n    float stepSize = 0.11\/float(nSAMPLES);\n    for( int i=0; i<nSAMPLES; i++ )\n    {\n        float t = 0.01 + stepSize;\n        \/\/Double distance each iteration (only valid for small sample count, e.g. 4)\n        stepSize = stepSize*2.0;\n        float dist = DF_composition( o+N*t, true ).d-isoSurfaceValue;\n        \/\/Occlusion factor inferred from the difference between the \n        \/\/distance covered along the ray, and the distance from other surrounding geometry.\n        float occlusion = saturate(t-dist);\n        TotalOcclusion += occlusion;\/\/Not reducing contribution on each iteration\n        MaxOcclusion += t;\n    }\n    \n    return saturate(1.0-TotalOcclusion\/(MaxOcclusion));\n}\n\nfloat MAT_processRoughness(float fRoughness, vec3 matColor, TraceData traceData, vec3 pos, vec3 N)\n{\n    if(traceData.matID==MATERIALID_WATER)\n    {\n        float fClamp = iMouse.y\/iResolution.x;\n    \tfRoughness = clamp((fRoughness)*1.0,fClamp,3.0)-fClamp; \n    \tfRoughness *= 0.25;\n        \/\/distance fade\n        fRoughness *= (1.0-saturate(traceData.rayLen\/95.0));\n        fRoughness += 0.15*saturate(traceData.rayLen\/25.0);\n    }\n    else if(traceData.matID==MATERIALID_STONE)\n    {\n        float heightFromWater = pos.y-(fMinWaterHeight+fWaterVariation);\n        float texRoughness = 0.05+smoothstep(0.3,0.6,matColor.g);\n        float inRoughness = smoothstep(0.3,0.7,fRoughness);\n\t\tfRoughness = (texRoughness+inRoughness)*0.5;\n        \n        fRoughness += 0.3*heightFromWater;\n        fRoughness *= (0.2+0.8*inRoughness);\n        fRoughness -= 0.6*(1.0-dot(N,vec3(0,1,0)));\n    }\n    return fRoughness;\n}\n\nvec3 MAT_getRoughnessPos(const int matID, vec3 surfacePos )\n{\n    vec3 lookupPos = vec3(0);\n    if(matID==MATERIALID_WATER)\n    {\n        lookupPos = vec3(surfacePos.xz*0.35-0.2*iTime,0).xzy;\n    }\n    else if(matID==MATERIALID_STONE)\n    {\n        lookupPos = vec3(surfacePos.xyz*0.2);\n    }\n    return lookupPos;\n}\n\n\/\/::MAT_apply\nvec4 MAT_apply(vec3 pos, TraceData traceData)\n{\n    \/\/Water reflection case : replace the material\n    if(traceData.bReflect && traceData.fReflectDist < 1000.0)\n    {\n        vec3 dReflect = reflect(traceData.rayDir,traceData.normal);\n        traceData.rayLen = traceData.fReflectDist;\n        traceData.normal = traceData.vReflectNormal;\n        pos  = pos+traceData.fReflectDist*dReflect;\n        traceData.matID = MATERIALID_STONE;\n    }\n    \n    \/\/L should bind with light position\n    vec3 L = normalize(vec3(0,0.2,1));\n    vec3 N = traceData.normal;\n    vec3 V = normalize(-traceData.rayDir);\n    float dfss = (traceData.matID==MATERIALID_SKY)?1.0:RAYMARCH_DFSS( pos+L*0.01, L, 0.2);\n    \n    \/\/<Material parameters>\n    vec3 vDiff = vec3(0);\n    float dfao = 1.0;\n    vec3 matColor = vec3(1);\n    float LI = 1.0;\n\tif(traceData.matID==MATERIALID_WATER)\n    {\n        LI = 0.5;\n        \/\/distance stabilization\n        N = mix(N,vec3(0,1,0),0.9*saturate(traceData.rayLen\/25.0));\n    }\n    else if(traceData.matID==MATERIALID_STONE)\n    {\n        LI = 2.0;\n        matColor = SAMPLER_triplanarChannel1(pos*0.5,traceData.normal);\n            \n        vDiff = matColor*MAT_integrateHemisphere(N);\n        dfao = RAYMARCH_DFAO( pos, N, 0.02);\n        vDiff *= (0.5+0.25*dfss);\n    }\n    \/\/<Material parameters>\n    \n    vec3 roughness_lookupPos = MAT_getRoughnessPos(traceData.matID,pos);\n    vec3 tex = NOISE_roughnessMap(roughness_lookupPos*306., traceData.rayLen);\n    float fRoughness = (tex.x+tex.y+tex.z)\/3.0;\n    fRoughness = MAT_processRoughness(fRoughness, matColor, traceData, pos, N);\n    \n    \/\/Single light & Image based lighting\n    vec3 I_L = PBR_Equation(V, L, N, fRoughness*0.5, vec3(1)*F_DIELECTRIC_WATER, vec3(0), false, false);\n    vec3 I_IBL = PBR_visitSamples(V, N, fRoughness, false, vec3(1)*F_DIELECTRIC_WATER, vec3(0));\n    \n    if(traceData.matID==MATERIALID_STONE)\n    {\n        if(traceData.bReflect)\n        {\n            LI *= 0.05;\n\t\t}\n    }\n    \n    vec3 col = matColor*dfss*(LColor*I_L)\n            +  LI*matColor*I_IBL*(0.5+0.5*dfss) \/\/Remove half the Image-Based lighting in the shadow.\n            +  vDiff;\n    col *= dfao;\n    \n    if(traceData.matID==MATERIALID_STONE)\n    {\n        if(traceData.bReflect)\n        {\n            col *= 0.6;\n\t\t}\n    }\n    \n    if(traceData.matID==MATERIALID_WATER)\n    {\n        \/\/<normal-based edge antialiasing>\n        \/\/When the normal direction \n        vec3 backgroundColor = PBR_HDRCubemap(traceData.rayDir, 0.0,true).xyz;\n        float aaAmount = 0.02;\n        if(dot(N,traceData.rayDir) > -aaAmount)\n        {\n            float smoothFactor = 1.0-clamp(-dot(N,traceData.rayDir)\/(aaAmount), 0.0, 1.0);\n            col.rgb = mix(col.rgb, backgroundColor, smoothFactor);\n        }\n        \/\/<\/normal-based edge antialiasing>\n    }\n    else if(traceData.matID==MATERIALID_SKY)\n    {\n        return PBR_HDRCubemap(traceData.rayDir, 0.0,true).xyzz;\n    }\n    \n    return vec4(col,1);\n}\n\nTraceData TRACE_getFront(const in TraceData tDataA, const in TraceData tDataB)\n{\n    if(tDataA.rayLen<tDataB.rayLen)\n    {\n        return tDataA;\n    }\n    else\n    {\n        return tDataB;\n    }\n}\n\n\/\/o=origin, d = direction\n\/\/::TRACE_geometry\nTraceData TRACE_geometry(vec3 o, vec3 d)\n{\n    TraceData skyInfo;\n    skyInfo.rayLen  = MAX_DIST-1.0;\n    skyInfo.rayDir  = d;\n\tskyInfo.geoDist = 0.0;\n\tskyInfo.normal  = -d; \/\/Shere center\n\tskyInfo.matID   = MATERIALID_SKY;\n    \n    TraceData waterInfo;\n    vec3 pWater = WATER_intersec(o, d, iTime);\n    waterInfo.rayDir  = d;\n    waterInfo.rayLen  = length(pWater-o);\n    waterInfo.geoDist = 0.0;\/\/waterHeight(;\n    waterInfo.normal  = WATER_normal(pWater,iTime);\n    waterInfo.matID   = MATERIALID_WATER;\n    waterInfo.bReflect = false;\n\n    vec3 dReflect = reflect(waterInfo.rayDir,waterInfo.normal);\n\trayMarchOut rmOut = RAYMARCH_reflect( o, d, waterInfo.rayLen, dReflect );\n    vec3 dfHitPosition = rmOut.hitPos;\n\tvec3 DF_normal = normalize(DF_gradient(dfHitPosition));\n    \n    if(rmOut.bReflect)\n    {\n        waterInfo.bReflect = true;\n        waterInfo.fReflectDist = rmOut.rayLen;\n        waterInfo.vReflectNormal = DF_normal;\n        return TRACE_getFront(skyInfo,waterInfo);\n    }\n    else\n    {\n        TraceData terrainInfo;\n    \tterrainInfo.rayDir     = d;\n    \tterrainInfo.rayLen     = rmOut.rayLen;\n    \tterrainInfo.geoDist    = rmOut.geoDist;\n    \tterrainInfo.normal     = normalize(DF_gradient(dfHitPosition));\n    \tterrainInfo.matID = MATERIALID_STONE;\n        return TRACE_getFront(TRACE_getFront(skyInfo,terrainInfo),waterInfo);\n    }\n}\n\nvec3 TRACE_debug(TraceData traceData, int elemID)\n{\n    if(elemID==DEBUG_RAYLEN)  return vec3(log(traceData.rayLen)*0.1);\n    if(elemID==DEBUG_GEODIST) return vec3(traceData.geoDist);\n    if(elemID==DEBUG_NORMAL)  return traceData.normal;\n    if(elemID==DEBUG_MATID)   return traceData.matID==MATERIALID_WATER?vec3(1):\n                                     vec3(traceData.matID==MATERIALID_FLOOR?1:0,\n                                          traceData.matID==MATERIALID_B?1:0,\n                                          traceData.matID==MATERIALID_SKY?1:0);\n    return vec3(0);\n}\n\nvec3 POST_ProcessFX(vec3 c, vec2 uv)\n{\n    \/\/Vignetting\n    float lensRadius = 0.65;\n    uv \/= lensRadius;\n    float sin2 = uv.x*uv.x+uv.y*uv.y;\n    float cos2 = 1.0-min(sin2*sin2,1.0);\n    float cos4 = cos2*cos2;\n    c *= cos4;\n    \n    \/\/Gamma\n    c = pow(c,vec3(0.4545));\n    return c;\n}\n\n\/\/::main\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n\tvec2 uv = (fragCoord.xy-0.5*iResolution.xy) \/ iResolution.xx;\n    \n    \/\/[Insert supersampling logic here]\n    Cam cam = CAM_animate(uv,iTime);\n    vec3 d = CAM_getRay(cam,uv);\n    \n    vec3 c = vec3(0);\n    TraceData geometryTraceData = TRACE_geometry(cam.o, d);\n    \/\/fragColor.rgb = TRACE_debug(geometryTraceData, DEBUG_RAYLEN); return; \/\/OK\n    \/\/fragColor.rgb = TRACE_debug(geometryTraceData, DEBUG_GEODIST); return; \/\/OK\n    \/\/fragColor.rgb = TRACE_debug(geometryTraceData, DEBUG_NORMAL); return; \/\/OK\n    \/\/fragColor.rgb = TRACE_debug(geometryTraceData, DEBUG_MATID); return; \/\/OK\n    \n    vec3 ptGeo = cam.o+d*geometryTraceData.rayLen;\n    c = MAT_apply(ptGeo,geometryTraceData).rgb;\n    \n    \/\/No supersampling required for most PostProcessFX.\n    c = POST_ProcessFX(c,uv);\n    \n    fragColor = vec4(c,1.0);\n}\n\n\/\/----------------------\n\/\/ Camera\n\/\/::CAM\nCam CAM_lookAt(vec3 at, float fPitch, float dst, float rot) \n{ \n    Cam cam;\n    cam.D = vec3(cos(rot)*cos(fPitch),sin(fPitch),sin(rot)*cos(fPitch));\n    cam.U = vec3(-sin(fPitch)*cos(rot),cos(fPitch),-sin(fPitch)*sin(rot));\n    cam.R = cross(cam.D,cam.U); cam.o = at-cam.D*dst;\n    return cam;\n}\nCam CAM_mouseLookAt(vec3 at, float dst)\n{\n    vec2 res = iResolution.xy; vec2 spdXY = vec2(15.1416,4.0);\n    float fMvtX = (iMouse.x\/res.x)-0.535;\n    if(fMvtX>0.3) dst *= (1.0+(fMvtX-0.3)\/0.03);\n    else if(fMvtX<-0.3) dst *= (1.0-(fMvtX+0.3)\/(-0.2));\n\t\/\/fMvtX += iTime*0.0250;\/\/Auto turn\n    return CAM_lookAt(at,spdXY.y*((\/*iMouse.y*\/0.40)-0.5),dst,spdXY.x*fMvtX);\n}\nCam CAM_animate(vec2 uv, float fTime)\n{\n    float targetDistance = 12.5;\n    vec3 cam_tgt = vec3(-0.2,2,-0.1);\n    Cam cam = CAM_lookAt(cam_tgt, -0.05, targetDistance, 1.3+0.1*sin(iTime*0.1));\n    if(iMouse.z > 0.0) \/\/Mouse button down : user control\n    {\n    \tcam = CAM_mouseLookAt(cam_tgt, targetDistance);\n    }\n    return cam;\n}\n\nvec3 CAM_getRay(Cam cam,vec2 uv)\n{\n    uv *= 1.6;\n    return normalize(uv.x*cam.R+uv.y*cam.U+cam.D);\n}\nvec3 SAMPLER_triplanarChannel1(vec3 p, vec3 n)\n{\n    \/\/Idea from http:\/\/http.developer.nvidia.com\/GPUGems3\/gpugems3_ch01.html\n    \/\/Figure 1-23 Triplanar Texturing\n    float fTotal = abs(n.x)+abs(n.y)+abs(n.z);\n    return ( abs(n.x)*texture(iChannel1,p.zy).xyz\n            +abs(n.y)*texture(iChannel1,p.zx).xyz\n            +abs(n.z)*texture(iChannel1,p.xy).xyz)\/fTotal;\n}\nfloat SAMPLER_trilinear(vec3 p)\n{\n    const float TEXTURE_RES = 256.0; \/\/Noise texture resolution\n    p *= TEXTURE_RES;   \/\/Computation in pixel space (1 unit = 1 pixel)\n    vec3 pixCoord = floor(p);\/\/Pixel coord, integer [0,1,2,3...256...]\n    vec3 t = p-pixCoord;     \/\/Pixel interpolation position, linear range [0-1] (fractional part)\n    t = (3.0 - 2.0 * t) * t * t; \/\/interpolant easing function : linear->cubic\n    vec2 layer_translation = -pixCoord.y*vec2(37.0,17.0)\/TEXTURE_RES; \/\/noise volume stacking trick : g layer = r layer shifted by (37x17 pixels -> this is no keypad smashing, but the actual translation embedded in the noise texture).\n    vec2 layer1_layer2 = texture(iChannel0,layer_translation+(pixCoord.xz+t.xz+0.5)\/TEXTURE_RES,-100.0).xy; \/\/Note : +0.5 to fall right on pixel center\n    return mix( layer1_layer2.x, layer1_layer2.y, t.y ); \/\/Layer interpolation (trilinear\/volumetric)\n}\nvec4 SAMPLER_trilinearWithDerivative(vec3 p)\n{\n    \/\/To be honest, this is rather complex for the benefit it provides. Could have used something much simpler\n    \/\/for the roughness texture.\n\n    \/\/See : https:\/\/iquilezles.org\/articles\/morenoise\n\tconst float TEXTURE_RES = 256.0; \/\/Noise texture resolution\n    vec3 pixCoord = floor(p);\/\/Pixel coord, integer [0,1,2,3...256...]\n    \/\/noise volume stacking trick : g layer = r layer shifted by (37x17 pixels)\n    \/\/(37x17)-> this value is the actual translation embedded in the noise texture, can't get around it.\n\t\/\/Note : shift is different from g to b layer (but it also works)\n    vec2 layer_translation = -pixCoord.z*vec2(37.0,17.0)\/TEXTURE_RES;\n    vec2 c1 = texture(iChannel0,layer_translation+(pixCoord.xy+vec2(0,0)+0.5)\/TEXTURE_RES,-100.0).rg;\n    vec2 c2 = texture(iChannel0,layer_translation+(pixCoord.xy+vec2(1,0)+0.5)\/TEXTURE_RES,-100.0).rg; \/\/+x\n    vec2 c3 = texture(iChannel0,layer_translation+(pixCoord.xy+vec2(0,1)+0.5)\/TEXTURE_RES,-100.0).rg; \/\/+z\n    vec2 c4 = texture(iChannel0,layer_translation+(pixCoord.xy+vec2(1,1)+0.5)\/TEXTURE_RES,-100.0).rg; \/\/+x+z\n    vec3 x = p-pixCoord;     \/\/Pixel interpolation position, linear range [0-1] (fractional part)\n    vec3 x2 = x*x;\n    vec3 t = (6.*x2-15.0*x+10.)*x*x2; \/\/Ease function : 6x^5-15x^4+10^3\n        \n    \/\/Lower quad corners\n    float a = c1.x; \/\/(x+0,y+0,z+0)\n    float b = c2.x; \/\/(x+1,y+0,z+0)\n    float c = c3.x; \/\/(x+0,y+1,z+0)\n    float d = c4.x; \/\/(x+1,y+1,z+0)\n    \/\/Upper quad corners\n    float e = c1.y; \/\/(x+0,y+0,z+1)\n    float f = c2.y; \/\/(x+1,y+0,z+1)\n    float g = c3.y; \/\/(x+0,y+1,z+1)\n    float h = c4.y; \/\/(x+1,y+1,z+1)\n    \n    \/\/Trilinear noise interpolation : (1-t)*v1+(t)*v2, repeated along the 3 axis of the interpolation cube.\n    float za = ((a+(b-a)*t.x)*(1.-t.y)\n               +(c+(d-c)*t.x)*(   t.y));\n    float zb = ((e+(f-e)*t.x)*(1.-t.y)\n               +(g+(h-g)*t.x)*(   t.y));\n    float value = (1.-t.z)*za+t.z*zb;\n    \n    \/\/Derivative scaling (depends on texture lookup).\n    \/\/There is definitely a pattern here.\n\t\/\/This could be factorized\/optimized but I fear it would make it cryptic.\n    float sx =  ((b-a)+t.y*(a-b-c+d))*(1.-t.z)\n               +((f-e)+t.y*(e-f-g+h))*(   t.z);\n    float sy =  ((c-a)+t.x*(a-b-c+d))*(1.-t.z)\n               +((g-e)+t.x*(e-f-g+h))*(   t.z);\n    float sz =  zb-za;\n    \n    \/\/Ease-in ease-out derivative : (6x^5-2x^3)' = 6x-6x^2\n    vec3 d_xyz = (30.*x2-60.*x+30.)*x2;\n    \n    return vec4(value,\n\t            d_xyz.x*sx, \/\/Derivative x scaling\n                d_xyz.y*sy,\n                d_xyz.z*sz);\n}\n\/\/:NOISE_roughnessMap\nvec3 NOISE_roughnessMap(vec3 p, float rayLen)\n{\n    float f = iTime;\n    const mat3 R1  = mat3(0.500, 0.000, -.866,\n\t                     0.000, 1.000, 0.000,\n                          .866, 0.000, 0.500);\n    const mat3 R2  = mat3(1.000, 0.000, 0.000,\n\t                      0.000, 0.500, -.866,\n                          0.000,  .866, 0.500);\n    const mat3 R = R1*R2;\n    p *= BUMP_MAP_UV_SCALE;\n    p = R1*p;\n    vec4 v1 = SAMPLER_trilinearWithDerivative(p);\n    p = R1*p*2.021;\n    vec4 v2 = SAMPLER_trilinearWithDerivative(p);\n    p = R1*p*2.021+1.204*v1.xyz;\n    vec4 v3 = SAMPLER_trilinearWithDerivative(p);\n    p = R1*p*2.021+0.704*v2.xyz;\n    vec4 v4 = SAMPLER_trilinearWithDerivative(p);\n    \n    return (v1+0.5*(v2+0.25)\n\t          +0.4*(v3+0.25)\n\t          +0.6*(v4+0.25)).yzw;\n}\n\nfloat DF_sphere( vec3 p, float size )\n{\n\treturn length(p)-size;    \n}\n\nfloat DF_cube( vec3 p, vec3 size )\n{\n    vec3 dEdge = abs(p)-size; \/\/distance to cube edge, along each axis\n    float internalDist = max(dEdge.x,max(dEdge.y,dEdge.z)); \n    float externalDist = length(max(dEdge,vec3(0))); \n    return externalDist+min(internalDist,0.0);\n}\n\nfloat DF_merge( float d1, float d2 )\n{\n    return min(d1,d2);\n}\n\nfloat DF_smoothMerge( float d1, float d2, float d3, float k )\n{\n    return -log(exp(-k*d1)+exp(-k*d2)+exp(-k*d3))\/k;\n}","name":"Image","description":"","type":"image"}]},{"ver":"0.1","info":{"id":"MscSRr","date":"1457315759","viewed":2153,"name":"PerspectiveReprojection","username":"Bers","description":"Screen space parallel lines intersection (vanishing point) is used in order to compute a world space parallelogram. One of the basic principles of automated 3D scene reconstruction. Only a screen space quad input required (3D position is inferred).","likes":49,"published":3,"flags":0,"usePreview":0,"tags":[]},"renderpass":[{"inputs":[{"id":"4dXGRn","filepath":"\/media\/a\/10eb4fe0ac8a7dc348a2cc282ca5df1759ab8bf680117e4047728100969e7b43.jpg","previewfilepath":"\/media\/ap\/10eb4fe0ac8a7dc348a2cc282ca5df1759ab8bf680117e4047728100969e7b43.jpg","type":"texture","channel":1,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":"4dfGRn","filepath":"\/media\/a\/8de3a3924cb95bd0e95a443fff0326c869f9d4979cd1d5b6e94e2a01f5be53e9.jpg","previewfilepath":"\/media\/ap\/8de3a3924cb95bd0e95a443fff0326c869f9d4979cd1d5b6e94e2a01f5be53e9.jpg","type":"texture","channel":0,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"\/\/ Author : Sebastien Berube\n\/\/ Created : Dec 2015\n\/\/ Modified : Jan 2016\n\/\/\n\/\/ This shader uses the vanishing point on the image plane in order to infer the world space direction of parallel lines.\n\/\/ From 4 points (2D) on the image plane, it will use projective geometry properties in order to generate 4 points (3D) world space.\n\/\/ \n\/\/ This is a very important concept for 3D scene reconstruction from 2D images.\n\/\/\n\/\/ The one line that is important in this shader is : \"p1_to_p2 = dirVanishingPoint\", in function \"resolveAdjacentCorner()\".\n\/\/ What this means is : the 3D line starting from the camera center and going towards the vanishing point of 2 parallel lines \n\/\/                      are all parallel with each other (as all lines directed towards this vanishing point are parallel).\n\/\/                      Although parallel lines are nerver supposed to cross each other in reality, they however do on the \n\/\/                      projected image plane, and this allows computation of the vanishing point intersection in 2D first,\n\/\/                      and then inferring 3D direction by casting a ray from the camera center through this vanishing point\n\/\/                      on the image plane.\n\/\/\n\/\/ License : Creative Commons Non-commercial (NC) license\n\/\/\nconst vec2 SS1_BOTTOM_LEFT  = vec2( 0.180, 0.320);\nconst vec2 SS1_BOTTOM_RIGHT = vec2( 0.332, 0.360);\nconst vec2 SS1_TOP_RIGHT    = vec2( 0.332, 0.640);\nconst vec2 SS1_TOP_LEFT     = vec2( 0.180, 0.766);\n\nconst vec2 SS2_BOTTOM_LEFT  = vec2( 0.820, 0.343);\nconst vec2 SS2_BOTTOM_RIGHT = vec2( 0.970, 0.33);\nconst vec2 SS2_TOP_RIGHT    = vec2( 0.965, 0.745);\nconst vec2 SS2_TOP_LEFT     = vec2( 0.815, 0.675);\n    \nstruct Cam { vec3 R; vec3 U; vec3 D; vec3 O;}; \/\/R=Right, U=Up, D=Direction, O=Origin\nCam    CAM_lookAt(vec3 target, float pitchAngleRad, float dist, float theta);\nCam    CAM_mouseLookAt(vec3 at, float dst);\n\n\/\/Function to cast a ray through a given coordinate (uv) on the image plane.\n\/\/It returns the direction of a 3D Ray.\n\/\/Note : screen center is uv=[0,0]\nvec3 ray(vec2 uv, Cam cam)\n{\n    return normalize(uv.x*cam.R+uv.y*cam.U+cam.D);\n}\n\n\/\/Function which does the opposite of the previous function:\n\/\/It receives a 3D world space position, then flattens it on the image plane \n\/\/and returns its [uv] coordinates.\n\/\/Note : screen center is uv=[0,0]\nvec2 camProj(Cam c, vec3 p)\n{\n    p = p-c.O;\n    float cZ = dot(p,c.D);\n    float cX = dot(p,c.R);\n\tfloat cY = dot(p,c.U);\n    return vec2(cX\/cZ,cY\/cZ);\n}\n\n\/\/Simple utility function which returns the distance from point \"p\" to a given line segment defined by 2 points [a,b]\nfloat distanceToLineSeg(vec2 p, vec2 a, vec2 b)\n{\n    \/\/e = capped [0,1] orthogonal projection of ap on ab\n    \/\/       p\n    \/\/      \/\n    \/\/     \/\n    \/\/    a--e-------b\n    vec2 ap = p-a;\n    vec2 ab = b-a;\n    vec2 e = a+clamp(dot(ap,ab)\/dot(ab,ab),0.0,1.0)*ab;\n    return length(p-e);\n}\n\n\/\/Utility function returning the intersection point of two 2D lines\n\/\/[p1a,p1b] = line1\n\/\/[p2a,p2b] = line1\nvec2 lineLineIntersection(vec2 p1a, vec2 p1b, vec2 p2a, vec2 p2b)\n{\n    vec2 d1 = (p1b-p1a); \/\/Direction Line 1\n    vec2 d2 = (p2b-p2a); \/\/Direction Line 2\n    vec2 d1n = vec2(d1.y, -d1.x); \/\/orthogonal line to d1 (normal), optimal direction to reach d1 from anywhere\n    float dist = dot(p1a-p2a,d1n);\/\/projection on the optimal direction = distance\n    float rate = dot(d2,d1n); \/\/rate : how much is our d2 line in the optimal direction? (<=1.0)\n    float t = 10000000.0 ; \/\/INFINITY! (rare parallel case)\n    if(rate != 0.0)\n\t\tt = dist\/rate; \/\/Starting from p2a, find the distance to reach the other line along d2.\n    return p2a+t*d2;  \/\/start point + distance along d2 * d2 direction = intersection.\n}\n\n\/\/Utility function to compute the distance along a ray to reach a plane, in 3D.\n\/\/The value returned is the distance along ray to the plane intersection.\n\/\/o = ray origin\n\/\/d = ray direction\n\/\/po = plane origin\n\/\/pn = plane normal\nfloat rayPlaneIntersec(vec3 o, vec3 d, vec3 po, vec3 pn) \n{\n    \/\/Same principle as lineLineIntersection() :\n    \/\/\"How far is the plane\"\/\"approach rate\".\n    \/\/No need to normalize pn, as dot product above and under cancel out and do not scale the result.\n    return dot(po-o,pn)\/dot(d,pn);\n}\n\nstruct screenSpaceQuad{ vec2 a; vec2 b; vec2 c; vec2 d; };\nstruct worldSpaceQuad{  vec3 a; vec3 b; vec3 c; vec3 d; };\n\n\/\/perspectiveCam : the camera from which the points in screen space come from\n\/\/P1 : known world space position of p1\n\/\/p1 : screen space p1 (which is resolved, already)\n\/\/p2 : screen space p2 (which must be adjacent to p1 - cannot be the opposite corner)\n\/\/parallel_a : first point (screen space) in the other line parallel to (p1,p2)\n\/\/parallel_b : second point (screen space) in the other line parallel to (p1,p2)\nvec3 resolveAdjacentCorner(in Cam perspectiveCam, vec3 P1, vec2 p1_resolved, vec2 p2_adjacent, vec2 parallel_a, vec2 parallel_b)\n{\n    \/\/screen space intersection (vanishing point on the projection plane)\n    vec2 ssIntersec = lineLineIntersection(p1_resolved,p2_adjacent,parallel_a,parallel_b);\n    \/\/Vanishing point direction, from camera, in world space.\n    vec3 dirVanishingPoint = ray(ssIntersec, perspectiveCam);\n    vec3 p1_to_p2 = dirVanishingPoint; \/\/Since vanishing point is at \"infinity\", p1_to_p2 == dirVanishingPoint\n    vec3 r2 = ray(p2_adjacent, perspectiveCam);\/\/Ray from camera to p2, in world space\n    \n    \/\/<Line3D intersection : where p1_to_p2 crosses r2>\n    \/\/(Note : this could probably be made simpler with a proper 3D line intersection formula)\n    \/\/Find (rb,p1_to_p2) intersection:\n    vec3 n_cam_p1_p2 = cross(p1_to_p2,r2); \/\/normal to the triangle formed by point p1, point p2 and the camera origin\n    vec3 n_plane_p2 = cross(n_cam_p1_p2,r2); \/\/normal to the plane which is crossed by line p1-p2 at point p2\n    float t = rayPlaneIntersec(P1,p1_to_p2,perspectiveCam.O,n_plane_p2);\n    vec3 p2_ws = P1+t*p1_to_p2;\n    \/\/<\/Line3D intersection>\n    return p2_ws;\n}\n    \n\/\/Finds each corner, one by one.\nvoid resolvePerspective(in Cam perspectiveCam, in screenSpaceQuad ssQuad, out worldSpaceQuad wsQuad)\n{\n    vec3 ra = ray(ssQuad.a, perspectiveCam); \/\/Find the direction of the ray passing by point a in screen space.\n\t                                      \/\/For the sake of simplicity, screenspace [uv.x,uv.y] = worldspace [x,y]. Z = depth.\n    \/\/Let's place point a in an arbitrary position along the ray ra. \n    \/\/It does not matter at which distance exactly, as it is the relationship between\n    \/\/the corners that is important. The first corner distance simply defines the scaling of the 3D scene.\n    wsQuad.a = perspectiveCam.O + 5.5*ra; \/\/5.5 = arbitrary scaling. Projective geometry does not preserve world space scaling.\n    wsQuad.b = resolveAdjacentCorner(perspectiveCam, wsQuad.a, ssQuad.a, ssQuad.b, ssQuad.c, ssQuad.d);\n    wsQuad.c = resolveAdjacentCorner(perspectiveCam, wsQuad.b, ssQuad.b, ssQuad.c, ssQuad.a, ssQuad.d);\n    wsQuad.d = resolveAdjacentCorner(perspectiveCam, wsQuad.a, ssQuad.a, ssQuad.d, ssQuad.b, ssQuad.c);\n}\n\nvec3 apply_atmosphere(float travelDist, in vec3 color, in vec3 p)\n{\n    \/\/From this nice article on fog:\n    \/\/https:\/\/iquilezles.org\/articles\/fog\n    \/\/or this PowerPoint from Crytek:\n\t\/\/GDC2007_RealtimeAtmoFxInGamesRev.ppt p17\n\tvec3 c_atmosphere = mix(vec3(0.87,0.94,1.0),vec3(0.6,0.80,1.0),clamp(3.0*p.y\/length(p.xz),0.,1.));\n    float c = 1.08;\n    float b = 0.06;\n\n    float cumul_density = c * exp(-1.0*b) * (1.0-exp( -travelDist*1.0*b ))\/1.0;\n    cumul_density = clamp(cumul_density,0.0,1.0);\n    vec3 FinalColor = mix(color,c_atmosphere,cumul_density);\n    return FinalColor;\n}\n\nvec3 alphaBlend(vec3 c1, vec3 c2, float alpha)\n{\n    return mix(c1,c2,clamp(alpha,0.0,1.0));\n}\n\nvec2 pixel2uv(vec2 px, bool bRecenter, bool bUniformSpace)\n{\n    if(bRecenter)\n    {\n        px.xy-=iResolution.xy*0.5;\n\t}\n    \n    vec2 resolution = bUniformSpace?iResolution.xx:iResolution.xy;\n    vec2 uv = px.xy \/ resolution;\n    return uv;\n}\n\nvec3 drawPoint(vec2 uv, vec2 point, vec3 cBack, vec3 cPoint, float radius, float fZoom)\n{\n    radius \/= fZoom;\n    float distPt = length(uv-point);\n    float alphaPt = 1.0-smoothstep(radius-.003\/fZoom,radius,distPt);\n    return alphaBlend(cBack,cPoint,alphaPt);\n}\n\nvec3 drawLine(vec2 uv, vec2 pa, vec2 pb, vec3 cBack, vec3 cLine, float radius, float fZoom)\n{\n    radius \/= fZoom;\n    float distLine = distanceToLineSeg(uv,pa,pb);\n    float alphaLine = 1.0-smoothstep(radius-.003\/fZoom,radius,distLine);\n    return alphaBlend(cBack,cLine,alphaLine);\n}\n\n\/\/wsQuad.a = origin (lower left corner)\n\/\/wsQuad.a,b,c,d = CCW point order.\nvec2 findParallelogramUV(vec3 o, vec3 d, worldSpaceQuad wsQuad)\n{\n    \/\/Note : This is tricky because axis are not orthogonal.\n    vec3 uvX_ref = wsQuad.b-wsQuad.a; \/\/horitonal axis\n    vec3 uvY_ref = wsQuad.d-wsQuad.a; \/\/vertical axis\n    vec3 quadN = cross(uvY_ref,uvX_ref);\n    float t = rayPlaneIntersec(o, d, wsQuad.a, quadN);\n        \n    vec3 p = o+t*d;\n    vec3 X0_N = cross(uvY_ref,quadN);\n    vec3 Y0_N = cross(uvX_ref,quadN);\n    \n    \/\/Vertical component : find the point where plane X0 is crossed\n    float t_x0 = rayPlaneIntersec(p, uvX_ref, wsQuad.a, X0_N);\n    vec3 pY = p+t_x0*uvX_ref-wsQuad.a;\n    \/\/Horizontal component : find the point where plane Y0 is crossed\n    float t_y0 = rayPlaneIntersec(p, uvY_ref, wsQuad.a, Y0_N);\n    vec3 pX = p+t_y0*uvY_ref-wsQuad.a;\n    \n    \/\/All is left to find is the relative length ot pX, pY compared to each axis reference\n    return vec2(dot(pX,uvX_ref)\/dot(uvX_ref,uvX_ref),\n\t            dot(pY,uvY_ref)\/dot(uvY_ref,uvY_ref));\n}\n\nvec3 drawPerspectiveScene(Cam perspectiveCam, vec2 uv, screenSpaceQuad ssQuad, worldSpaceQuad wsQuad, vec3 cBackground, float fZoom)\n{\n    vec3 cScene = cBackground;\n    cScene = texture(iChannel0,uv+0.5).xyz;\n    \n\tfloat fLineWidth = 0.0025;\n    cScene = drawLine(uv, ssQuad.a, ssQuad.b, cScene, vec3(0), fLineWidth, fZoom);\n    cScene = drawLine(uv, ssQuad.b, ssQuad.c, cScene, vec3(0), fLineWidth, fZoom);\n    cScene = drawLine(uv, ssQuad.c, ssQuad.d, cScene, vec3(0), fLineWidth, fZoom);\n    cScene = drawLine(uv, ssQuad.d, ssQuad.a, cScene, vec3(0), fLineWidth, fZoom);\n    \n    float fPointRad = 0.006;\n    cScene = drawPoint(uv, ssQuad.a, cScene, vec3(0,1,0), fPointRad, fZoom);\n    cScene = drawPoint(uv, ssQuad.b, cScene, vec3(0,1,0), fPointRad, fZoom);\n    cScene = drawPoint(uv, ssQuad.c, cScene, vec3(0,1,0), fPointRad, fZoom);\n    cScene = drawPoint(uv, ssQuad.d, cScene, vec3(0,1,0), fPointRad, fZoom);\n    \n    \/\/Show results\n    fPointRad = 0.004;\n    vec2 aDebug = camProj(perspectiveCam,wsQuad.a);\n    vec2 bDebug = camProj(perspectiveCam,wsQuad.b);\n    vec2 cDebug = camProj(perspectiveCam,wsQuad.c);\n    vec2 dDebug = camProj(perspectiveCam,wsQuad.d);\n    cScene = drawPoint(uv, aDebug, cScene, vec3(0,0,1), fPointRad, fZoom);\n    cScene = drawPoint(uv, bDebug, cScene, vec3(0,0,1), fPointRad, fZoom);\n    cScene = drawPoint(uv, cDebug, cScene, vec3(0,0,1), fPointRad, fZoom);\n    cScene = drawPoint(uv, dDebug, cScene, vec3(0,0,1), fPointRad, fZoom);\n    \n    return cScene;\n}\n\nCam setupPerspectiveCamera()\n{\n    Cam cam;\n    cam.O = vec3(0,0,0);\n    cam.R = vec3(1,0,0);\n    cam.U = vec3(0,1,0);\n    cam.D = vec3(0,0,-1);\n    return cam;\n}\n\nscreenSpaceQuad setupPerspectiveQuad(vec2 mouse_uv)\n{\n    screenSpaceQuad ssQuad;\n    \n    \/\/Arbitrary screen-space parallelograms.\n    if(fract(iTime\/4.0)> 0.5)\n    {\n        ssQuad.a = SS1_BOTTOM_LEFT-0.5;\n    \tssQuad.b = SS1_BOTTOM_RIGHT-0.5;\n    \tssQuad.c = SS1_TOP_RIGHT-0.5;\n    \tssQuad.d = SS1_TOP_LEFT-0.5;\n    }\n    else\n    {\n     \tssQuad.a = SS2_BOTTOM_LEFT-0.5;\n    \tssQuad.b = SS2_BOTTOM_RIGHT-0.5;\n    \tssQuad.c = SS2_TOP_RIGHT-0.5;\n    \tssQuad.d = SS2_TOP_LEFT-0.5;   \n    }\n    \n    if(iMouse.z > 0.0 && mouse_uv.x < 0.5 && mouse_uv.y < 0.5) \/\/if mouse btn down\n    {\n\t\tssQuad.d = mouse_uv;\n    }\n    \n    return ssQuad;\n}\n\nvec2 inversePerspective_uv(Cam perspectiveCam, vec2 uv_01, screenSpaceQuad ssQuad, worldSpaceQuad wsQuad )\n{\n    vec3 x_ws = wsQuad.b-wsQuad.a;\n    vec3 y_ws = wsQuad.d-wsQuad.a;\n    vec3 p_ws = wsQuad.a+uv_01.x*x_ws + uv_01.y*y_ws;\n    vec2 puv = camProj(perspectiveCam,p_ws);\n\treturn puv;\n}\n\nCam setupSceneCamera()\n{\n    float targetDistance = 10.5;\n    vec3 cam_tgt = vec3(0,0,-3.0);\n    Cam cam = CAM_lookAt(cam_tgt, -0.2, targetDistance, -0.75+iTime*0.1);\n    if(iMouse.xz != vec2(0.0,0.0) && ( iMouse.x > iResolution.x\/4.0 || iMouse.y > iResolution.y\/4.0) ) \/\/Mouse button down : user control\n    {\n    \tcam = CAM_mouseLookAt(cam_tgt, targetDistance);\n    }\n    return cam;\n}\n\nvec3 draw3DScene(Cam perspectiveCam, Cam sceneCam, vec2 uv, worldSpaceQuad wsQuad, screenSpaceQuad ssQuad)\n{\n    vec3 o = sceneCam.O;\n    vec3 d = ray(uv,sceneCam);\n    \n    vec3 cScene = vec3(0);\n    \n    float t = rayPlaneIntersec(o,d, vec3(0,-1.0,0), vec3(0,1,0));\n    if(t<0.0)\n    {\n        t = 1000.0;\n        cScene = apply_atmosphere(t,vec3(1),o+t*d);\n    }\n    else\n    {\n\t\tvec3 pFloor = o+t*d;\n    \tvec3 cFloor = texture(iChannel1,pFloor.xz*0.25).xyz;\n    \tcScene = apply_atmosphere(t,cFloor,pFloor);\n    }\n    \n    float fZoom = 3.0*iResolution.x\/1920.;\n    vec2 aDebug = camProj(sceneCam,wsQuad.a);\n    vec2 bDebug = camProj(sceneCam,wsQuad.b);\n    vec2 cDebug = camProj(sceneCam,wsQuad.c);\n    vec2 dDebug = camProj(sceneCam,wsQuad.d);\n    vec2 oDebug = camProj(sceneCam,perspectiveCam.O);\n    cScene = drawPoint(uv,aDebug,cScene,vec3(1,0,0),0.005, fZoom);\n    cScene = drawPoint(uv,bDebug,cScene,vec3(1,0,0),0.005, fZoom);\n    cScene = drawPoint(uv,cDebug,cScene,vec3(1,0,0),0.005, fZoom);\n    cScene = drawPoint(uv,dDebug,cScene,vec3(1,0,0),0.005, fZoom);\n    cScene = drawPoint(uv,oDebug,cScene,vec3(0,0,1),0.005, fZoom);\n    cScene = drawLine(uv,aDebug,oDebug,cScene,vec3(0,0.8,1),0.0025, fZoom);\n    cScene = drawLine(uv,bDebug,oDebug,cScene,vec3(0,0.8,1),0.0025, fZoom);\n    cScene = drawLine(uv,cDebug,oDebug,cScene,vec3(0,0.8,1),0.0025, fZoom);\n    cScene = drawLine(uv,dDebug,oDebug,cScene,vec3(0,0.8,1),0.0025, fZoom);\n    cScene = drawLine(uv,aDebug,bDebug,cScene,vec3(0),0.0025, fZoom);\n    cScene = drawLine(uv,bDebug,cDebug,cScene,vec3(0),0.0025, fZoom);\n    cScene = drawLine(uv,cDebug,dDebug,cScene,vec3(0),0.0025, fZoom);\n    cScene = drawLine(uv,dDebug,aDebug,cScene,vec3(0),0.0025, fZoom);\n    \n    \/\/Projection Plane (camera near plane)\n    float tImage = rayPlaneIntersec(o,d, perspectiveCam.O+normalize(perspectiveCam.D), perspectiveCam.D);\n    if(tImage>0.0) \/\/tImage < 0 when the ray never intersects the floor plane (intersection happens behind camera)\n    {\n        vec3 pImage = o+tImage*d;\n        vec2 uv = camProj(perspectiveCam,pImage);\n        \n        if(abs(uv.x)<0.5 && abs(uv.y)<0.5*iResolution.y\/iResolution.x)\n        {\n            vec3 cPersp = drawPerspectiveScene(perspectiveCam, uv, ssQuad, wsQuad, vec3(0.55), fZoom*0.1);\n            cScene = alphaBlend(cScene,cPersp,0.5);\n        }\n    }\n    \n    \/\/\n    vec3 nQuad = cross((wsQuad.b-wsQuad.a),(wsQuad.d-wsQuad.a));\n    float tQuad = rayPlaneIntersec(o,d, wsQuad.a, nQuad);\n    if(tQuad>0.0) \/\/tQuad < 0 when the ray never intersects the floor plane (intersection happens behind camera)\n    {\n        vec2 uv = findParallelogramUV(o,d,wsQuad);\n        if(uv.x>0.0 && uv.x<1.0 &&\n           uv.y>0.0 && uv.y<1.0 )\n        {\n            vec2 tuv = inversePerspective_uv(perspectiveCam, uv, ssQuad, wsQuad);\n        \tvec3 cTest = drawPerspectiveScene(perspectiveCam, tuv, ssQuad, wsQuad, vec3(0.55), fZoom*0.25);\n            cScene = alphaBlend(cScene,cTest,0.5);\n        }\n    }\n    \n    return cScene;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    float perspectiveImageSize = 0.25;\n    float fZoom = 3.0*iResolution.x\/1920.;\n    \n    vec2 perspective_uv = pixel2uv(fragCoord\/perspectiveImageSize, true, true);\n    vec2 perspective_mouse_uv = pixel2uv(iMouse.xy\/perspectiveImageSize, true, true);\n\t\n    worldSpaceQuad wsQuad;\n    screenSpaceQuad ssQuad = setupPerspectiveQuad(perspective_mouse_uv);\n    Cam perspectiveCam = setupPerspectiveCamera();\n    resolvePerspective(perspectiveCam,ssQuad,wsQuad);\n    \n    \/\/Perspective view\n    if(fragCoord.x<iResolution.x*perspectiveImageSize && fragCoord.y<iResolution.y*perspectiveImageSize)\n    {\n        vec3 cPerspective = drawPerspectiveScene(perspectiveCam, perspective_uv, ssQuad, wsQuad, vec3(0.55), fZoom*perspectiveImageSize);\n        fragColor = vec4(cPerspective,1.0);\n    }\n    \/\/Inverse view\n    else if(fragCoord.x>iResolution.x*(1.0-perspectiveImageSize) && fragCoord.y<iResolution.y*perspectiveImageSize)\n    {\n        vec2 fragCoordLocal = vec2( fragCoord.x-iResolution.x*(1.0-perspectiveImageSize),fragCoord.y);\n        vec2 inverse_perspective_uv = pixel2uv(fragCoordLocal\/perspectiveImageSize, false, false);\n        \n        vec2 tuv = inversePerspective_uv(perspectiveCam, inverse_perspective_uv, ssQuad, wsQuad);\n        vec3 cTest = drawPerspectiveScene(perspectiveCam, tuv, ssQuad, wsQuad, vec3(0.55), fZoom*perspectiveImageSize);\n        fragColor = vec4(cTest,1.0);\n    }\n    \/\/3D Scene\n    else\n    {\n        vec2 uvScene = pixel2uv(fragCoord, true, true);\n\t    Cam sceneCam = setupSceneCamera();\n\t    vec3 cScene = draw3DScene(perspectiveCam, sceneCam, uvScene, wsQuad, ssQuad);\n        fragColor = vec4(cScene,1.0);\n    }\n}\n\nCam CAM_lookAt(vec3 at, float fPitch, float dst, float rot) \n{ \n    Cam cam;\n    cam.D = vec3(cos(rot)*cos(fPitch),sin(fPitch),sin(rot)*cos(fPitch));\n    cam.U = vec3(-sin(fPitch)*cos(rot),cos(fPitch),-sin(fPitch)*sin(rot));\n    cam.R = cross(cam.D,cam.U); cam.O = at-cam.D*dst;\n    return cam;\n}\nCam CAM_mouseLookAt(vec3 at, float dst)\n{\n    vec2 res = iResolution.xy; vec2 spdXY = vec2(15.1416,4.0);\n    float fMvtX = (iMouse.x\/res.x)-0.535;\n    if(fMvtX>0.3) dst *= (1.0+(fMvtX-0.3)\/0.03);\n    else if(fMvtX<-0.3) dst *= (1.0-(fMvtX+0.3)\/(-0.2));\n\tfMvtX += iTime*0.0150;\/\/Auto turn\n    return CAM_lookAt(at,spdXY.y*((iMouse.y\/res.y)-0.5),dst,spdXY.x*fMvtX);\n}","name":"Image","description":"","type":"image"}]},{"ver":"0.1","info":{"id":"Ms3SRr","date":"1457314218","viewed":1471,"name":"Noise Volume Explanation","username":"Bers","description":"An explanation about 3D noise created from a 2D texture. The difficulty is to allow the noise to be continuous along the 3rd axis.","likes":22,"published":3,"flags":0,"usePreview":0,"tags":[]},"renderpass":[{"inputs":[{"id":"Xsf3zn","filepath":"\/media\/a\/f735bee5b64ef98879dc618b016ecf7939a5756040c2cde21ccb15e69a6e1cfb.png","previewfilepath":"\/media\/ap\/f735bee5b64ef98879dc618b016ecf7939a5756040c2cde21ccb15e69a6e1cfb.png","type":"texture","channel":0,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"false","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":"4dfGRr","channel":0}],"code":"\/\/ Author : S\u00c3\u00a9bastien B\u00c3\u00a9rub\u00c3\u00a9\n\/\/ (trilinearSampling\/Noise function from : Inigo Quilez https:\/\/www.shadertoy.com\/view\/XslGRr)\n\/\/ Created : Dec 2014\n\/\/ Modified : Jan 2016\n\/\/\n\/\/ This shader was created in order to understand and explain the noise stacking trick \n\/\/ used in many excellent volumetric shaders (Clouds, amongst many).\n\/\/ It uses a single texture lookup (r+g channels) to generate 3D noise.\n\/\/\n\/\/ Therefore, here goes the explaination:\n\/\/\n\/\/ \t\tFirst, the sampled result is a trilinear interpolation.\n\/\/      (See images here : https:\/\/en.wikipedia.org\/wiki\/Trilinear_interpolation)\n\/\/      Since the texture() function takes care internally of the fractional interpolation\n\/\/      on the XZ texture plane, one only needs to interpolate between 2 XZ layers in order \n\/\/      to add the 3rd (Y) dimension to the noise and produce a noise volume.\n\/\/\n\/\/      The tricky part here is the [37x17] offset. Why 37x17? If you change this number, you will\n\/\/      essentially get garbage (discontinuities) along the Y-axis. Why is that? Well, it is because\n\/\/      the RGB noise texture is \"hacked\" for this :). The 3 noise layers are NOT random, they only are\n\/\/      a tranlated version of each other. Indeed, the 37x17 is the exact translation to align\n\/\/      the red texture plane on the green texture plane. The B texture plane has a different offset\n\/\/      (I do not remember what it is, but the noise layering trick also works between any channel\n\/\/       when you plug in the exact offset across them. The 64x64 RBG noise textures are\n\/\/       also built that way)\n\/\/\n\/\/      So, now that we know the offset between noise layers, how does that helps in\n\/\/      contructing a noise volume? Well, it helps making the noise volume CONTINOUS across\n\/\/      sections on the Y-Axis. Indeed, when the fractionnal part of the Y-Axis coordinates\n\/\/\t\treturns to zero (t.y), the translated XZ coordinates (by [37x17]) allow us to swap the \n\/\/      R&G channels seamlessly, and continue interpolation along the Y Axis like if it was\n\/\/      a continuous noise volume.\n\/\/\n\/\/      And to finish, \"t = t * t * (3.0 - 2.0 * t)\" is simply an easing function\n\/\/      to convert from purely linear interpolation to a more rounded\/organic transition.\n\/\/\t\tThe noise volume will still work if you remove this line, yet it will look\n\/\/      much less smooth.\n\/\/\n\/\/ Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License.\n\/\/\n\nfloat trilinearSampling(vec3 p)\n{\n    const float TEXTURE_RES = 256.0; \/\/Texture resolution\n    p *= TEXTURE_RES;   \/\/Computation in pixel space (1 unit = 1 pixel)\n    vec3 pixCoord = floor(p);\/\/Pixel coord, integer [0,1,2,3...256...]\n    vec3 t = p-pixCoord;     \/\/Pixel interpolation position, linear [0-1]\n    t = t * t * (3.0 - 2.0 * t); \/\/interpolant easing function\n    \/\/noise volume stacking trick : g layer = r layer shifted by (37x17 pixels ->\n    \/\/this is no keypad smashing, but the actual translation embedded in the noise texture).\n    vec2 layer_translation = -pixCoord.y*vec2(37.0,17.0)\/TEXTURE_RES;\n    vec2 layer1_layer2 = texture(iChannel0,layer_translation+(pixCoord.xz+t.xz+0.5)\/TEXTURE_RES,-100.0).rg;\n    return mix( layer1_layer2.x, layer1_layer2.y, t.y );\n}\n\nconst float PI = 3.14159;\nconst float INFINITY = 200000.0;\n\n\/\/Utility function to compute the distance along a ray to reach a plane, in 3D.\n\/\/The value returned is the distance along ray (in \"d\" units) to the plane intersection.\n\/\/o = ray origin\n\/\/d = ray direction\n\/\/pn = plane normal\n\/\/pp = arbitrary point on the plane\nfloat planeLineIntersect(vec3 o,vec3 d,vec3 pn,vec3 pp)\n{\n    \/\/Note : The plane normal is the optimal direction for a ray to reach it.\n    \/\/The equation below can be conceptualized this way : \"How far is the plane\"\/\"approach rate\".\n    \/\/No need to normalize pn, as dot product above and under cancel out and do not scale the result.\n    return dot(pp-o,pn)\/dot(d,pn);\n}\n\nfloat _sign(float x)\n{\n    if(x>0.)\n        return 1.0;\n    else\n        return -1.0;\n}\n\n\/\/A very basic rotation.\nvec3 rotate(vec3 p, const float yaw, const float pitch)\n{\n    p.xz = vec2( p.x*cos(yaw)+p.z*sin(yaw),\n                 p.z*cos(yaw)-p.x*sin(yaw));\n    p.yz = vec2( p.y*cos(pitch)+p.z*sin(pitch),\n                 p.z*cos(pitch)-p.y*sin(pitch));\n    return p;\n}\n\n\/\/This function returns the intersection point of a ray cast towards a plane.\n\/\/o = ray origin\n\/\/d = ray direction\n\/\/center : the plane center\n\/\/[yaw,pitch] = rad angles\n\/\/Size = plane size\n\/\/return value : distance along the ray to intersec the plane\nfloat plane(vec3 o, vec3 d, vec3 center, vec2 yawPitch, vec2 size)\n{\n    \/\/The plane is not really rotated nor translated. The ray being cast is, however, which yields\n    \/\/the same result.\n    o = o-center;\n    float yaw = yawPitch.x;\n    float pitch = yawPitch.y;\n    d = rotate(d,-yaw,-pitch);\n    o = rotate(o,-yaw,-pitch);\n    \n    \/\/t = distance along the ray to reach the plane.\n    float t = planeLineIntersect(o,d,vec3(0,-_sign(d.y),0),vec3(0,0,0));\n    \n    \/\/Intersection position : (o:start)+(t:step size)*(d:direction)\n    vec3 p = o+t*d;\n    \n    if( abs(p.x) <= size.x && abs(p.z) <= size.y) \/\/xz plane\n    \treturn t;\n    \n    return INFINITY; \/\/Did not cross the plane. Return infinity.\n}\n\n\/\/A very unintersting animation. This is just to show the volumetric lookup values.\nvec4 animatedNoisePlane(vec3 o, vec3 d, vec3 offset, float fTime)\n{\n    float planeAngle = -0.2;\n    vec3 planePos = offset+vec3(0,0,-6);\n    \n    \/\/Rotate layers from in time interval : [0-1]\n    if(fTime<1.)\n    {\n    \tplaneAngle += fTime*PI;\n    }\n    \/\/Move layers up and down between time : [1-2]\n\telse\n    {\n        planePos += vec3(0,0.5+0.5*sin(-PI\/2.+fTime*2.*PI),0);\n    }\n    \n    float t = plane(o,d,planePos,vec2(0.0,planeAngle),vec2(2));\n    \n    \/\/Intersection position : (o:start)+(t:step size)*(d:direction)\n    vec3 p = o+t*d;\n    \n    \/\/Background\n    if(t>=INFINITY || t<0.0 )\n        return vec4(0);\n    \n    \/\/Noise volume at position p (scaled at 1:100)\n    return vec4(vec3(trilinearSampling(p*0.01)),0.25); \/\/0.5 is alpha\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    \/\/Centered, scaled uv coordinates (x:[-0.5;0.5])\n    vec2 uv = (fragCoord.xy-0.5*iResolution.xy) \/ iResolution.xx;\n    \n    \/\/The 3 axis of the camera\n    vec3 camR = vec3(1,0,0);\n    vec3 camU = vec3(0,1,0);\n    vec3 camD = vec3(0,0,-1);\n    vec3 o = vec3(0,1,0);\/\/Camera origin\n    vec3 d = normalize(uv.x*camR+uv.y*camU+camD); \/\/ray direction : use uv coordinate to cast the ray\n    \n    \/\/Arbitrary time scale\n    float fTime = fract(iTime*0.2)*2.0;\n    \n    \/\/Accumulate the values for the 4 lookup planes.\n    float fOffset = 0.0;\n    vec4 cAccum = vec4(0);\n    for(int i=0; i < 4; ++i)\n    {\n        fOffset += 0.5;\n        vec4 c = animatedNoisePlane(o,d,vec3(0,fOffset,-fOffset),fTime);\n        cAccum += (1.0-cAccum.w)*c*c.w;\n    }\n    \n    fragColor = cAccum*1.5;\n}","name":"Image","description":"","type":"image"}]}];var gFollow = -1;
    var gUseScreenshots = piIsMobile();
    var gThemeName = "classic";
    </script>

</head>

<body onload="resultsInitStatic(8,null,null)">

<!-- header =================================================================================== -->


<div id="header">

    <div id="headerBlock1">
        <a href="/" id="headerTitle">Shadertoy</a>
        <form name="formSearch" action="/results" method="get" style="display:inline-block;">
        <div  id="headerSearch">
            <input type="search" id="mySearch" name="query" placeholder="Search..." value=""/>
        </div>
        </form>
    </div>

    <div id="headerBlock2">
            <a class="headerLinks" href="/browse">Browse</a>
        <a class="headerLinks" href="/new">New</a>
        <a class="headerLinks" href="/signin">Sign In</a>
        </div>
</div>
<!-- content ================================================================================== -->

<div id="content">

    
    <script>
    function follow()
    {
        if (gFollow < 0) return;
        try
        {
            var req = new XMLHttpRequest();
            req.onload = function()
            {
                var jsn = req.response;
                if( jsn==null ) return;
                let btnFollow = document.getElementById( "btnFollow");
                if (gFollow == 1) {
                    gFollow = 0;
                    btnFollow.value="Follow";
                } else if (gFollow == 0) {
                    gFollow = 1;
                    btnFollow.value="Unfollow";
                }
            }
            req.open( "POST", "/shadertoy", true );
            req.responseType = "json";
            req.setRequestHeader('Content-Type', 'application/x-www-form-urlencoded');
            if (gFollow == 1) {
                var str = "fu=1&uid=Bers";
            } else if (gFollow == 0) {
                var str = "fs=1&uid=Bers";
            }
            req.send( str );
        }
        catch(e)
        {
            alert( "exception: " + e );
        }
    }
    </script>

    <!-- ---------------------------------- --> 

    <div id="divUser">
        <table style="border:0px;border-spacing:0px;border-collapse:collapse;"><tr>
        <td style="vertical-align:top;">
        <img id="userPicture" src="/media/users/Bers/profile.png"></img>        </td>
        <td style="vertical-align:top;padding-left:16px;">
        <b>Name</b>: Bers <br/><b>Joined</b>: March 15, 2013 <br/> <br/><b>Shaders</b>: 19<br/><b>Playlists</b>: 0<br/><b>Comments</b>: 66<br/> <br/><b>Following</b>: 1<br/><b>Followers</b>: 10<br/>        </td>
        <td style="vertical-align:top;padding-left:32px;">
        <b>About</b><br><br>Name: Sebastien Berube<br/>email: berubeseb@gmail.com<br/><br/>80's kid.<br/><br/>Currently working at Moment Factory.        </td>
        <td style="vertical-align:top;padding-left:32px;">
                    </td>
        </tr></table>
    </div>

<!-- --------------------------- -->

  <div id="controls">

    <div>
      <div style="text-align: center; vertical-align: middle; display: inline-block; padding-bottom:5px; padding-top:4px; margin-right:8px; margin-bottom:8px; margin-top:8px;">
      Sort:      </div>
      <div class="controlOptions"><div class="pageButtonsCurrent" href="/user/Bers/sort=popular">Popular</div><a class="pageButtons" href="/user/Bers/sort=newest">Newest</a><a class="pageButtons" href="/user/Bers/sort=love">Love</a></div>
    </div>

    <div id="controlFilter">
      <div style="display:flex;margin-right:8px;align-items:center;">Filter:</div>
      <div class="controlOptions"> <a class="pageButtons" href="/user/Bers&sort=popular&filter=multipass">Multipass</a><a class="pageButtons" href="/user/Bers&sort=popular&filter=soundoutput">GPU Sound</a><a class="pageButtons" href="/user/Bers&sort=popular&filter=vr">VR</a><a class="pageButtons" href="/user/Bers&sort=popular&filter=soundinput">Microphone</a><a class="pageButtons" href="/user/Bers&sort=popular&filter=musicstream">Soundcloud</a><a class="pageButtons" href="/user/Bers&sort=popular&filter=webcam">Webcam</a></div>
    </div>

    <div>
        <div style="text-align: center; vertical-align: middle; display: inline-block; padding-bottom:5px; padding-top:4px; margin-right:8px; margin-bottom:8px; margin-top:8px;">
        Results (19):        </div>

        <div class="controlOptions">
              <div id="pageButton"0 class="pageButtonsCurrent" href="/user/Bers/sort=popular&from=0&num=8">1</div><a id="pageButton"1 class="pageButtons" href="/user/Bers/sort=popular&from=8&num=8">2</a><a id="pageButton"2 class="pageButtons" href="/user/Bers/sort=popular&from=16&num=8">3</a>        </div>
    </div>
  </div>


  <div id="shaderGrid">
    <div class='searchResult'><div class='searchResultContainer' id='Preview_0_Container'>  <a class='shaderPreview searchResultCanvas' id='Preview_0_Link'>    <div class='previewNoGLContainter searchResultCanvas' id='Preview_0_NoWebGL'>        <img class='previewThumbnailImage' id='Preview_0_ThumnailImageNoWebGL'></img>        <div class='previewNoGLMessage' id='Preview_0_MessageNoWebGL'>No Screenshot Availabe</div>    </div>    <div class='previewErrorContainer searchResultCanvas' id='Preview_0_Error'>        <div class='previewErrorMessage'>Shader Error</div>    </div>    <div class='previewThumbnailContainer searchResultCanvas' id='Preview_0_Thumnail'>        <img class='previewThumbnailImage' id='Preview_0_ThumnailImage'></img>        <div class='previewThumbnailIcon' id='Preview_0_ThumnailWarning1' title='This shader takes too long to compile, a preview image is shown instead to improve browsing.
Click on the shader to see it in real-time.'>Warning</div>        <div class='previewThumbnailIcon' id='Preview_0_ThumnailWarning2' title='You are using static shader previews.
Click on the shader to see it in real-time.'>Preview</div>    </div>    <canvas class='previewCanvas searchResultCanvas' id='Preview_0_Canvas'></canvas>  </a></div><div class='previewInfo' id='Preview_0_Info'>  <span class='previewText'  id='Preview_0_Text'></span>  <span>by</span>  <span class='previewTextUser'  id='Preview_0_TextUser'></span>  <span class='previewStats' id='Preview_0_Stats'></span></div></div><div class='searchResult'><div class='searchResultContainer' id='Preview_1_Container'>  <a class='shaderPreview searchResultCanvas' id='Preview_1_Link'>    <div class='previewNoGLContainter searchResultCanvas' id='Preview_1_NoWebGL'>        <img class='previewThumbnailImage' id='Preview_1_ThumnailImageNoWebGL'></img>        <div class='previewNoGLMessage' id='Preview_1_MessageNoWebGL'>No Screenshot Availabe</div>    </div>    <div class='previewErrorContainer searchResultCanvas' id='Preview_1_Error'>        <div class='previewErrorMessage'>Shader Error</div>    </div>    <div class='previewThumbnailContainer searchResultCanvas' id='Preview_1_Thumnail'>        <img class='previewThumbnailImage' id='Preview_1_ThumnailImage'></img>        <div class='previewThumbnailIcon' id='Preview_1_ThumnailWarning1' title='This shader takes too long to compile, a preview image is shown instead to improve browsing.
Click on the shader to see it in real-time.'>Warning</div>        <div class='previewThumbnailIcon' id='Preview_1_ThumnailWarning2' title='You are using static shader previews.
Click on the shader to see it in real-time.'>Preview</div>    </div>    <canvas class='previewCanvas searchResultCanvas' id='Preview_1_Canvas'></canvas>  </a></div><div class='previewInfo' id='Preview_1_Info'>  <span class='previewText'  id='Preview_1_Text'></span>  <span>by</span>  <span class='previewTextUser'  id='Preview_1_TextUser'></span>  <span class='previewStats' id='Preview_1_Stats'></span></div></div><div class='searchResult'><div class='searchResultContainer' id='Preview_2_Container'>  <a class='shaderPreview searchResultCanvas' id='Preview_2_Link'>    <div class='previewNoGLContainter searchResultCanvas' id='Preview_2_NoWebGL'>        <img class='previewThumbnailImage' id='Preview_2_ThumnailImageNoWebGL'></img>        <div class='previewNoGLMessage' id='Preview_2_MessageNoWebGL'>No Screenshot Availabe</div>    </div>    <div class='previewErrorContainer searchResultCanvas' id='Preview_2_Error'>        <div class='previewErrorMessage'>Shader Error</div>    </div>    <div class='previewThumbnailContainer searchResultCanvas' id='Preview_2_Thumnail'>        <img class='previewThumbnailImage' id='Preview_2_ThumnailImage'></img>        <div class='previewThumbnailIcon' id='Preview_2_ThumnailWarning1' title='This shader takes too long to compile, a preview image is shown instead to improve browsing.
Click on the shader to see it in real-time.'>Warning</div>        <div class='previewThumbnailIcon' id='Preview_2_ThumnailWarning2' title='You are using static shader previews.
Click on the shader to see it in real-time.'>Preview</div>    </div>    <canvas class='previewCanvas searchResultCanvas' id='Preview_2_Canvas'></canvas>  </a></div><div class='previewInfo' id='Preview_2_Info'>  <span class='previewText'  id='Preview_2_Text'></span>  <span>by</span>  <span class='previewTextUser'  id='Preview_2_TextUser'></span>  <span class='previewStats' id='Preview_2_Stats'></span></div></div><div class='searchResult'><div class='searchResultContainer' id='Preview_3_Container'>  <a class='shaderPreview searchResultCanvas' id='Preview_3_Link'>    <div class='previewNoGLContainter searchResultCanvas' id='Preview_3_NoWebGL'>        <img class='previewThumbnailImage' id='Preview_3_ThumnailImageNoWebGL'></img>        <div class='previewNoGLMessage' id='Preview_3_MessageNoWebGL'>No Screenshot Availabe</div>    </div>    <div class='previewErrorContainer searchResultCanvas' id='Preview_3_Error'>        <div class='previewErrorMessage'>Shader Error</div>    </div>    <div class='previewThumbnailContainer searchResultCanvas' id='Preview_3_Thumnail'>        <img class='previewThumbnailImage' id='Preview_3_ThumnailImage'></img>        <div class='previewThumbnailIcon' id='Preview_3_ThumnailWarning1' title='This shader takes too long to compile, a preview image is shown instead to improve browsing.
Click on the shader to see it in real-time.'>Warning</div>        <div class='previewThumbnailIcon' id='Preview_3_ThumnailWarning2' title='You are using static shader previews.
Click on the shader to see it in real-time.'>Preview</div>    </div>    <canvas class='previewCanvas searchResultCanvas' id='Preview_3_Canvas'></canvas>  </a></div><div class='previewInfo' id='Preview_3_Info'>  <span class='previewText'  id='Preview_3_Text'></span>  <span>by</span>  <span class='previewTextUser'  id='Preview_3_TextUser'></span>  <span class='previewStats' id='Preview_3_Stats'></span></div></div><div class='searchResult'><div class='searchResultContainer' id='Preview_4_Container'>  <a class='shaderPreview searchResultCanvas' id='Preview_4_Link'>    <div class='previewNoGLContainter searchResultCanvas' id='Preview_4_NoWebGL'>        <img class='previewThumbnailImage' id='Preview_4_ThumnailImageNoWebGL'></img>        <div class='previewNoGLMessage' id='Preview_4_MessageNoWebGL'>No Screenshot Availabe</div>    </div>    <div class='previewErrorContainer searchResultCanvas' id='Preview_4_Error'>        <div class='previewErrorMessage'>Shader Error</div>    </div>    <div class='previewThumbnailContainer searchResultCanvas' id='Preview_4_Thumnail'>        <img class='previewThumbnailImage' id='Preview_4_ThumnailImage'></img>        <div class='previewThumbnailIcon' id='Preview_4_ThumnailWarning1' title='This shader takes too long to compile, a preview image is shown instead to improve browsing.
Click on the shader to see it in real-time.'>Warning</div>        <div class='previewThumbnailIcon' id='Preview_4_ThumnailWarning2' title='You are using static shader previews.
Click on the shader to see it in real-time.'>Preview</div>    </div>    <canvas class='previewCanvas searchResultCanvas' id='Preview_4_Canvas'></canvas>  </a></div><div class='previewInfo' id='Preview_4_Info'>  <span class='previewText'  id='Preview_4_Text'></span>  <span>by</span>  <span class='previewTextUser'  id='Preview_4_TextUser'></span>  <span class='previewStats' id='Preview_4_Stats'></span></div></div><div class='searchResult'><div class='searchResultContainer' id='Preview_5_Container'>  <a class='shaderPreview searchResultCanvas' id='Preview_5_Link'>    <div class='previewNoGLContainter searchResultCanvas' id='Preview_5_NoWebGL'>        <img class='previewThumbnailImage' id='Preview_5_ThumnailImageNoWebGL'></img>        <div class='previewNoGLMessage' id='Preview_5_MessageNoWebGL'>No Screenshot Availabe</div>    </div>    <div class='previewErrorContainer searchResultCanvas' id='Preview_5_Error'>        <div class='previewErrorMessage'>Shader Error</div>    </div>    <div class='previewThumbnailContainer searchResultCanvas' id='Preview_5_Thumnail'>        <img class='previewThumbnailImage' id='Preview_5_ThumnailImage'></img>        <div class='previewThumbnailIcon' id='Preview_5_ThumnailWarning1' title='This shader takes too long to compile, a preview image is shown instead to improve browsing.
Click on the shader to see it in real-time.'>Warning</div>        <div class='previewThumbnailIcon' id='Preview_5_ThumnailWarning2' title='You are using static shader previews.
Click on the shader to see it in real-time.'>Preview</div>    </div>    <canvas class='previewCanvas searchResultCanvas' id='Preview_5_Canvas'></canvas>  </a></div><div class='previewInfo' id='Preview_5_Info'>  <span class='previewText'  id='Preview_5_Text'></span>  <span>by</span>  <span class='previewTextUser'  id='Preview_5_TextUser'></span>  <span class='previewStats' id='Preview_5_Stats'></span></div></div><div class='searchResult'><div class='searchResultContainer' id='Preview_6_Container'>  <a class='shaderPreview searchResultCanvas' id='Preview_6_Link'>    <div class='previewNoGLContainter searchResultCanvas' id='Preview_6_NoWebGL'>        <img class='previewThumbnailImage' id='Preview_6_ThumnailImageNoWebGL'></img>        <div class='previewNoGLMessage' id='Preview_6_MessageNoWebGL'>No Screenshot Availabe</div>    </div>    <div class='previewErrorContainer searchResultCanvas' id='Preview_6_Error'>        <div class='previewErrorMessage'>Shader Error</div>    </div>    <div class='previewThumbnailContainer searchResultCanvas' id='Preview_6_Thumnail'>        <img class='previewThumbnailImage' id='Preview_6_ThumnailImage'></img>        <div class='previewThumbnailIcon' id='Preview_6_ThumnailWarning1' title='This shader takes too long to compile, a preview image is shown instead to improve browsing.
Click on the shader to see it in real-time.'>Warning</div>        <div class='previewThumbnailIcon' id='Preview_6_ThumnailWarning2' title='You are using static shader previews.
Click on the shader to see it in real-time.'>Preview</div>    </div>    <canvas class='previewCanvas searchResultCanvas' id='Preview_6_Canvas'></canvas>  </a></div><div class='previewInfo' id='Preview_6_Info'>  <span class='previewText'  id='Preview_6_Text'></span>  <span>by</span>  <span class='previewTextUser'  id='Preview_6_TextUser'></span>  <span class='previewStats' id='Preview_6_Stats'></span></div></div><div class='searchResult'><div class='searchResultContainer' id='Preview_7_Container'>  <a class='shaderPreview searchResultCanvas' id='Preview_7_Link'>    <div class='previewNoGLContainter searchResultCanvas' id='Preview_7_NoWebGL'>        <img class='previewThumbnailImage' id='Preview_7_ThumnailImageNoWebGL'></img>        <div class='previewNoGLMessage' id='Preview_7_MessageNoWebGL'>No Screenshot Availabe</div>    </div>    <div class='previewErrorContainer searchResultCanvas' id='Preview_7_Error'>        <div class='previewErrorMessage'>Shader Error</div>    </div>    <div class='previewThumbnailContainer searchResultCanvas' id='Preview_7_Thumnail'>        <img class='previewThumbnailImage' id='Preview_7_ThumnailImage'></img>        <div class='previewThumbnailIcon' id='Preview_7_ThumnailWarning1' title='This shader takes too long to compile, a preview image is shown instead to improve browsing.
Click on the shader to see it in real-time.'>Warning</div>        <div class='previewThumbnailIcon' id='Preview_7_ThumnailWarning2' title='You are using static shader previews.
Click on the shader to see it in real-time.'>Preview</div>    </div>    <canvas class='previewCanvas searchResultCanvas' id='Preview_7_Canvas'></canvas>  </a></div><div class='previewInfo' id='Preview_7_Info'>  <span class='previewText'  id='Preview_7_Text'></span>  <span>by</span>  <span class='previewTextUser'  id='Preview_7_TextUser'></span>  <span class='previewStats' id='Preview_7_Stats'></span></div></div>  </div>
</div>

<!-- footer ================================================================================== -->

<div id="footer">
    
    <div><span style="color:#ffffff;">Community Forums</span>
      <ul>
      <li><a class="regular" href="/events">Official Events</a></li>
      <li><a class="regular" href="https://www.facebook.com/groups/147749602472741">In Facebook (english)</a></li>
      <li><a class="regular" href="https://www.facebook.com/groups/1339783682699494">In Facebook (korean)</a></li>
      <li><a class="regular" href="https://discord.gg/XtmMN6E">In Discord</a> (<a class="regular" href="https://discordapp.com/channels/578696555612209173/579531723348639754">direct link</a>)</li>
      </ul>
    </div>

    <div><span style="color:#ffffff;">Feedback and Support</span>
      <ul>
      <li><a class="regular" href="https://www.facebook.com/Shadertoy">Facebook</a></li>
      <li><a class="regular" href="https://twitter.com/shadertoy">Twitter</a></li>
      <li><a class="regular" href="https://www.patreon.com/shadertoy">Patreon</a></li>
      <li><a class="regular" href="https://trello.com/b/5hM0CjId">Roadmap</a></li>

      
      </ul>
    </div>

    <div><span style="color:#ffffff;">Shadertoy</span>
      <ul>
      <li><a class="regular" href="/store">Store</a></li>
      <li><a class="regular" href="/howto">Documentation</a></li>
      <li><a class="regular" href="/terms">Terms & Privacy</a></li>
      <li><a class="regular" href="/about">About</a></li>
      </ul>
    </div>

    <div><span style="color:#ffffff;">Apps and Plugins</span>
      <ul>
      <li><a class="regular" href="https://itunes.apple.com/us/app/shadertoy/id717961814">Official iPhone App</a> by <a class="user" href="/user/reinder">Reinder</a></li>
      <li><a class="regular" href="https://steamcommunity.com/sharedfiles/filedetails/?id=1726697188">Screensaver</a> by <a class="user" href="/user/kosro">Kosro</a></li>
      <li><a class="regular" href="https://chrome.google.com/webstore/detail/shadertoy-unofficial-plug/ohicbclhdmkhoabobgppffepcopomhgl">Shadertoy plugin</a> by <a class="user" href="/user/patu">Patu</a></li>
      </ul>
    </div>

    <div><span style="color:#ffffff;">Tutorials</span>
      <ul>
      <li><a class="regular" href="https://www.youtube.com/watch?v=0ifChJ0nJfM">Shader coding intro</a> by <a class="user" href="/user/iq">iq</a></li>
      <li><a class="regular" href="https://shadertoyunofficial.wordpress.com/">Shadertoy Unofficial</a> by <a class="user" href="/user/FabriceNeyret2">FabriceNeyret2</a></li>
      </ul>
    </div>

</div>

<div id="compliance" style="padding-bottom:6px;visibility:hidden;left:0;top:0px;width:100%;background-color:rgb(200,120,20,0.93);position:absolute;color:#FFFFFF">
    <div style="text-align: center; margin-top:8px">
        We use cookies to give you the best experience on our website. If you continue using Shadertoy, we'll assume that you are happy to receive all cookies on this website. 
        For more information, please review our <a class="regular" href="/terms">Terms & Privacy</a>.
    </div> 
    <div style="text-align: center;margin-top:6px">
        <button type="button" style="width:100px;font-size:inherit" onclick="acceptCompliance()">Accept</button>
    </div>
</div>

<script>
(function runCompliance() 
{
    let showCompliance = 1;
    let allcookies = document.cookie;
    let cookiearray = allcookies.split(';');
    for (var i=0; i<cookiearray.length; i++)
    {
        let name  = cookiearray[i].split('=')[0];
        let value = cookiearray[i].split('=')[1];
        if (name.trim() == "scmp") 
        {
            showCompliance = value;
            break;
        }
    }

    if (showCompliance === 1) 
    {
        var ve = document.getElementById("compliance");
        ve.style.visibility="visible";
    }
})();

function acceptCompliance()
{
    let now = new Date();
    now.setTime( now.getTime() + (5*365*24*60*60*1000) );
    document.cookie="scmp=0;expires=" + now.toUTCString() + ";";

    var ve = document.getElementById("compliance");
    ve.style.visibility="hidden";
}
</script>

<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-44068895-1', 'shadertoy.com');
    ga('send', 'pageview');
</script>
</body>
</html>
